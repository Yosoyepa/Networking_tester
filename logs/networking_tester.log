2025-05-14 21:33:52 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 21:33:52 [INFO   ] [__main__            ] [main:64] Starting Networking Tester v0.2.0
2025-05-14 21:33:52 [INFO   ] [__main__            ] [main:118] Starting Networking Tester v0.2.0
2025-05-14 21:33:52 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 21:33:52 [INFO   ] [src.core.engine     ] [_load_analyzers:49] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 21:33:53 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 21:33:53 [INFO   ] [src.core.engine     ] [run_live_capture:117] Starting live capture run: interface=auto, count=0, timeout=None, filter='None'
2025-05-14 21:33:53 [INFO   ] [src.core.engine     ] [run_live_capture:125] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 21:33:53 [INFO   ] [src.capture.frame_capture] [start_capture:45] Starting synchronous capture on interface None (count=0, timeout=None, filter='None')
2025-05-14 21:35:22 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 21:35:22 [INFO   ] [__main__            ] [main:64] Starting Networking Tester v0.2.0
2025-05-14 21:35:22 [INFO   ] [__main__            ] [main:118] Starting Networking Tester v0.2.0
2025-05-14 21:35:22 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 21:35:22 [INFO   ] [src.core.engine     ] [_load_analyzers:49] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 21:35:22 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 21:35:22 [INFO   ] [src.core.engine     ] [run_live_capture:117] Starting live capture run: interface=auto, count=0, timeout=None, filter='None'
2025-05-14 21:35:22 [INFO   ] [src.core.engine     ] [run_live_capture:125] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 21:35:22 [INFO   ] [src.capture.frame_capture] [start_capture:45] Starting synchronous capture on interface None (count=0, timeout=None, filter='None')
2025-05-14 21:37:49 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 21:37:49 [INFO   ] [__main__            ] [main:64] Starting Networking Tester v0.2.0
2025-05-14 21:38:14 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 21:49:09 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 21:49:09 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 21:49:09 [INFO   ] [src.core.engine     ] [_load_analyzers:49] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 21:49:09 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 21:51:03 [INFO   ] [__main__            ] [main:180] Starting live capture on interface: Ethernet2
2025-05-14 21:51:03 [ERROR  ] [__main__            ] [main:194] Error during operation: AnalysisEngine.run_live_capture() got an unexpected keyword argument 'output_pcap_path'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\main.py", line 181, in main
    engine.run_live_capture(
TypeError: AnalysisEngine.run_live_capture() got an unexpected keyword argument 'output_pcap_path'
2025-05-14 21:53:14 [INFO   ] [__main__            ] [main:203] Exiting Networking Tester...
2025-05-14 21:53:14 [INFO   ] [src.core.engine     ] [shutdown:179] Shutting down AnalysisEngine...
2025-05-14 21:53:14 [INFO   ] [src.core.engine     ] [shutdown:184] AnalysisEngine shut down.
2025-05-14 21:53:14 [INFO   ] [__main__            ] [main:215] Networking Tester finished.
2025-05-14 21:58:59 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 21:58:59 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 21:58:59 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 21:58:59 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 21:59:08 [INFO   ] [__main__            ] [main:180] Starting live capture on interface: Ethernet2
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet2, count=50, timeout=None, filter='None', write_to='None'
2025-05-14 21:59:08 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface Ethernet2 (count=50, timeout=None, filter='None')
2025-05-14 21:59:08 [ERROR  ] [src.capture.frame_capture] [start_capture:52] Error during synchronous packet capture: Interface 'Ethernet2' not found !
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\capture\frame_capture.py", line 49, in start_capture
    sniff(**kwargs)
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\sendrecv.py", line 1424, in sniff
    sniffer._run(*args, **kwargs)
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\sendrecv.py", line 1273, in _run
    sniff_sockets[_RL2(iface)(type=ETH_P_ALL, iface=iface,
                  ^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\sendrecv.py", line 1258, in <lambda>
    _RL2 = lambda i: L2socket or resolve_iface(i).l2listen()  # type: Callable[[_GlobInterfaceType], Callable[..., SuperSocket]]  # noqa: E501
                                 ^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\interfaces.py", line 434, in resolve_iface
    return resolve_iface(dev, retry=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\interfaces.py", line 431, in resolve_iface
    raise ValueError("Interface '%s' not found !" % dev)
ValueError: Interface 'Ethernet2' not found !
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 21:59:08 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_215908.json
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 0
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: None
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: None
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 0
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 21:59:08 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:07:38 [INFO   ] [__main__            ] [main:203] Exiting Networking Tester...
2025-05-14 22:07:38 [INFO   ] [src.core.engine     ] [shutdown:207] Shutting down AnalysisEngine...
2025-05-14 22:07:38 [INFO   ] [src.core.engine     ] [shutdown:212] AnalysisEngine shut down.
2025-05-14 22:07:38 [INFO   ] [__main__            ] [main:215] Networking Tester finished.
2025-05-14 22:11:51 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 22:11:51 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 22:11:51 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 22:11:51 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 22:13:15 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:163] Starting live capture on interface: Ethernet 2
2025-05-14 22:13:15 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=50, timeout=None, filter='None', write_to='None'
2025-05-14 22:13:15 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface Ethernet 2 (count=50, timeout=None, filter='None')
2025-05-14 22:13:41 [INFO   ] [src.capture.frame_capture] [start_capture:50] Synchronous capture finished on Ethernet 2.
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:13:41 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_221341.json
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 50
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:13:16.419840
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:13:41.039374
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 24.619534
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 2.03
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     UDP: 11
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     OTHER: 5
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 34
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 19
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     20.189.173.17: 6
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.10: 5
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     140.82.112.22: 4
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.4: 2
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 17
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     20.189.173.17: 9
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     255.255.255.255: 5
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     224.0.0.251: 4
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     140.82.112.22: 3
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 16
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53027: 9
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     59727: 5
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     5353: 4
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     52908: 3
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 18
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53027: 6
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     6667: 5
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     5353: 4
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:195]     52908: 4
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:13:41 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:14:27 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:163] Starting live capture on interface: Ethernet 2
2025-05-14 22:14:27 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='mycapture.pcap'
2025-05-14 22:14:27 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-14 22:14:30 [INFO   ] [src.capture.frame_capture] [start_capture:50] Synchronous capture finished on Ethernet 2.
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [run_live_capture:150] Writing 10 captured packets to mycapture.pcap
2025-05-14 22:14:30 [INFO   ] [src.capture.frame_capture] [write_pcap:77] Writing 10 packets to mycapture.pcap
2025-05-14 22:14:30 [INFO   ] [src.capture.frame_capture] [write_pcap:80] Successfully wrote packets to mycapture.pcap
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:14:30 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_221430.json
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 10
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:14:27.323108
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:14:30.041592
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 2.718484
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 3.68
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     OTHER: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 6
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     UDP: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 5
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     18.211.21.156: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.1: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     13.107.5.93: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 3
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     18.211.21.156: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     13.107.5.93: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.1: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     50207: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53035: 2
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     54752: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 4
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     50207: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     54752: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53035: 1
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:14:30 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:15:19 [INFO   ] [src.ui.menu_handler ] [run_main_loop:253] Exiting Networking Tester...
2025-05-14 22:15:19 [INFO   ] [src.core.engine     ] [shutdown:207] Shutting down AnalysisEngine...
2025-05-14 22:15:19 [INFO   ] [src.core.engine     ] [shutdown:212] AnalysisEngine shut down.
2025-05-14 22:15:19 [INFO   ] [src.ui.menu_handler ] [run_main_loop:265] Networking Tester finished.
2025-05-14 22:15:24 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 22:15:24 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 22:15:24 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 22:15:24 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 22:16:36 [ERROR  ] [src.ui.menu_handler ] [handle_pcap_analysis:214] Error during PCAP analysis: type object 'ConfigManager' has no attribute 'set'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\ui\menu_handler.py", line 203, in handle_pcap_analysis
    ConfigManager.set('reporting.default_format', parsed_args.report_format)
    ^^^^^^^^^^^^^^^^^
AttributeError: type object 'ConfigManager' has no attribute 'set'. Did you mean: 'get'?
2025-05-14 22:17:30 [INFO   ] [src.ui.menu_handler ] [run_main_loop:253] Exiting Networking Tester...
2025-05-14 22:17:30 [INFO   ] [src.core.engine     ] [shutdown:207] Shutting down AnalysisEngine...
2025-05-14 22:17:30 [INFO   ] [src.core.engine     ] [shutdown:212] AnalysisEngine shut down.
2025-05-14 22:17:30 [INFO   ] [src.ui.menu_handler ] [run_main_loop:265] Networking Tester finished.
2025-05-14 22:20:35 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 22:20:35 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 22:20:35 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 22:20:35 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 22:21:36 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:214] Report format overridden by CLI to: json
2025-05-14 22:21:36 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:218] Analyzing PCAP file: mycapture.pcap
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [run_from_pcap:158] Starting PCAP file run: mycapture.pcap
2025-05-14 22:21:36 [INFO   ] [src.capture.frame_capture] [read_pcap:57] Reading packets from mycapture.pcap
2025-05-14 22:21:36 [INFO   ] [src.capture.frame_capture] [read_pcap:69] Read and processed 10 packets from mycapture.pcap
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [run_from_pcap:174] PCAP file run finished for mycapture.pcap.
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:21:36 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_222136.json
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 10
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:21:36.150030
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:21:36.150030
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0.0
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 0
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     OTHER: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 6
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     UDP: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 5
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     18.211.21.156: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.1: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     13.107.5.93: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 3
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     18.211.21.156: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     13.107.5.93: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.1: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     50207: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53035: 2
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     54752: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 4
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     50207: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     54752: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53035: 1
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:21:36 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:24:51 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:169] Starting live capture on interface: Ethernet 2
2025-05-14 22:24:51 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='test_para_profe.pcap'
2025-05-14 22:24:51 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-14 22:24:53 [INFO   ] [src.capture.frame_capture] [start_capture:50] Synchronous capture finished on Ethernet 2.
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [run_live_capture:150] Writing 10 captured packets to test_para_profe.pcap
2025-05-14 22:24:53 [INFO   ] [src.capture.frame_capture] [write_pcap:77] Writing 10 packets to test_para_profe.pcap
2025-05-14 22:24:53 [INFO   ] [src.capture.frame_capture] [write_pcap:80] Successfully wrote packets to test_para_profe.pcap
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:24:53 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_222453.json
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 10
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:24:51.730753
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:24:53.070872
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 1.340119
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 7.46
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     UDP: 1
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 9
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     169.150.228.142: 5
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 4
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.10: 1
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 5
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     169.150.228.142: 4
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     255.255.255.255: 1
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 5
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53161: 4
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     59727: 1
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53161: 5
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 4
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:195]     6667: 1
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:24:53 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:25:45 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:169] Starting live capture on interface: auto
2025-05-14 22:25:45 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=auto, count=0, timeout=10, filter='None', write_to='test_para_profe.pcap'
2025-05-14 22:25:45 [INFO   ] [src.core.engine     ] [run_live_capture:141] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 22:25:45 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface None (count=0, timeout=10, filter='None')
2025-05-14 22:25:55 [INFO   ] [src.capture.frame_capture] [start_capture:50] Synchronous capture finished on None.
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:25:55 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_222555.json
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 0
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: None
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: None
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 0
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:25:55 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:26:51 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:214] Report format overridden by CLI to: json
2025-05-14 22:26:51 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:218] Analyzing PCAP file: test_para_profe.pcap
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [run_from_pcap:158] Starting PCAP file run: test_para_profe.pcap
2025-05-14 22:26:51 [INFO   ] [src.capture.frame_capture] [read_pcap:57] Reading packets from test_para_profe.pcap
2025-05-14 22:26:51 [INFO   ] [src.capture.frame_capture] [read_pcap:69] Read and processed 10 packets from test_para_profe.pcap
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [run_from_pcap:174] PCAP file run finished for test_para_profe.pcap.
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:26:51 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_222651.json
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 10
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:26:51.709755
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:26:51.710789
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0.001034
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 9671.18
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     UDP: 1
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 9
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     169.150.228.142: 5
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 4
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.10: 1
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 5
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     169.150.228.142: 4
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     255.255.255.255: 1
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 5
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53161: 4
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     59727: 1
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53161: 5
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 4
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:195]     6667: 1
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:26:51 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:27:58 [INFO   ] [src.ui.menu_handler ] [run_main_loop:265] Exiting Networking Tester...
2025-05-14 22:27:58 [INFO   ] [src.core.engine     ] [shutdown:207] Shutting down AnalysisEngine...
2025-05-14 22:27:58 [INFO   ] [src.core.engine     ] [shutdown:212] AnalysisEngine shut down.
2025-05-14 22:27:58 [INFO   ] [src.ui.menu_handler ] [run_main_loop:277] Networking Tester finished.
2025-05-14 22:34:04 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 22:34:04 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 22:34:04 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 22:34:04 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 22:35:49 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:183] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\testing.pcap
2025-05-14 22:35:49 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:185] Starting live capture on interface: auto
2025-05-14 22:35:49 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=auto, count=0, timeout=10, filter='None', write_to='data\captures\testing.pcap'
2025-05-14 22:35:49 [INFO   ] [src.core.engine     ] [run_live_capture:141] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 22:35:49 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface None (count=0, timeout=10, filter='None')
2025-05-14 22:35:59 [INFO   ] [src.capture.frame_capture] [start_capture:50] Synchronous capture finished on None.
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:35:59 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_223559.json
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 0
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: None
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: None
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 0
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:35:59 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:38:17 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:183] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\my_capture.pcap
2025-05-14 22:38:17 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:185] Starting live capture on interface: Ethernet 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='data\captures\my_capture.pcap'
2025-05-14 22:38:17 [INFO   ] [src.capture.frame_capture] [start_capture:41] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-14 22:38:17 [INFO   ] [src.capture.frame_capture] [start_capture:50] Synchronous capture finished on Ethernet 2.
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [run_live_capture:150] Writing 10 captured packets to data\captures\my_capture.pcap
2025-05-14 22:38:17 [INFO   ] [src.capture.frame_capture] [write_pcap:77] Writing 10 packets to data\captures\my_capture.pcap
2025-05-14 22:38:17 [INFO   ] [src.capture.frame_capture] [write_pcap:80] Successfully wrote packets to data\captures\my_capture.pcap
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:38:17 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_223817.json
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 10
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:38:17.488808
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:38:17.559897
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0.071089
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 140.67
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     UDP: 4
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 6
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 6
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.1: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     52.168.112.66: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     52.168.112.66: 4
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 4
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.1: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53339: 4
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     50060: 1
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53396: 1
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 4
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53339: 2
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     50060: 1
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53396: 1
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:38:17 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:40:50 [INFO   ] [src.ui.menu_handler ] [run_main_loop:289] Exiting Networking Tester...
2025-05-14 22:40:50 [INFO   ] [src.core.engine     ] [shutdown:207] Shutting down AnalysisEngine...
2025-05-14 22:40:50 [INFO   ] [src.core.engine     ] [shutdown:212] AnalysisEngine shut down.
2025-05-14 22:40:50 [INFO   ] [src.ui.menu_handler ] [run_main_loop:301] Networking Tester finished.
2025-05-14 22:46:58 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 22:46:58 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 22:46:58 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 22:46:58 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 22:48:08 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap
2025-05-14 22:48:08 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 22:48:08 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap'
2025-05-14 22:48:08 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-14 22:48:11 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [run_live_capture:150] Writing 5 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap
2025-05-14 22:48:11 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap
2025-05-14 22:48:11 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap
2025-05-14 22:48:11 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap size: 405 bytes.
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:48:11 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_224811.json
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 5
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: 2025-05-14T22:48:09.190804
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: 2025-05-14T22:48:11.182068
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 1.991264
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 2.51
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     OTHER: 3
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     TCP: 2
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     172.64.145.54: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     172.64.145.54: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     192.168.0.5: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53472: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     443: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:195]     53472: 1
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:48:11 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:48:28 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap
2025-05-14 22:48:28 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: auto
2025-05-14 22:48:28 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=auto, count=0, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture1.pcap'
2025-05-14 22:48:28 [INFO   ] [src.core.engine     ] [run_live_capture:141] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 22:48:28 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface None (count=0, timeout=None, filter='None')
2025-05-14 22:49:10 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 22:49:10 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 22:49:10 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 22:49:10 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 22:49:31 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap
2025-05-14 22:49:31 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: auto
2025-05-14 22:49:31 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=auto, count=5, timeout=10, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap'
2025-05-14 22:49:31 [INFO   ] [src.core.engine     ] [run_live_capture:141] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 22:49:31 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface None (count=5, timeout=10, filter='None')
2025-05-14 22:49:41 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on None.
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:49:41 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_224941.json
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 0
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: None
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: None
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 0
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:49:41 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:50:24 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\networking_testerdatacaptures test_capture.pcap
2025-05-14 22:50:24 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: auto
2025-05-14 22:50:24 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=auto, count=5, timeout=10, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\networking_testerdatacaptures test_capture.pcap'
2025-05-14 22:50:24 [INFO   ] [src.core.engine     ] [run_live_capture:141] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 22:50:24 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface None (count=5, timeout=10, filter='None')
2025-05-14 22:50:34 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on None.
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [run_live_capture:154] Live capture run finished.
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:179] Finalizing run...
2025-05-14 22:50:34 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_225034.json
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:190] Final Statistics:
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:197]   total_packets: 0
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:197]   start_time: None
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:197]   end_time: None
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:197]   duration_seconds: 0
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:197]   packets_per_second: 0
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:193]   protocol_distribution:
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ips:
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ips:
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_source_ports:
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:193]   top_destination_ports:
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:197]   error_count: 0
2025-05-14 22:50:34 [INFO   ] [src.core.engine     ] [_finalize_run:203] Run finalized.
2025-05-14 22:50:45 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-14 22:50:45 [INFO   ] [src.core.engine     ] [shutdown:207] Shutting down AnalysisEngine...
2025-05-14 22:50:45 [INFO   ] [src.core.engine     ] [shutdown:212] AnalysisEngine shut down.
2025-05-14 22:50:45 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-14 23:03:48 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 23:03:48 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 23:03:48 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 23:03:48 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 23:04:28 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap
2025-05-14 23:04:28 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 23:04:28 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap'
2025-05-14 23:04:28 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-14 23:04:38 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 10 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap
2025-05-14 23:04:38 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap
2025-05-14 23:04:38 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap
2025-05-14 23:04:38 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture.pcap size: 1244 bytes.
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:04:38 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_230438.json
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 10
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-14T23:04:32.904877
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-14T23:04:38.395845
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 5.490968
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 1.82
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 8
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 6
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.10: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.111.229.128: 1
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.111.229.115: 1
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     255.255.255.255: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.111.229.128: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.111.229.115: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     186.31.253.161: 1
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     59727: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52797: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52796: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     53638: 1
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 6
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     6667: 2
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52797: 1
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52796: 1
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-14 23:04:38 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:06:23 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap
2025-05-14 23:06:23 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: auto
2025-05-14 23:06:23 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=auto, count=10, timeout=10, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap'
2025-05-14 23:06:23 [INFO   ] [src.core.engine     ] [run_live_capture:141] No specific interface provided, Scapy will attempt to choose one.
2025-05-14 23:06:23 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface None (count=10, timeout=10, filter='None')
2025-05-14 23:06:33 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on None.
2025-05-14 23:06:33 [WARNING] [src.core.engine     ] [run_live_capture:155] No packets were captured. PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap' will not be written because there is no data.
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:06:33 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_230633.json
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 0
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: None
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: None
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 0
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-14 23:06:33 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:08:32 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap
2025-05-14 23:08:32 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethenet 2
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethenet 2, count=3, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap'
2025-05-14 23:08:32 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethenet 2 (count=3, timeout=None, filter='None')
2025-05-14 23:08:32 [ERROR  ] [src.capture.frame_capture] [start_capture:53] Error during synchronous packet capture: Interface 'Ethenet 2' not found !
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\capture\frame_capture.py", line 50, in start_capture
    sniff(**kwargs)
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\sendrecv.py", line 1424, in sniff
    sniffer._run(*args, **kwargs)
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\sendrecv.py", line 1273, in _run
    sniff_sockets[_RL2(iface)(type=ETH_P_ALL, iface=iface,
                  ^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\sendrecv.py", line 1258, in <lambda>
    _RL2 = lambda i: L2socket or resolve_iface(i).l2listen()  # type: Callable[[_GlobInterfaceType], Callable[..., SuperSocket]]  # noqa: E501
                                 ^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\interfaces.py", line 434, in resolve_iface
    return resolve_iface(dev, retry=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\interfaces.py", line 431, in resolve_iface
    raise ValueError("Interface '%s' not found !" % dev)
ValueError: Interface 'Ethenet 2' not found !
2025-05-14 23:08:32 [WARNING] [src.core.engine     ] [run_live_capture:155] No packets were captured. PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap' will not be written because there is no data.
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:08:32 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_230832.json
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 0
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: None
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: None
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 0
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-14 23:08:32 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:08:52 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap
2025-05-14 23:08:52 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 23:08:52 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=3, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap'
2025-05-14 23:08:52 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=3, timeout=None, filter='None')
2025-05-14 23:08:59 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 3 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap
2025-05-14 23:08:59 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 3 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap
2025-05-14 23:08:59 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap
2025-05-14 23:08:59 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_capture_profe.pcap size: 776 bytes.
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:08:59 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_230859.json
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 3
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-14T23:08:53.011606
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-14T23:08:59.277215
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 6.265609
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 0.48
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 2
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     OTHER: 1
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.10: 2
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     255.255.255.255: 2
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     59727: 2
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     6667: 2
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-14 23:08:59 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:25:45 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-14 23:25:45 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-14 23:25:45 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-14 23:25:45 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-14 23:31:26 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 23:31:26 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 23:31:26 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 23:31:26 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 23:31:31 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2.pcap
2025-05-14 23:31:31 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 23:31:31 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=15, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2.pcap'
2025-05-14 23:31:31 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=15, filter='None')
2025-05-14 23:31:32 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 10 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2.pcap
2025-05-14 23:31:32 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2.pcap
2025-05-14 23:31:32 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2.pcap
2025-05-14 23:31:32 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2.pcap size: 949 bytes.
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:31:32 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_233132.json
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 10
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-14T23:31:31.830009
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-14T23:31:32.499694
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.669685
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 14.93
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 10
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 6
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     3.130.54.159: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     172.217.173.35: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     142.251.133.99: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     142.250.218.131: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     3.130.54.159: 2
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     172.217.173.35: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     142.251.133.99: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     142.250.218.131: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54376: 2
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54430: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54445: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54460: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 6
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54376: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54430: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54445: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54460: 1
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-14 23:31:32 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:42:09 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-14 23:42:09 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-14 23:42:09 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-14 23:42:09 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-14 23:49:28 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 23:49:28 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 23:49:28 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 23:49:28 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 23:49:35 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v2.pcap
2025-05-14 23:49:35 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 23:49:35 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=15, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v2.pcap'
2025-05-14 23:49:35 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=15, filter='None')
2025-05-14 23:49:39 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 23:49:39 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 10 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v2.pcap
2025-05-14 23:49:39 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v2.pcap
2025-05-14 23:49:39 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v2.pcap
2025-05-14 23:49:39 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v2.pcap size: 3571 bytes.
2025-05-14 23:49:39 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:49:39 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:49:39 [ERROR  ] [src.ui.menu_handler ] [handle_live_capture:207] Error during live capture: Circular reference detected
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\ui\menu_handler.py", line 195, in handle_live_capture
    engine.run_live_capture(
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 159, in run_live_capture
    self._finalize_run()
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 190, in _finalize_run
    self.report_generator.generate_report(self.all_analyzed_data, report_format)
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\reporting\report_generator.py", line 44, in generate_report
    formatted_string = formatter.format(analyzed_data_list)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\reporting\formatters.py", line 16, in format
    return json.dumps(data_list, indent=4, default=str) # default=str for datetime etc.
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 430, in _iterencode
    yield from _iterencode_list(o, _current_indent_level)
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 326, in _iterencode_list
    yield from chunks
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\json\encoder.py", line 341, in _iterencode_dict
    raise ValueError("Circular reference detected")
ValueError: Circular reference detected
2025-05-14 23:49:58 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-14 23:49:58 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-14 23:49:58 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-14 23:49:58 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-14 23:55:06 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 23:55:06 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 23:55:06 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 23:55:06 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 23:55:31 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix.pcap
2025-05-14 23:55:31 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 23:55:31 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix.pcap'
2025-05-14 23:55:31 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-14 23:55:35 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 5 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix.pcap
2025-05-14 23:55:35 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix.pcap
2025-05-14 23:55:35 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix.pcap
2025-05-14 23:55:35 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix.pcap size: 615 bytes.
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:55:35 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_235535.json
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 5
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-14T23:55:33.094283
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-14T23:55:35.957898
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 2.863615
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 1.75
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     OTHER: 3
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.10: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     255.255.255.255: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     59727: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     6667: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 3
2025-05-14 23:55:35 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:55:42 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-14 23:55:42 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-14 23:55:42 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-14 23:55:42 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-14 23:58:39 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-14 23:58:39 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-14 23:58:39 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-14 23:58:39 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-14 23:59:03 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_report_fix.pcap
2025-05-14 23:59:03 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-14 23:59:03 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_report_fix.pcap'
2025-05-14 23:59:03 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-14 23:59:06 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 10 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_report_fix.pcap
2025-05-14 23:59:06 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_report_fix.pcap
2025-05-14 23:59:06 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_report_fix.pcap
2025-05-14 23:59:06 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_report_fix.pcap size: 1080 bytes.
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-14 23:59:06 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250514_235906.json
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 10
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-14T23:59:03.392950
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-14T23:59:06.566849
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 3.173899
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 3.15
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 9
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     20.189.173.25: 4
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 3
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.10: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     66.110.49.114: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 6
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     20.189.173.25: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     255.255.255.255: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     66.110.49.114: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 6
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54697: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     59727: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54971: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54697: 4
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 3
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     6667: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54971: 1
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-14 23:59:06 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-14 23:59:23 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-14 23:59:23 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-14 23:59:23 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-14 23:59:23 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:19:37 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:19:37 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:19:37 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:19:37 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:19:57 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix2.pcap
2025-05-15 00:19:57 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 00:19:57 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix2.pcap'
2025-05-15 00:19:57 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-15 00:19:59 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 5 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix2.pcap
2025-05-15 00:19:59 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix2.pcap
2025-05-15 00:19:59 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix2.pcap
2025-05-15 00:19:59 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_circ_ref_fix2.pcap size: 1978 bytes.
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 00:19:59 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_001959.json
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 5
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T00:19:57.523535
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T00:19:59.549272
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 2.025737
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 2.47
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     OTHER: 2
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 3
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 3
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.168.117.169: 3
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55160: 3
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 3
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 2
2025-05-15 00:19:59 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 00:21:13 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 00:21:13 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:21:13 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:21:13 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:23:23 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:23:23 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:23:23 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:23:23 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:23:33 [INFO   ] [src.ui.menu_handler ] [run_main_loop:307] \nNetworking Tester interrupted by user (Ctrl+C). Exiting now.
2025-05-15 00:23:33 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:23:33 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:23:33 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:23:46 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:23:46 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:23:46 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:23:46 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:23:50 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_flow_debug.pcap
2025-05-15 00:23:50 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 00:23:50 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_flow_debug.pcap'
2025-05-15 00:23:50 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 192.168.0.5:55160 > 52.168.117.169:https PA / Raw. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 192.168.0.5:55160 > 52.168.117.169:https PA / Raw. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 192.168.0.5:55160 > 52.168.117.169:https A / Raw. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 192.168.0.5:55160 > 52.168.117.169:https PA / Raw. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 52.168.117.169:https > 192.168.0.5:55160 A / Padding. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 52.168.117.169:https > 192.168.0.5:55160 PA / Raw. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 52.168.117.169:https > 192.168.0.5:55160 A / Padding. Results: {}
2025-05-15 00:23:51 [WARNING] [src.core.engine     ] [_determine_packet_type_and_analyze:292] FlowAnalyzer returned empty or non-dict results for Ether / IP / TCP 52.168.117.169:https > 192.168.0.5:55160 A / Padding. Results: {}
2025-05-15 00:23:51 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 10 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_flow_debug.pcap
2025-05-15 00:23:51 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_flow_debug.pcap
2025-05-15 00:23:51 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_flow_debug.pcap
2025-05-15 00:23:51 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_flow_debug.pcap size: 3261 bytes.
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 00:23:51 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_002351.json
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 10
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T00:23:51.378698
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T00:23:51.518922
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.140224
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 71.31
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 8
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     OTHER: 2
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.168.117.169: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.168.117.169: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55160: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55160: 4
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 2
2025-05-15 00:23:51 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 00:39:00 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:39:00 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:39:00 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:39:00 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:39:07 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 00:39:07 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:39:07 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:39:07 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:39:14 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 00:39:14 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:39:14 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:39:14 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:39:28 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:39:28 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:39:28 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:39:28 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:39:46 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:39:46 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 00:39:46 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=10, timeout=15, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap'
2025-05-15 00:39:46 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=15, filter='None')
2025-05-15 00:39:47 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 10 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:39:47 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:39:47 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:39:47 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap size: 4431 bytes.
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 00:39:47 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_003947.json
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 10
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T00:39:46.683512
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T00:39:47.808664
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 1.125152
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 8.89
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 10
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 6
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.25.225.136: 2
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     13.89.178.26: 2
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     13.89.178.26: 5
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.25.225.136: 1
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55345: 5
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54375: 1
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 6
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54375: 2
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55345: 2
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 00:39:47 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 00:44:14 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:44:14 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:44:14 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:44:14 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:45:28 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:238] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\est_ethernet2_v3.pcap
2025-05-15 00:45:28 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:252] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\est_ethernet2_v3.pcap
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [run_from_pcap:162] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\est_ethernet2_v3.pcap
2025-05-15 00:45:28 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\est_ethernet2_v3.pcap
2025-05-15 00:45:28 [ERROR  ] [src.capture.frame_capture] [read_pcap:73] Error reading PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\est_ethernet2_v3.pcap: [Errno 2] No such file or directory: 'c:\\Users\\juanc\\Documents\\Proyectos Personales\\networking_tester\\data\\captures\\est_ethernet2_v3.pcap'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\capture\frame_capture.py", line 61, in read_pcap
    packets_from_file = rdpcap(pcap_file)
                        ^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\utils.py", line 1345, in rdpcap
    with PcapReader(filename) as fdesc:  # type: ignore
         ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\utils.py", line 1385, in __call__
    filename, fdesc, magic = cls.open(filename)
                             ^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\scapy\utils.py", line 1419, in open
    fdesc = open(filename, "rb")  # type: _ByteStream
            ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'c:\\Users\\juanc\\Documents\\Proyectos Personales\\networking_tester\\data\\captures\\est_ethernet2_v3.pcap'
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [run_from_pcap:178] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\est_ethernet2_v3.pcap.
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 00:45:28 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_004528.json
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 0
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: None
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: None
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 0
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 00:45:28 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 00:46:15 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:238] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:46:15 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:252] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [run_from_pcap:162] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:46:15 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:46:15 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 10 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [run_from_pcap:178] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_ethernet2_v3.pcap.
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 00:46:15 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_004615.json
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 10
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T00:46:15.025204
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T00:46:15.027310
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.002106
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 4748.34
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 10
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 6
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.25.225.136: 2
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     13.89.178.26: 2
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     13.89.178.26: 5
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     52.25.225.136: 1
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55345: 5
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54375: 1
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 6
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     54375: 2
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55345: 2
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 00:46:15 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 00:46:37 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 00:46:37 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:46:37 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:46:37 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:52:58 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:52:58 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:52:58 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:52:58 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:53:12 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_incomplete_details.pcap
2025-05-15 00:53:12 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 00:53:12 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=15, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_incomplete_details.pcap'
2025-05-15 00:53:12 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=15, timeout=None, filter='None')
2025-05-15 00:53:13 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 15 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_incomplete_details.pcap
2025-05-15 00:53:13 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 15 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_incomplete_details.pcap
2025-05-15 00:53:13 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_incomplete_details.pcap
2025-05-15 00:53:13 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_incomplete_details.pcap size: 11914 bytes.
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 00:53:13 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_005313.json
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 15
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T00:53:12.964073
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T00:53:13.121192
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.157119
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 95.47
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 15
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 9
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     140.82.113.21: 6
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     140.82.113.21: 7
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 6
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     13.89.178.26: 2
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55663: 7
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 6
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55345: 2
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 9
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55663: 6
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 00:53:13 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 00:53:16 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 00:53:16 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:53:16 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:53:16 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:56:19 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:56:19 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:56:19 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:56:19 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:56:40 [ERROR  ] [src.ui.menu_handler ] [handle_live_capture:207] Error during live capture: No closing quotation
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\ui\menu_handler.py", line 153, in handle_live_capture
    args_list = shlex.split(arg_string)
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\shlex.py", line 313, in split
    return list(lex)
           ^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\shlex.py", line 300, in __next__
    token = self.get_token()
            ^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\shlex.py", line 109, in get_token
    raw = self.read_token()
          ^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\AppData\Local\Programs\Python\Python312\Lib\shlex.py", line 191, in read_token
    raise ValueError("No closing quotation")
ValueError: No closing quotation
2025-05-15 00:57:05 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos
2025-05-15 00:57:05 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 00:57:05 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=0, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos'
2025-05-15 00:57:05 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=0, timeout=None, filter='None')
2025-05-15 00:57:34 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 00:57:34 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 1927 captured packets to c:\Users\juanc\Documents\Proyectos
2025-05-15 00:57:34 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 1927 packets to c:\Users\juanc\Documents\Proyectos
2025-05-15 00:57:34 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:205] \nLive capture interrupted by user (Ctrl+C). Returning to main menu.
2025-05-15 00:57:34 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:57:34 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:58:03 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:58:03 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:58:03 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:58:03 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 00:58:49 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 00:58:49 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 00:58:49 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 00:58:49 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 00:58:53 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 00:58:53 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 00:58:53 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 00:58:53 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:02:10 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:02:10 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:02:10 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:02:10 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:03:21 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:03:21 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 01:03:21 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 01:03:21 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:03:27 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:03:27 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:03:27 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:03:27 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:03:31 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:03:31 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 01:03:31 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 01:03:31 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:03:39 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:03:39 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:03:39 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:03:39 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:04:12 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:04:12 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 01:04:12 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 01:04:12 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:04:57 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:165] Report format overridden by CLI to: json
2025-05-15 01:04:57 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:04:57 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap'
2025-05-15 01:04:57 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-15 01:04:57 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 5 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:04:57 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:04:57 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:04:57 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap size: 5348 bytes.
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 01:04:57 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_010457.json
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 5
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T01:04:57.955324
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T01:04:57.958745
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.003421
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 1461.56
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 5
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     190.26.13.208: 4
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 1
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     190.26.13.208: 1
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50673: 1
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50673: 4
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 1
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 01:04:57 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 01:05:01 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:05:01 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:05:01 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:05:01 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:05:13 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:05:13 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 01:05:13 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 01:05:13 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:06:14 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:238] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:06:14 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:252] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [run_from_pcap:162] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:06:14 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:06:14 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [run_from_pcap:178] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live.pcap.
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 01:06:14 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_010614.json
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 5
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T01:06:14.431494
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T01:06:14.432914
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.00142
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 3521.13
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 5
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     190.26.13.208: 4
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 1
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 4
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     190.26.13.208: 1
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 4
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50673: 1
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50673: 4
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 1
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 01:06:14 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 01:06:17 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:06:17 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:06:17 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:06:17 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:07:00 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:07:00 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 01:07:00 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 01:07:00 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:08:37 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:08:37 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:08:37 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:08:37 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:10:18 [INFO   ] [src.ui.menu_handler ] [run_main_loop:307] \nNetworking Tester interrupted by user (Ctrl+C). Exiting now.
2025-05-15 01:10:18 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:10:18 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:10:18 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_packet_summary_generation:370] Packet summary generation test successful (assuming integrated into analyze_packet)
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:378] Running test_performance_metrics_extraction.
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:462] Performance metrics extraction test ran for 4 frames (basic checks).
2025-05-15 01:10:25 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:10:25 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:10:25 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_protocol_analysis:200] Analyzed 3 protocol packets successfully
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_qos_extraction:239] QoS extraction from 32 IP packets successful
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_qos_extraction:278] QoS extraction from 8 WiFi QoS frames successful
2025-05-15 01:10:25 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:10:25 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_security_analysis:313] Security analysis of 2 IP packets successful
2025-05-15 01:10:25 [INFO   ] [networking_tester   ] [test_wifi_frame_analysis:147] Analyzed 3 WiFi frames successfully
2025-05-15 01:10:32 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp72iydwzp\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [start_async_capture:107] Starting asynchronous capture on interface eth0 (filter='tcp')
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [start_async_capture:116] Asynchronous capture started on eth0.
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [stop_async_capture:127] Asynchronous capture stopped.
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_async_capture:261] Async capture test successful (adapted)
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpbd8drdyf\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_capture_statistics:215] Capture statistics test successful (verified absence of stats attributes)
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp9b20lm64\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=5, timeout=None, filter='tcp port 80')
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_capture_with_filter:158] Capture with filter test successful (adapted, checks filter pass-through)
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp4uvj1uij\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_error_handling_async_start_fail:208] Error handling for async start failure test successful
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp9sbek0te\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_error_handling_read_pcap_non_existent:179] Error handling for read_pcap (non-existent file) test successful
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmppxjh7js5\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_error_handling_write_pcap_fail:194] Error handling for write_pcap (failure) test successful
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpv4cl2t4w\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=3, timeout=10, filter='None')
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_live_capture:99] Live capture test successful (adapted for sync capture)
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp_tn0_05t\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_packet_processing_callback_usage:165] Packet processing callback usage is tested via other methods.
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp4udl04zh\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_print_capture_summary:225] Print capture summary test successful (verified absence of summary method)
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpc64tbxvi\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\AppData\Local\Temp\tmpc64tbxvi\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\AppData\Local\Temp\tmpc64tbxvi\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [__main__            ] [test_read_from_pcap:119] PCAP reading test successful (verified callback calls and return)
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:10:32 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpol1svmpj\test_capture.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\AppData\Local\Temp\tmpol1svmpj\output_test.pcap
2025-05-15 01:10:32 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\AppData\Local\Temp\tmpol1svmpj\output_test.pcap
2025-05-15 01:10:32 [ERROR  ] [src.capture.frame_capture] [write_pcap:100] PCAP file C:\Users\juanc\AppData\Local\Temp\tmpol1svmpj\output_test.pcap was NOT created after wrpcap call.
2025-05-15 01:10:32 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpq4qnxwb5\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [start_async_capture:110] Starting asynchronous capture on interface eth0 (filter='tcp')
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [start_async_capture:119] Asynchronous capture started on eth0.
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [stop_async_capture:130] Asynchronous capture stopped.
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_async_capture:268] Async capture test successful (adapted)
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpe3un5tec\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_capture_statistics:222] Capture statistics test successful (verified absence of stats attributes)
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp37_pixlk\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=5, timeout=None, filter='tcp port 80')
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_capture_with_filter:165] Capture with filter test successful (adapted, checks filter pass-through)
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpg15jh1fc\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_error_handling_async_start_fail:215] Error handling for async start failure test successful
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpbloo4acp\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_error_handling_read_pcap_non_existent:186] Error handling for read_pcap (non-existent file) test successful
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp0qwt2t2q\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_error_handling_write_pcap_fail:201] Error handling for write_pcap (failure) test successful
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmps5jy633k\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=3, timeout=10, filter='None')
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_live_capture:99] Live capture test successful (adapted for sync capture)
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpzho61ycs\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_packet_processing_callback_usage:172] Packet processing callback usage is tested via other methods.
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpuhanqasl\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_print_capture_summary:232] Print capture summary test successful (verified absence of summary method)
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpxceemg_2\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\AppData\Local\Temp\tmpxceemg_2\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\AppData\Local\Temp\tmpxceemg_2\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [__main__            ] [test_read_from_pcap:119] PCAP reading test successful (verified callback calls and return)
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:14:20 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp4j_7npm_\test_capture.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\AppData\Local\Temp\tmp4j_7npm_\output_test.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\AppData\Local\Temp\tmp4j_7npm_\output_test.pcap
2025-05-15 01:14:20 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\AppData\Local\Temp\tmp4j_7npm_\output_test.pcap size: 100 bytes.
2025-05-15 01:14:20 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpha_ruowd\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [start_async_capture:110] Starting asynchronous capture on interface eth0 (filter='tcp')
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [start_async_capture:119] Asynchronous capture started on eth0.
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [stop_async_capture:130] Asynchronous capture stopped.
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_async_capture:268] Async capture test successful (adapted)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpbta24pus\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_capture_statistics:222] Capture statistics test successful (verified absence of stats attributes)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpm8ltg2dc\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=5, timeout=None, filter='tcp port 80')
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_capture_with_filter:165] Capture with filter test successful (adapted, checks filter pass-through)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp1sganl14\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_error_handling_async_start_fail:215] Error handling for async start failure test successful
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpm_p3ttsz\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_error_handling_read_pcap_non_existent:186] Error handling for read_pcap (non-existent file) test successful
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpoxm0l1me\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_error_handling_write_pcap_fail:201] Error handling for write_pcap (failure) test successful
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmprn3km47x\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=3, timeout=10, filter='None')
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_live_capture:99] Live capture test successful (adapted for sync capture)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpew27qo1s\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_packet_processing_callback_usage:172] Packet processing callback usage is tested via other methods.
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpkwlo0xrr\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_print_capture_summary:232] Print capture summary test successful (verified absence of summary method)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp9sgld9cc\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\AppData\Local\Temp\tmp9sgld9cc\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\AppData\Local\Temp\tmp9sgld9cc\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_read_from_pcap:119] PCAP reading test successful (verified callback calls and return)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:09 [INFO   ] [__main__            ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpny2sy7qb\test_capture.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\AppData\Local\Temp\tmpny2sy7qb\output_test.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\AppData\Local\Temp\tmpny2sy7qb\output_test.pcap
2025-05-15 01:16:09 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\AppData\Local\Temp\tmpny2sy7qb\output_test.pcap size: 100 bytes.
2025-05-15 01:16:09 [INFO   ] [__main__            ] [test_write_to_pcap:139] PCAP writing test successful (adapted)
2025-05-15 01:16:09 [INFO   ] [__main__            ] [tearDown:63] Test cleanup complete
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_packet_summary_generation:370] Packet summary generation test successful (assuming integrated into analyze_packet)
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:378] Running test_performance_metrics_extraction.
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:462] Performance metrics extraction test ran for 4 frames (basic checks).
2025-05-15 01:16:16 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:16:16 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:16:16 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_protocol_analysis:200] Analyzed 3 protocol packets successfully
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_qos_extraction:239] QoS extraction from 32 IP packets successful
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_qos_extraction:278] QoS extraction from 8 WiFi QoS frames successful
2025-05-15 01:16:16 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:16:16 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_security_analysis:313] Security analysis of 2 IP packets successful
2025-05-15 01:16:16 [INFO   ] [networking_tester   ] [test_wifi_frame_analysis:147] Analyzed 3 WiFi frames successfully
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_ethernet_frame_analysis:94] Analyzed 3 Ethernet frames successfully
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_packet_summary_generation:370] Packet summary generation test successful (assuming integrated into analyze_packet)
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:378] Running test_performance_metrics_extraction.
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:462] Performance metrics extraction test ran for 4 frames (basic checks).
2025-05-15 01:17:31 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:17:31 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:17:31 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_protocol_analysis:200] Analyzed 3 protocol packets successfully
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_qos_extraction:239] QoS extraction from 32 IP packets successful
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_qos_extraction:278] QoS extraction from 8 WiFi QoS frames successful
2025-05-15 01:17:31 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:17:31 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_security_analysis:313] Security analysis of 2 IP packets successful
2025-05-15 01:17:31 [INFO   ] [networking_tester   ] [test_wifi_frame_analysis:147] Analyzed 3 WiFi frames successfully
2025-05-15 01:17:40 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:17:40 [INFO   ] [src.core.engine     ] [__init__:23] Initializing AnalysisEngine...
2025-05-15 01:17:40 [INFO   ] [src.core.engine     ] [_load_analyzers:54] Loaded 5 analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'AnomalyDetector']
2025-05-15 01:17:40 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:18:03 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:03 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Starting live capture on interface: Ethernet 2
2025-05-15 01:18:03 [INFO   ] [src.core.engine     ] [run_live_capture:131] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap'
2025-05-15 01:18:03 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-15 01:18:06 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [run_live_capture:151] Writing 5 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:06 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:06 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:06 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap size: 592 bytes.
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [run_live_capture:158] Live capture run finished.
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 01:18:06 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_011806.json
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 5
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T01:18:05.817830
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T01:18:06.968717
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 1.150887
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 4.34
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 4
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 2
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.10: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     140.82.114.21: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 2
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     255.255.255.255: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     140.82.114.21: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 2
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     59727: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55831: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 2
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     6667: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55831: 1
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 01:18:06 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 01:18:31 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:238] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:31 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:252] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [run_from_pcap:162] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:31 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:31 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [run_from_pcap:178] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap.
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:183] Finalizing run...
2025-05-15 01:18:31 [INFO   ] [src.reporting.report_generator] [generate_report:53] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_011831.json
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:194] Final Statistics:
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:201]   total_packets: 5
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:201]   start_time: 2025-05-15T01:18:31.314299
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:201]   end_time: 2025-05-15T01:18:31.315344
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:201]   duration_seconds: 0.001045
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:201]   packets_per_second: 4784.69
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:197]   protocol_distribution:
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     TCP: 4
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     UDP: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ips:
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 2
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.10: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     140.82.114.21: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ips:
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     192.168.0.5: 2
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     18.211.21.156: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     255.255.255.255: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     140.82.114.21: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_source_ports:
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 2
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     59727: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55831: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:197]   top_destination_ports:
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     443: 2
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     50207: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     6667: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:199]     55831: 1
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:201]   error_count: 0
2025-05-15 01:18:31 [INFO   ] [src.core.engine     ] [_finalize_run:207] Run finalized.
2025-05-15 01:20:17 [INFO   ] [src.ui.menu_handler ] [run_main_loop:299] Exiting Networking Tester...
2025-05-15 01:20:17 [INFO   ] [src.core.engine     ] [shutdown:211] Shutting down AnalysisEngine...
2025-05-15 01:20:17 [INFO   ] [src.core.engine     ] [shutdown:216] AnalysisEngine shut down.
2025-05-15 01:20:17 [INFO   ] [src.ui.menu_handler ] [run_main_loop:311] Networking Tester finished.
2025-05-15 01:48:02 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:48:02 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 01:48:02 [INFO   ] [src.core.engine     ] [_load_analyzers:69] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 01:48:02 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:48:02 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 01:48:02 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 01:48:02 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 01:48:02 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 01:48:02 [INFO   ] [src.core.engine     ] [_load_ai_model:85] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 01:51:04 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:167] Report format overridden by CLI to: json
2025-05-15 01:51:04 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:04 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Ethernet 2
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [run_live_capture:164] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap'
2025-05-15 01:51:04 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-15 01:51:04 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [run_live_capture:181] Writing 5 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:04 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:04 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:04 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap size: 5284 bytes.
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [run_live_capture:186] Live capture run finished.
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:207] Finalizing run...
2025-05-15 01:51:04 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_015104.json
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:220] Final Statistics (also included in reports):
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   total_packets: 5
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   start_time: 2025-05-15T01:51:04.154329
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   end_time: 2025-05-15T01:51:04.219630
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   duration_seconds: 0.065301
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   packets_per_second: 76.57
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   protocol_distribution:
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     TCP: 5
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_source_ips:
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     192.168.0.5: 5
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_destination_ips:
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     140.82.114.22: 4
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     52.168.112.67: 1
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_source_ports:
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     56718: 4
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     56749: 1
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_destination_ports:
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:225]     443: 5
2025-05-15 01:51:04 [INFO   ] [src.core.engine     ] [_finalize_run:222]   error_count: 0
2025-05-15 01:51:41 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:41 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [run_from_pcap:190] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:41 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:41 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [run_from_pcap:202] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap.
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:207] Finalizing run...
2025-05-15 01:51:41 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_015141.json
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:220] Final Statistics (also included in reports):
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   total_packets: 5
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   start_time: 2025-05-15T01:51:41.741331
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   end_time: 2025-05-15T01:51:41.741851
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   duration_seconds: 0.00052
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   packets_per_second: 9615.38
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   protocol_distribution:
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     TCP: 5
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_source_ips:
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     192.168.0.5: 5
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_destination_ips:
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     140.82.114.22: 4
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     52.168.112.67: 1
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_source_ports:
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     56718: 4
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     56749: 1
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_destination_ports:
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:225]     443: 5
2025-05-15 01:51:41 [INFO   ] [src.core.engine     ] [_finalize_run:222]   error_count: 0
2025-05-15 01:52:30 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 01:52:30 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Ethernet 2
2025-05-15 01:52:30 [INFO   ] [src.core.engine     ] [run_live_capture:164] Starting live capture run: interface=Ethernet 2, count=5, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap'
2025-05-15 01:52:30 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=5, timeout=None, filter='None')
2025-05-15 01:52:31 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [run_live_capture:181] Writing 5 captured packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 01:52:31 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 01:52:31 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 01:52:31 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap size: 454 bytes.
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [run_live_capture:186] Live capture run finished.
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:207] Finalizing run...
2025-05-15 01:52:31 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_015231.json
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:220] Final Statistics (also included in reports):
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   total_packets: 5
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   start_time: 2025-05-15T01:52:30.616883
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   end_time: 2025-05-15T01:52:31.617163
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   duration_seconds: 1.00028
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   packets_per_second: 5.0
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   protocol_distribution:
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     OTHER: 2
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     TCP: 3
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_source_ips:
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     192.168.0.5: 2
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     3.130.54.159: 1
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_destination_ips:
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     3.130.54.159: 2
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     192.168.0.5: 1
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_source_ports:
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     54376: 2
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     443: 1
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   top_destination_ports:
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     443: 2
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:225]     54376: 1
2025-05-15 01:52:31 [INFO   ] [src.core.engine     ] [_finalize_run:222]   error_count: 2
2025-05-15 01:53:16 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 01:53:16 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 01:53:16 [INFO   ] [src.core.engine     ] [_load_analyzers:69] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 01:53:16 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 01:53:16 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 01:53:16 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 01:53:16 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 01:53:16 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 01:53:16 [INFO   ] [src.core.engine     ] [_load_ai_model:85] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 01:53:29 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 01:53:29 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:428] Starting AI anomaly model training process...
2025-05-15 01:53:29 [INFO   ] [src.core.engine     ] [_read_packets_for_training:419] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap for training.
2025-05-15 01:53:29 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:458] Extracting features from 5 packets for training.
2025-05-15 01:53:29 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 46)
2025-05-15 01:53:29 [ERROR  ] [src.core.engine     ] [train_ai_anomaly_model:478] AI model training/saving error: 'AnomalyDetector' object has no attribute 'train'
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 468, in train_ai_anomaly_model
    self.ai_anomaly_detector.train(features_df_normal)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'AnomalyDetector' object has no attribute 'train'
2025-05-15 02:01:06 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 02:01:06 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 02:01:06 [INFO   ] [src.core.engine     ] [_load_analyzers:69] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 02:01:06 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 02:01:06 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 02:01:06 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 02:01:06 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 02:01:06 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 02:01:06 [INFO   ] [src.core.engine     ] [_load_ai_model:85] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 02:01:38 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:01:38 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:428] Starting AI anomaly model training process...
2025-05-15 02:01:38 [INFO   ] [src.core.engine     ] [_read_packets_for_training:419] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap for training.
2025-05-15 02:01:38 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:458] Extracting features from 5 packets for training.
2025-05-15 02:01:38 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 51)
2025-05-15 02:01:38 [ERROR  ] [src.core.engine     ] [train_ai_anomaly_model:478] AI model training/saving error: AnomalyDetector.train_model() missing 2 required positional arguments: 'model_save_path' and 'scaler_save_path'
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 468, in train_ai_anomaly_model
    self.ai_anomaly_detector.train_model(features_df_normal)
TypeError: AnomalyDetector.train_model() missing 2 required positional arguments: 'model_save_path' and 'scaler_save_path'
2025-05-15 02:02:00 [INFO   ] [src.core.engine     ] [shutdown:484] Shutting down Analysis Engine...
2025-05-15 02:02:00 [INFO   ] [src.core.engine     ] [shutdown:496] Analysis Engine shut down successfully.
2025-05-15 02:02:00 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 02:05:01 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 02:05:01 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 02:05:01 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 02:05:01 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 02:05:01 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 02:05:01 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 02:05:01 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 02:05:01 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 02:05:01 [INFO   ] [src.core.engine     ] [_load_ai_model:95] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 02:05:08 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 02:05:08 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:438] Starting AI anomaly model training process...
2025-05-15 02:05:08 [INFO   ] [src.core.engine     ] [_read_packets_for_training:429] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap for training.
2025-05-15 02:05:08 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:468] Extracting features from 5 packets for training.
2025-05-15 02:05:08 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 46)
2025-05-15 02:05:08 [ERROR  ] [src.core.engine     ] [train_ai_anomaly_model:488] AI model training/saving error: AnomalyDetector.train_model() missing 2 required positional arguments: 'model_save_path' and 'scaler_save_path'
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 478, in train_ai_anomaly_model
    self.ai_anomaly_detector.train_model(features_df_normal)
TypeError: AnomalyDetector.train_model() missing 2 required positional arguments: 'model_save_path' and 'scaler_save_path'
2025-05-15 02:10:14 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 02:10:14 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 02:10:14 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 02:10:44 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 02:10:44 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 02:10:44 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 02:10:44 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 02:10:44 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 02:10:44 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 02:10:44 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 02:10:44 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 02:10:44 [INFO   ] [src.core.engine     ] [_load_ai_model:95] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 02:10:50 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:10:50 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:438] Starting AI anomaly model training process...
2025-05-15 02:10:50 [INFO   ] [src.core.engine     ] [_read_packets_for_training:429] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap for training.
2025-05-15 02:10:50 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:468] Extracting features from 5 packets for training.
2025-05-15 02:10:50 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 51)
2025-05-15 02:10:50 [ERROR  ] [src.core.engine     ] [train_ai_anomaly_model:488] AI model training/saving error: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 479, in train_ai_anomaly_model
    self.ai_anomaly_detector.train_model(
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\ai_monitoring\anomaly_detector.py", line 142, in train_model
    if not normal_traffic_features_list_of_dicts:
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pandas\core\generic.py", line 1577, in __nonzero__
    raise ValueError(
ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
2025-05-15 02:11:17 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 02:11:17 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 02:11:17 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 02:27:36 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 02:27:36 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 02:27:36 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 02:27:36 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 02:27:36 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 02:27:36 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 02:27:36 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 02:27:36 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 02:27:36 [INFO   ] [src.core.engine     ] [_load_ai_model:95] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 02:27:40 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap
2025-05-15 02:27:40 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:438] Starting AI anomaly model training process...
2025-05-15 02:27:40 [INFO   ] [src.core.engine     ] [_read_packets_for_training:429] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live33.pcap for training.
2025-05-15 02:27:40 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:468] Extracting features from 5 packets for training.
2025-05-15 02:27:40 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 46)
2025-05-15 02:27:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 02:27:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 02:27:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 02:27:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 02:27:41 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:484] AI Anomaly Detector trained and model/scaler saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 02:29:09 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2
2025-05-15 02:29:09 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2
2025-05-15 02:29:09 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2
2025-05-15 02:29:09 [ERROR  ] [src.core.engine     ] [run_from_pcap:202] PCAP file not found: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2
2025-05-15 02:29:22 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:29:22 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:29:22 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:29:22 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap.
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 02:29:22 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_022922.json
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 5
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T02:29:22.166505
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T02:29:22.167539
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.001034
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 4835.59
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 4
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     UDP: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     18.211.21.156: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.10: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     140.82.114.21: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     18.211.21.156: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     255.255.255.255: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     140.82.114.21: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     50207: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     59727: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     55831: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     50207: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     6667: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:235]     55831: 1
2025-05-15 02:29:22 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 0
2025-05-15 02:29:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:259] Starting AI analysis on 5 processed packets' original data.
2025-05-15 02:29:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:267] Extracting features from 5 packets for AI...
2025-05-15 02:29:30 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 48)
2025-05-15 02:29:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:275] AI Feature extraction complete. Shape: (5, 48)
2025-05-15 02:29:30 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 02:29:30 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 02:29:30 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 02:50:45 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 02:50:45 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 02:50:45 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 02:50:45 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 02:50:45 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 02:50:45 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 02:50:45 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-15 02:50:45 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 02:50:45 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 02:50:45 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 02:50:45 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 02:51:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:51:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:51:06 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:51:06 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live2.pcap.
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 02:51:06 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_025106.json
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 5
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T02:51:06.163060
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T02:51:06.164588
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.001528
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 3272.25
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 4
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     UDP: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     18.211.21.156: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.10: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     140.82.114.21: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     18.211.21.156: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     255.255.255.255: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     140.82.114.21: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     50207: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     59727: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     55831: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     50207: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     6667: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:235]     55831: 1
2025-05-15 02:51:06 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 0
2025-05-15 02:51:18 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:259] Starting AI analysis on 5 processed packets' original data.
2025-05-15 02:51:18 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:267] Extracting features from 5 packets for AI...
2025-05-15 02:51:18 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 48)
2025-05-15 02:51:18 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:275] AI Feature extraction complete. Shape: (5, 48)
2025-05-15 02:51:18 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:286] Error scaling features for prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- udp_chksum
- udp_len

2025-05-15 02:51:18 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:291] Error during anomaly prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- ip_dst
- ip_src
- udp_chksum
- udp_len
- wifi_addr1
- ...

2025-05-15 02:51:18 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 5 samples.
2025-05-15 02:51:18 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:92] Performed basic performance feature analysis on 5 samples.
2025-05-15 02:51:18 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:412] AI analysis on session data completed and results structured.
2025-05-15 02:53:18 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:53:18 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:53:18 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:53:18 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap.
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 02:53:18 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_025318.json
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 5
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T02:53:18.915999
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T02:53:18.916510
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.000511
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 9784.74
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     OTHER: 2
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 3
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 1
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 2
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 1
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 2
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 1
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 1
2025-05-15 02:53:18 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 2
2025-05-15 02:53:24 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:259] Starting AI analysis on 5 processed packets' original data.
2025-05-15 02:53:24 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:267] Extracting features from 5 packets for AI...
2025-05-15 02:53:24 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 51)
2025-05-15 02:53:24 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:275] AI Feature extraction complete. Shape: (5, 51)
2025-05-15 02:53:24 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:286] Error scaling features for prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- icmp_chksum
- icmp_code
- icmp_type
- udp_chksum
- udp_len

2025-05-15 02:53:24 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:291] Error during anomaly prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- icmp_chksum
- icmp_code
- icmp_type
- ip_dst
- ip_src
- ...

2025-05-15 02:53:24 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 5 samples.
2025-05-15 02:53:24 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:92] Performed basic performance feature analysis on 5 samples.
2025-05-15 02:53:24 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:412] AI analysis on session data completed and results structured.
2025-05-15 02:55:08 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 02:55:08 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 02:55:08 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 03:03:35 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:03:35 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:03:35 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:03:35 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:03:35 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:03:35 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:03:35 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:13] PerformanceMLAnalyzer initialized.
2025-05-15 03:03:35 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:03:35 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:03:35 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:03:35 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:04:05 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:04:05 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:04:05 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:04:05 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap.
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 03:04:05 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_030405.json
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 5
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T03:04:05.536895
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T03:04:05.538411
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.001516
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 3298.15
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     OTHER: 2
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 3
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 1
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 2
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 1
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 2
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 1
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 1
2025-05-15 03:04:05 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 2
2025-05-15 03:04:09 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:259] Starting AI analysis on 5 processed packets' original data.
2025-05-15 03:04:09 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:267] Extracting features from 5 packets for AI...
2025-05-15 03:04:09 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 51)
2025-05-15 03:04:09 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:275] AI Feature extraction complete. Shape: (5, 51)
2025-05-15 03:04:09 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:286] Error scaling features for prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- icmp_chksum
- icmp_code
- icmp_type
- udp_chksum
- udp_len

2025-05-15 03:04:09 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:291] Error during anomaly prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- icmp_chksum
- icmp_code
- icmp_type
- ip_dst
- ip_src
- ...

2025-05-15 03:04:09 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 5 samples.
2025-05-15 03:04:09 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:412] AI analysis on session data completed and results structured.
2025-05-15 03:04:39 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 03:04:39 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 03:04:39 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 03:05:16 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:05:16 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:05:16 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:05:16 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:05:16 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:05:16 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:05:16 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:05:16 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:05:16 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:05:16 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:05:16 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:05:41 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:05:41 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:05:41 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:05:41 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap.
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 03:05:41 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_030541.json
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 5
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T03:05:41.293464
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T03:05:41.293464
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.0
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 0
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     OTHER: 2
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 3
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 1
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 2
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 1
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 2
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 1
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 1
2025-05-15 03:05:41 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 2
2025-05-15 03:05:48 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:259] Starting AI analysis on 5 processed packets' original data.
2025-05-15 03:05:48 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:267] Extracting features from 5 packets for AI...
2025-05-15 03:05:48 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 51)
2025-05-15 03:05:48 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:275] AI Feature extraction complete. Shape: (5, 51)
2025-05-15 03:05:48 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:286] Error scaling features for prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- icmp_chksum
- icmp_code
- icmp_type
- udp_chksum
- udp_len

2025-05-15 03:05:48 [ERROR  ] [src.ai_monitoring.anomaly_detector] [predict:291] Error during anomaly prediction: The feature names should match those that were passed during fit.
Feature names unseen at fit time:
- icmp_chksum
- icmp_code
- icmp_type
- ip_dst
- ip_src
- ...

2025-05-15 03:05:48 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 5 samples.
2025-05-15 03:05:48 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:412] AI analysis on session data completed and results structured.
2025-05-15 03:05:54 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 03:05:54 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 03:05:54 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 03:21:03 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:21:03 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:21:03 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:21:03 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:21:03 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:21:03 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:21:03 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:21:03 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:21:03 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:21:03 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:21:03 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:21:24 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:21:24 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:21:24 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:21:24 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test_saveload_CLI_live34.pcap.
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 03:21:24 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250515_032124.json
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 5
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T03:21:24.640031
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T03:21:24.641098
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.001067
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 4686.04
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     OTHER: 2
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 3
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 2
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 1
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     3.130.54.159: 2
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     192.168.0.5: 1
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 2
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 1
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 2
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:235]     54376: 1
2025-05-15 03:21:24 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 2
2025-05-15 03:21:28 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:259] Starting AI analysis on 5 processed packets' original data.
2025-05-15 03:21:28 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:267] Extracting features from 5 packets for AI...
2025-05-15 03:21:28 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 5 packets. DataFrame shape: (5, 51)
2025-05-15 03:21:28 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:275] AI Feature extraction complete. Shape: (5, 51)
2025-05-15 03:21:28 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 5 samples.
2025-05-15 03:21:28 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:412] AI analysis on session data completed and results structured.
2025-05-15 03:29:26 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:29:26 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:29:26 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:29:27 [WARNING] [networking_tester   ] [test_end_to_end_workflow:430] test_end_to_end_workflow in test_ai_monitoring.py needs significant refactoring due to core engine changes.
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpmmxjege5\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpmmxjege5\test_model_scaler.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpmmxjege5\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpmmxjege5\test_model_scaler.joblib
2025-05-15 03:29:27 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'non_existent_path.joblib' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:27 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpae33l1f5\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpae33l1f5\test_model_scaler.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:190] --- AI Anomaly Detection Results ---
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:207] [ANOMALY DETECTED] for: Packet 1
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:214] Total anomalies detected in this batch: 1
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpceert01a\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpceert01a\test_model_scaler.joblib
2025-05-15 03:29:27 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpceert01a\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpceert01a\test_model_scaler.joblib
2025-05-15 03:29:27 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpceert01a\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:47] Scaler loaded from default path: C:\Users\juanc\AppData\Local\Temp\tmpceert01a\test_model_scaler.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpvodozjkp\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpvodozjkp\test_model_scaler.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwc2tacjt\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwc2tacjt\test_model_scaler.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpicmlib_1\test_model.joblib
2025-05-15 03:29:27 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpicmlib_1\test_model_scaler.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp4w2bypcs\test_model.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp4w2bypcs\test_model_scaler.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwwfh6xbx\test_model.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwwfh6xbx\test_model_scaler.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpr8uvbzgp\test_model.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpr8uvbzgp\test_model_scaler.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp_gbsz13l\test_model.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp_gbsz13l\test_model_scaler.joblib
2025-05-15 03:29:28 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train:253] Training anomaly detector model on-the-fly...
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train:258] On-the-fly AnomalyDetector model training completed.
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp0i6vmwy6\test_model.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp0i6vmwy6\test_model_scaler.joblib
2025-05-15 03:29:28 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\AppData\Local\Temp\tmp0i6vmwy6\new_model.joblib
2025-05-15 03:29:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\AppData\Local\Temp\tmp0i6vmwy6\new_model_scaler.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp0i6vmwy6\new_model.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp0i6vmwy6\new_model_scaler.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:29 [WARNING] [src.ai_monitoring.anomaly_detector] [predict:292] No features in the input match the features the model was trained on.
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:29 [WARNING] [src.ai_monitoring.anomaly_detector] [predict:292] No features in the input match the features the model was trained on.
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_ethernet_frame_analysis:94] Analyzed 3 Ethernet frames successfully
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_packet_summary_generation:370] Packet summary generation test successful (assuming integrated into analyze_packet)
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:378] Running test_performance_metrics_extraction.
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:462] Performance metrics extraction test ran for 4 frames (basic checks).
2025-05-15 03:29:29 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:29 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:29 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_protocol_analysis:200] Analyzed 3 protocol packets successfully
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_qos_extraction:239] QoS extraction from 32 IP packets successful
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_qos_extraction:278] QoS extraction from 8 WiFi QoS frames successful
2025-05-15 03:29:29 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:29 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_security_analysis:313] Security analysis of 2 IP packets successful
2025-05-15 03:29:29 [INFO   ] [networking_tester   ] [test_wifi_frame_analysis:147] Analyzed 3 WiFi frames successfully
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmphn3e2vnj\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [start_async_capture:110] Starting asynchronous capture on interface eth0 (filter='tcp')
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [start_async_capture:119] Asynchronous capture started on eth0.
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [stop_async_capture:130] Asynchronous capture stopped.
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_async_capture:268] Async capture test successful (adapted)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmplu9c1y81\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_capture_statistics:222] Capture statistics test successful (verified absence of stats attributes)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpq3o2l2es\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=5, timeout=None, filter='tcp port 80')
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_capture_with_filter:165] Capture with filter test successful (adapted, checks filter pass-through)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpc7gvgsu5\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_error_handling_async_start_fail:215] Error handling for async start failure test successful
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp2bkzf9gc\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_error_handling_read_pcap_non_existent:186] Error handling for read_pcap (non-existent file) test successful
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmplhmr02k2\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_error_handling_write_pcap_fail:201] Error handling for write_pcap (failure) test successful
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpm4l8oopc\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=3, timeout=10, filter='None')
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_live_capture:99] Live capture test successful (adapted for sync capture)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpsm4c_mv9\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_packet_processing_callback_usage:172] Packet processing callback usage is tested via other methods.
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpssk99oou\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_print_capture_summary:232] Print capture summary test successful (verified absence of summary method)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp2p7363bv\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\AppData\Local\Temp\tmp2p7363bv\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\AppData\Local\Temp\tmp2p7363bv\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_read_from_pcap:119] PCAP reading test successful (verified callback calls and return)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmplkmomb6f\test_capture.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\AppData\Local\Temp\tmplkmomb6f\output_test.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\AppData\Local\Temp\tmplkmomb6f\output_test.pcap
2025-05-15 03:29:29 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\AppData\Local\Temp\tmplkmomb6f\output_test.pcap size: 100 bytes.
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [test_write_to_pcap:139] PCAP writing test successful (adapted)
2025-05-15 03:29:29 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:29 [WARNING] [src.ai_monitoring.performance_analyzer_ml_simple] [analyze_performance_features:34] Performance analysis input is empty.
2025-05-15 03:29:29 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:45 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:29:45 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:29:45 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:29:46 [WARNING] [networking_tester   ] [test_end_to_end_workflow:430] test_end_to_end_workflow in test_ai_monitoring.py needs significant refactoring due to core engine changes.
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp033synlm\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp033synlm\test_model_scaler.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp033synlm\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp033synlm\test_model_scaler.joblib
2025-05-15 03:29:46 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'non_existent_path.joblib' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:46 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpe0fntmi8\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpe0fntmi8\test_model_scaler.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:190] --- AI Anomaly Detection Results ---
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:207] [ANOMALY DETECTED] for: Packet 1
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:214] Total anomalies detected in this batch: 1
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwii2yhkw\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwii2yhkw\test_model_scaler.joblib
2025-05-15 03:29:46 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwii2yhkw\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwii2yhkw\test_model_scaler.joblib
2025-05-15 03:29:46 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwii2yhkw\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:47] Scaler loaded from default path: C:\Users\juanc\AppData\Local\Temp\tmpwii2yhkw\test_model_scaler.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp838_ufxo\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp838_ufxo\test_model_scaler.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwsz35tlv\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwsz35tlv\test_model_scaler.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwkjf3cbs\test_model.joblib
2025-05-15 03:29:46 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpwkjf3cbs\test_model_scaler.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp8d_girgv\test_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp8d_girgv\test_model_scaler.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxviwoj7e\test_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxviwoj7e\test_model_scaler.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp9vd0mu_g\test_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp9vd0mu_g\test_model_scaler.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpoqtci9tq\test_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpoqtci9tq\test_model_scaler.joblib
2025-05-15 03:29:47 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train:253] Training anomaly detector model on-the-fly...
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train:258] On-the-fly AnomalyDetector model training completed.
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpdg1hoenw\test_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpdg1hoenw\test_model_scaler.joblib
2025-05-15 03:29:47 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\AppData\Local\Temp\tmpdg1hoenw\new_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\AppData\Local\Temp\tmpdg1hoenw\new_model_scaler.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpdg1hoenw\new_model.joblib
2025-05-15 03:29:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpdg1hoenw\new_model_scaler.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:48 [WARNING] [src.ai_monitoring.anomaly_detector] [predict:292] No features in the input match the features the model was trained on.
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 03:29:48 [WARNING] [src.ai_monitoring.anomaly_detector] [predict:292] No features in the input match the features the model was trained on.
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_ethernet_frame_analysis:94] Analyzed 3 Ethernet frames successfully
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_packet_summary_generation:370] Packet summary generation test successful (assuming integrated into analyze_packet)
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:378] Running test_performance_metrics_extraction.
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:462] Performance metrics extraction test ran for 4 frames (basic checks).
2025-05-15 03:29:48 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:48 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:48 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_protocol_analysis:200] Analyzed 3 protocol packets successfully
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_qos_extraction:239] QoS extraction from 32 IP packets successful
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_qos_extraction:278] QoS extraction from 8 WiFi QoS frames successful
2025-05-15 03:29:48 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:48 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_security_analysis:313] Security analysis of 2 IP packets successful
2025-05-15 03:29:48 [INFO   ] [networking_tester   ] [test_wifi_frame_analysis:147] Analyzed 3 WiFi frames successfully
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpujf9nl7_\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [start_async_capture:110] Starting asynchronous capture on interface eth0 (filter='tcp')
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [start_async_capture:119] Asynchronous capture started on eth0.
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [stop_async_capture:130] Asynchronous capture stopped.
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_async_capture:268] Async capture test successful (adapted)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpjw5d5s_4\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_capture_statistics:222] Capture statistics test successful (verified absence of stats attributes)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp1ec_24p5\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=5, timeout=None, filter='tcp port 80')
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_capture_with_filter:165] Capture with filter test successful (adapted, checks filter pass-through)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpvd8on4nm\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_error_handling_async_start_fail:215] Error handling for async start failure test successful
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpkfezvck8\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_error_handling_read_pcap_non_existent:186] Error handling for read_pcap (non-existent file) test successful
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpusar37ht\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_error_handling_write_pcap_fail:201] Error handling for write_pcap (failure) test successful
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp_1fggeuu\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=3, timeout=10, filter='None')
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_live_capture:99] Live capture test successful (adapted for sync capture)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp8fgddd64\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_packet_processing_callback_usage:172] Packet processing callback usage is tested via other methods.
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpbv0vlvlv\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_print_capture_summary:232] Print capture summary test successful (verified absence of summary method)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp5ou4y44y\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\AppData\Local\Temp\tmp5ou4y44y\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\AppData\Local\Temp\tmp5ou4y44y\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_read_from_pcap:119] PCAP reading test successful (verified callback calls and return)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp99tbk4tc\test_capture.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\AppData\Local\Temp\tmp99tbk4tc\output_test.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\AppData\Local\Temp\tmp99tbk4tc\output_test.pcap
2025-05-15 03:29:48 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\AppData\Local\Temp\tmp99tbk4tc\output_test.pcap size: 100 bytes.
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [test_write_to_pcap:139] PCAP writing test successful (adapted)
2025-05-15 03:29:48 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:48 [WARNING] [src.ai_monitoring.performance_analyzer_ml_simple] [analyze_performance_features:34] Performance analysis input is empty.
2025-05-15 03:29:48 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:29:58 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:00 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:01 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:03 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:05 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:06 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:08 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:10 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:11 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:30:13 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:31:27 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 03:31:27 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 03:31:27 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 03:31:35 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:31:35 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:31:35 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:31:35 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:31:35 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:31:35 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:31:35 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:31:35 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:31:35 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:31:35 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:31:35 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:34:16 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:34:17 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:34:17 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:34:17 [WARNING] [networking_tester   ] [test_end_to_end_workflow:430] test_end_to_end_workflow in test_ai_monitoring.py needs significant refactoring due to core engine changes.
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp7cvngez5\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp7cvngez5\test_model_scaler.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp7cvngez5\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp7cvngez5\test_model_scaler.joblib
2025-05-15 03:34:17 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'non_existent_path.joblib' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:34:17 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpox3jy6_c\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpox3jy6_c\test_model_scaler.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:190] --- AI Anomaly Detection Results ---
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:207] [ANOMALY DETECTED] for: Packet 1
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [interpret_prediction_results:214] Total anomalies detected in this batch: 1
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxnshn6j6\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxnshn6j6\test_model_scaler.joblib
2025-05-15 03:34:17 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxnshn6j6\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxnshn6j6\test_model_scaler.joblib
2025-05-15 03:34:17 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpxnshn6j6\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:47] Scaler loaded from default path: C:\Users\juanc\AppData\Local\Temp\tmpxnshn6j6\test_model_scaler.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpqd8h0of6\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpqd8h0of6\test_model_scaler.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpppezi9ze\test_model.joblib
2025-05-15 03:34:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpppezi9ze\test_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpiugmln62\test_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpiugmln62\test_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmp6y9i31qx\test_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmp6y9i31qx\test_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpapyr_vcl\test_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpapyr_vcl\test_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmphlslo93_\test_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmphlslo93_\test_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpr8nwxwwo\test_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpr8nwxwwo\test_model_scaler.joblib
2025-05-15 03:34:18 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [train:253] Training anomaly detector model on-the-fly...
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [train:258] On-the-fly AnomalyDetector model training completed.
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpd2goj5et\test_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpd2goj5et\test_model_scaler.joblib
2025-05-15 03:34:18 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\AppData\Local\Temp\tmpd2goj5et\new_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\AppData\Local\Temp\tmpd2goj5et\new_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\AppData\Local\Temp\tmpd2goj5et\new_model.joblib
2025-05-15 03:34:18 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\AppData\Local\Temp\tmpd2goj5et\new_model_scaler.joblib
2025-05-15 03:34:18 [INFO   ] [networking_tester   ] [test_ethernet_frame_analysis:94] Analyzed 3 Ethernet frames successfully
2025-05-15 03:34:18 [INFO   ] [networking_tester   ] [test_packet_summary_generation:370] Packet summary generation test successful (assuming integrated into analyze_packet)
2025-05-15 03:34:18 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:378] Running test_performance_metrics_extraction.
2025-05-15 03:34:18 [INFO   ] [networking_tester   ] [test_performance_metrics_extraction:462] Performance metrics extraction test ran for 4 frames (basic checks).
2025-05-15 03:34:18 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:34:18 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:34:18 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:34:18 [INFO   ] [networking_tester   ] [test_protocol_analysis:200] Analyzed 3 protocol packets successfully
2025-05-15 03:34:19 [INFO   ] [networking_tester   ] [test_qos_extraction:239] QoS extraction from 32 IP packets successful
2025-05-15 03:34:19 [INFO   ] [networking_tester   ] [test_qos_extraction:278] QoS extraction from 8 WiFi QoS frames successful
2025-05-15 03:34:19 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:34:19 [WARNING] [src.analysis.protocol_analyzer] [analyze_packet:26] ProtocolAnalyzer received a MagicMock packet directly. Providing enhanced mock data.
2025-05-15 03:34:19 [INFO   ] [networking_tester   ] [test_security_analysis:313] Security analysis of 2 IP packets successful
2025-05-15 03:34:19 [INFO   ] [networking_tester   ] [test_wifi_frame_analysis:147] Analyzed 3 WiFi frames successfully
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpuk008ku1\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [start_async_capture:110] Starting asynchronous capture on interface eth0 (filter='tcp')
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [start_async_capture:119] Asynchronous capture started on eth0.
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [stop_async_capture:130] Asynchronous capture stopped.
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_async_capture:268] Async capture test successful (adapted)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp9txcusug\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_capture_statistics:222] Capture statistics test successful (verified absence of stats attributes)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp2662b8kd\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=5, timeout=None, filter='tcp port 80')
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_capture_with_filter:165] Capture with filter test successful (adapted, checks filter pass-through)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmplree9rcv\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_error_handling_async_start_fail:215] Error handling for async start failure test successful
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpgsf8prc6\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_error_handling_read_pcap_non_existent:186] Error handling for read_pcap (non-existent file) test successful
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp_ao2sur8\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_error_handling_write_pcap_fail:201] Error handling for write_pcap (failure) test successful
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmpt7fih3ac\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface eth0 (count=3, timeout=10, filter='None')
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on eth0.
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_live_capture:99] Live capture test successful (adapted for sync capture)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp1oghb0h7\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_packet_processing_callback_usage:172] Packet processing callback usage is tested via other methods.
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp6j4by6c4\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_print_capture_summary:232] Print capture summary test successful (verified absence of summary method)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmp3iu5pe1i\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\AppData\Local\Temp\tmp3iu5pe1i\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 5 packets from C:\Users\juanc\AppData\Local\Temp\tmp3iu5pe1i\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_read_from_pcap:119] PCAP reading test successful (verified callback calls and return)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [setUp:49] Test setup complete. Created test PCAP at C:\Users\juanc\AppData\Local\Temp\tmplrakru6n\test_capture.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 5 packets to C:\Users\juanc\AppData\Local\Temp\tmplrakru6n\output_test.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\AppData\Local\Temp\tmplrakru6n\output_test.pcap
2025-05-15 03:34:19 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\AppData\Local\Temp\tmplrakru6n\output_test.pcap size: 100 bytes.
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [test_write_to_pcap:139] PCAP writing test successful (adapted)
2025-05-15 03:34:19 [INFO   ] [test_frame_capture  ] [tearDown:63] Test cleanup complete
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [WARNING] [src.ai_monitoring.performance_analyzer_ml_simple] [analyze_performance_features:34] Performance analysis input is empty.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [WARNING] [src.ai_monitoring.performance_analyzer_ml_simple] [analyze_performance_features:34] Performance analysis input is empty.
2025-05-15 03:34:19 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:34:19 [INFO   ] [__main__            ] [run_tests:54] Tests run: 47
2025-05-15 03:34:19 [INFO   ] [__main__            ] [run_tests:55] Errors: 0
2025-05-15 03:34:19 [INFO   ] [__main__            ] [run_tests:56] Failures: 0
2025-05-15 03:34:19 [INFO   ] [__main__            ] [run_tests:57] Skipped: 7
2025-05-15 03:36:54 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:36:56 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:36:57 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:36:59 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:37:01 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:37:03 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:37:05 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:37:06 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:37:08 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:37:10 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:44:34 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:44:34 [INFO   ] [__main__            ] [run_feature_mismatch_test:31] Running feature mismatch test
2025-05-15 03:44:34 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:44:34 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:44:34 [INFO   ] [__main__            ] [run_feature_mismatch_test:60] Feature mismatch test passed: Successfully made predictions with mismatched features
2025-05-15 03:44:41 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:44:41 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:44:41 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:44:41 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:44:41 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:44:41 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:44:41 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:44:41 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:44:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:44:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:44:41 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:45:11 [INFO   ] [src.ui.menu_handler ] [run_main_loop:427] \nNetworking Tester interrupted by user (Ctrl+C). Exiting now.
2025-05-15 03:45:11 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 03:45:11 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 03:45:11 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 03:50:09 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:50:09 [INFO   ] [__main__            ] [run_feature_mismatch_test:31] Running feature mismatch test
2025-05-15 03:50:09 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:50:09 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:50:09 [INFO   ] [__main__            ] [run_feature_mismatch_test:60] Feature mismatch test passed: Successfully made predictions with mismatched features
2025-05-15 03:50:11 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:50:11 [ERROR  ] [__main__            ] [main:116] PCAP file not found: nonexistent_file.pcap
2025-05-15 03:50:13 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:50:13 [ERROR  ] [__main__            ] [main:110] --live and --file options cannot be used together
2025-05-15 03:50:53 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:50:53 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:50:53 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:50:53 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:50:53 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:50:53 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:50:53 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:50:53 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:50:53 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:50:53 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:50:53 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:50:56 [INFO   ] [src.ui.menu_handler ] [run_main_loop:427] \nNetworking Tester interrupted by user (Ctrl+C). Exiting now.
2025-05-15 03:50:56 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 03:50:56 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 03:50:56 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 03:51:37 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 03:51:37 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 03:51:37 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 03:51:37 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 03:51:37 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 03:51:37 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 03:51:37 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 03:51:37 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 03:51:37 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 03:51:37 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:51:37 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 03:51:51 [INFO   ] [src.ui.menu_handler ] [run_main_loop:427] \nNetworking Tester interrupted by user (Ctrl+C). Exiting now.
2025-05-15 03:51:51 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 03:51:51 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 03:51:51 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 04:04:40 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:04:40 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 04:04:40 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 04:04:40 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 04:04:40 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 04:04:40 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 04:04:40 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 04:04:40 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 04:04:40 [INFO   ] [src.core.engine     ] [_ensure_model_dir_exists:84] Created directory for AI model: C:\Users\juanc\Documents\Proyectos Personales\data\models
2025-05-15 04:04:40 [INFO   ] [src.core.engine     ] [_load_ai_model:95] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Proyectos Personales\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 04:04:47 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 04:04:47 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 04:04:47 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 04:04:53 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 04:04:53 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 04:04:53 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 04:04:57 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:04:57 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 04:04:57 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 04:04:57 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 04:04:57 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 04:04:57 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 04:04:57 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 04:04:57 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 04:04:57 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 04:04:57 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:04:57 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:18:26 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:26 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 04:18:26 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 04:18:26 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 04:18:26 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 04:18:26 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 04:18:26 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 04:18:26 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 04:18:26 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 04:18:26 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:18:26 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:18:32 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:34 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:35 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:35 [ERROR  ] [__main__            ] [main:116] PCAP file not found: nonexistent_file.pcap
2025-05-15 04:18:37 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:37 [ERROR  ] [__main__            ] [main:110] --live and --file options cannot be used together
2025-05-15 04:18:39 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:39 [INFO   ] [__main__            ] [main:120] Headless mode not fully implemented for this option
2025-05-15 04:18:40 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:42 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:43 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:43 [INFO   ] [__main__            ] [run_feature_mismatch_test:31] Running feature mismatch test
2025-05-15 04:18:43 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 04:18:43 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 04:18:43 [INFO   ] [__main__            ] [run_feature_mismatch_test:60] Feature mismatch test passed: Successfully made predictions with mismatched features
2025-05-15 04:18:45 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:45 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 04:18:45 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 04:18:45 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 04:18:45 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 04:18:45 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 04:18:45 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 04:18:45 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 04:18:45 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 04:18:45 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:18:45 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:18:51 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:53 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:54 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:54 [ERROR  ] [__main__            ] [main:116] PCAP file not found: nonexistent_file.pcap
2025-05-15 04:18:56 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:56 [ERROR  ] [__main__            ] [main:110] --live and --file options cannot be used together
2025-05-15 04:18:58 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:18:58 [INFO   ] [__main__            ] [main:120] Headless mode not fully implemented for this option
2025-05-15 04:19:00 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:01 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:03 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:03 [INFO   ] [__main__            ] [run_feature_mismatch_test:31] Running feature mismatch test
2025-05-15 04:19:03 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 04:19:03 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 04:19:03 [INFO   ] [__main__            ] [run_feature_mismatch_test:60] Feature mismatch test passed: Successfully made predictions with mismatched features
2025-05-15 04:19:22 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 04:19:22 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 04:19:22 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 04:19:25 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 04:19:25 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 04:19:25 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 04:19:48 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:48 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 04:19:48 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 04:19:48 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 04:19:48 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 04:19:48 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 04:19:48 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 04:19:48 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 04:19:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 04:19:48 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:19:48 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:19:54 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:55 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:57 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:57 [ERROR  ] [__main__            ] [main:116] PCAP file not found: nonexistent_file.pcap
2025-05-15 04:19:58 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:19:58 [ERROR  ] [__main__            ] [main:110] --live and --file options cannot be used together
2025-05-15 04:20:00 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:20:00 [INFO   ] [__main__            ] [main:120] Headless mode not fully implemented for this option
2025-05-15 04:20:02 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:20:03 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:20:05 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:20:05 [INFO   ] [__main__            ] [run_feature_mismatch_test:31] Running feature mismatch test
2025-05-15 04:20:05 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 04:20:05 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 04:20:05 [INFO   ] [__main__            ] [run_feature_mismatch_test:60] Feature mismatch test passed: Successfully made predictions with mismatched features
2025-05-15 04:27:03 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 04:27:03 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 04:27:03 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 04:27:05 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:27:05 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 04:27:05 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 04:27:05 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 04:27:05 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 04:27:05 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 04:27:05 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 04:27:05 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 04:27:05 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 04:27:05 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:27:05 [INFO   ] [src.core.engine     ] [_load_ai_model:93] AI Anomaly Detection model and scaler loaded from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 04:27:11 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:27:12 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:27:12 [ERROR  ] [__main__            ] [main:116] PCAP file not found: nonexistent_file.pcap
2025-05-15 04:27:14 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:27:14 [ERROR  ] [__main__            ] [main:110] --live and --file options cannot be used together
2025-05-15 04:27:15 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:27:15 [INFO   ] [__main__            ] [main:120] Headless mode not fully implemented for this option
2025-05-15 04:27:17 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-15 04:27:17 [INFO   ] [__main__            ] [run_feature_mismatch_test:31] Running feature mismatch test
2025-05-15 04:27:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: data/models/ai_anomaly_detector.joblib
2025-05-15 04:27:17 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: data/models/ai_anomaly_detector_scaler.joblib
2025-05-15 04:27:17 [INFO   ] [__main__            ] [run_feature_mismatch_test:60] Feature mismatch test passed: Successfully made predictions with mismatched features
2025-05-15 18:47:25 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 18:47:25 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-15 18:47:25 [INFO   ] [src.core.engine     ] [_load_analyzers:78] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 18:47:25 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 18:47:25 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 18:47:25 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 18:47:25 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 18:47:25 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 18:47:25 [INFO   ] [src.core.engine     ] [_ensure_model_dir_exists:84] Created directory for AI model: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models
2025-05-15 18:47:25 [INFO   ] [src.core.engine     ] [_load_ai_model:95] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 18:48:23 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:192] Created directory: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures
2025-05-15 18:48:23 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:23 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 18:48:23 [INFO   ] [src.core.engine     ] [run_live_capture:174] Starting live capture run: interface=Wi-Fi 2, count=30, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap'
2025-05-15 18:48:23 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=30, timeout=None, filter='None')
2025-05-15 18:48:26 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [run_live_capture:191] Writing 30 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:26 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 30 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:26 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:26 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap size: 3347 bytes.
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [run_live_capture:196] Live capture run finished.
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 18:48:26 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_184826.json
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 30
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T18:48:24.070737
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T18:48:26.201639
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 2.130902
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 14.08
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     UDP: 11
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     OTHER: 12
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 6
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     ICMP: 1
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     10.203.146.75: 11
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     66.110.49.115: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     168.176.5.11: 2
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     8.8.8.8: 2
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     10.203.146.75: 7
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     66.110.49.115: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     8.8.8.8: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     224.0.0.251: 2
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     168.176.5.11: 2
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     53: 4
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     57415: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     5353: 2
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     49676: 1
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     53: 4
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     57415: 3
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     5353: 2
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:235]     1900: 1
2025-05-15 18:48:26 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 12
2025-05-15 18:48:56 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:56 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [run_from_pcap:200] Starting PCAP file run: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:56 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:56 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 30 packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [run_from_pcap:212] PCAP file run finished for C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap.
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:217] Finalizing run...
2025-05-15 18:48:56 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_184856.json
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:230] Final Statistics (also included in reports):
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   total_packets: 30
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   start_time: 2025-05-15T18:48:56.617848
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   end_time: 2025-05-15T18:48:56.629385
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   duration_seconds: 0.011537
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   packets_per_second: 2600.33
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   protocol_distribution:
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     UDP: 11
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     OTHER: 12
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     TCP: 6
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     ICMP: 1
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ips:
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     10.203.146.75: 11
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     66.110.49.115: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     168.176.5.11: 2
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     8.8.8.8: 2
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ips:
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     10.203.146.75: 7
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     66.110.49.115: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     8.8.8.8: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     224.0.0.251: 2
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     168.176.5.11: 2
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_source_ports:
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     53: 4
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     57415: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     5353: 2
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     49676: 1
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   top_destination_ports:
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     53: 4
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     443: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     57415: 3
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     5353: 2
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:235]     1900: 1
2025-05-15 18:48:56 [INFO   ] [src.core.engine     ] [_finalize_run:232]   error_count: 12
2025-05-15 18:49:24 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap
2025-05-15 18:49:24 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:438] Starting AI anomaly model training process...
2025-05-15 18:49:24 [INFO   ] [src.core.engine     ] [_read_packets_for_training:429] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\test_for_teacher.pcap for training.
2025-05-15 18:49:24 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:468] Extracting features from 30 packets for training.
2025-05-15 18:49:25 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 30 packets. DataFrame shape: (30, 51)
2025-05-15 18:49:25 [ERROR  ] [src.core.engine     ] [train_ai_anomaly_model:488] AI model training/saving error: AnomalyDetector.train_model() missing 2 required positional arguments: 'model_save_path' and 'scaler_save_path'
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 478, in train_ai_anomaly_model
    self.ai_anomaly_detector.train_model(features_df_normal)
TypeError: AnomalyDetector.train_model() missing 2 required positional arguments: 'model_save_path' and 'scaler_save_path'
2025-05-15 18:53:09 [INFO   ] [src.core.engine     ] [shutdown:494] Shutting down Analysis Engine...
2025-05-15 18:53:09 [INFO   ] [src.core.engine     ] [shutdown:506] Analysis Engine shut down successfully.
2025-05-15 18:53:09 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:04:16 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:04:16 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:04:16 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:04:16 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:04:16 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:04:16 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:04:16 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:04:16 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:04:16 [INFO   ] [src.core.engine     ] [_load_ai_model:94] No pre-trained AI Anomaly Detection model found at C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib or model file is empty. Model will need training.
2025-05-15 19:04:56 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_1.pcap
2025-05-15 19:04:56 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:04:56 [INFO   ] [src.core.engine     ] [run_live_capture:180] Starting live capture run: interface=Wi-Fi 2, count=50, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_1.pcap'
2025-05-15 19:04:56 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=50, timeout=None, filter='None')
2025-05-15 19:05:00 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [run_live_capture:197] Writing 50 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_1.pcap
2025-05-15 19:05:00 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 50 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_1.pcap
2025-05-15 19:05:00 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_1.pcap
2025-05-15 19:05:00 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_1.pcap size: 3876 bytes.
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [run_live_capture:202] Live capture run finished.
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:223] Finalizing run...
2025-05-15 19:05:00 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_190500.json
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:236] Final Statistics (also included in reports):
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   total_packets: 50
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   start_time: 2025-05-15T19:04:56.081858
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   end_time: 2025-05-15T19:05:00.795355
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   duration_seconds: 4.713497
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   packets_per_second: 10.61
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   protocol_distribution:
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     OTHER: 39
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     TCP: 10
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     UDP: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   packet_type_distribution:
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     Ethernet: 50
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_source_ips:
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     10.203.146.75: 6
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     66.110.49.114: 3
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     142.251.133.106: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     66.110.49.116: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_destination_ips:
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     10.203.146.75: 5
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     66.110.49.114: 3
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     239.255.255.250: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     142.251.133.106: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     66.110.49.116: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_source_ports:
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     443: 5
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     59946: 3
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     49676: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     57208: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     60096: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_destination_ports:
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     443: 5
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     59946: 3
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     1900: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     57208: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:241]     60096: 1
2025-05-15 19:05:00 [INFO   ] [src.core.engine     ] [_finalize_run:238]   error_count: 39
2025-05-15 19:05:20 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:05:20 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:05:20 [INFO   ] [src.core.engine     ] [run_live_capture:180] Starting live capture run: interface=Wi-Fi 2, count=100, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap'
2025-05-15 19:05:20 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=100, timeout=None, filter='None')
2025-05-15 19:05:28 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [run_live_capture:197] Writing 100 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:05:28 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 100 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:05:28 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:05:28 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap size: 8395 bytes.
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [run_live_capture:202] Live capture run finished.
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:223] Finalizing run...
2025-05-15 19:05:28 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_190528.json
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:236] Final Statistics (also included in reports):
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   total_packets: 100
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   start_time: 2025-05-15T19:05:20.356013
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   end_time: 2025-05-15T19:05:28.855260
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   duration_seconds: 8.499247
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   packets_per_second: 11.77
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   protocol_distribution:
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     OTHER: 91
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     UDP: 2
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     TCP: 7
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   packet_type_distribution:
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     Ethernet: 100
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_source_ips:
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     10.203.146.75: 5
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     142.250.78.42: 3
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     8.8.4.4: 1
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_destination_ips:
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     10.203.146.75: 4
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     239.255.255.250: 2
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     142.250.78.42: 2
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     8.8.4.4: 1
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_source_ports:
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     443: 4
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     49676: 2
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     59963: 2
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     60052: 1
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_destination_ports:
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     443: 3
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     59963: 3
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     1900: 2
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:241]     60052: 1
2025-05-15 19:05:28 [INFO   ] [src.core.engine     ] [_finalize_run:238]   error_count: 91
2025-05-15 19:05:42 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:444] Starting AI anomaly model training process...
2025-05-15 19:05:42 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:461] Using current session data (assumed normal) for training.
2025-05-15 19:05:42 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:474] Extracting features from 100 packets for training.
2025-05-15 19:05:42 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 100 packets. DataFrame shape: (100, 51)
2025-05-15 19:05:42 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 19:05:43 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 19:05:43 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:05:43 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:05:43 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:489] AI Anomaly Detector trained successfully.
2025-05-15 19:06:47 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:06:47 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:444] Starting AI anomaly model training process...
2025-05-15 19:06:47 [INFO   ] [src.core.engine     ] [_read_packets_for_training:435] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap for training.
2025-05-15 19:06:47 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:474] Extracting features from 100 packets for training.
2025-05-15 19:06:47 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 100 packets. DataFrame shape: (100, 51)
2025-05-15 19:06:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 19:06:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 19:06:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:06:47 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:06:47 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:489] AI Anomaly Detector trained successfully.
2025-05-15 19:07:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:07:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [run_from_pcap:206] Starting PCAP file run: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:07:06 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:07:06 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 100 packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [run_from_pcap:218] PCAP file run finished for C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train_2.pcap.
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:223] Finalizing run...
2025-05-15 19:07:06 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_190706.json
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:236] Final Statistics (also included in reports):
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   total_packets: 100
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   start_time: 2025-05-15T19:07:06.072710
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   end_time: 2025-05-15T19:07:06.086954
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   duration_seconds: 0.014244
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   packets_per_second: 7020.5
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   protocol_distribution:
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     OTHER: 91
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     UDP: 2
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     TCP: 7
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   packet_type_distribution:
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     Ethernet: 100
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_source_ips:
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     10.203.146.75: 5
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     142.250.78.42: 3
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     8.8.4.4: 1
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_destination_ips:
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     10.203.146.75: 4
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     239.255.255.250: 2
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     142.250.78.42: 2
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     8.8.4.4: 1
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_source_ports:
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     443: 4
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     49676: 2
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     59963: 2
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     60052: 1
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   top_destination_ports:
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     443: 3
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     59963: 3
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     1900: 2
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:241]     60052: 1
2025-05-15 19:07:06 [INFO   ] [src.core.engine     ] [_finalize_run:238]   error_count: 91
2025-05-15 19:07:12 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:265] Starting AI analysis on 100 processed packets' original data.
2025-05-15 19:07:12 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:273] Extracting features from 100 packets for AI...
2025-05-15 19:07:12 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 100 packets. DataFrame shape: (100, 51)
2025-05-15 19:07:12 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:281] AI Feature extraction complete. Shape: (100, 51)
2025-05-15 19:07:12 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 100 samples.
2025-05-15 19:07:12 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:418] AI analysis on session data completed and results structured.
2025-05-15 19:12:58 [INFO   ] [src.core.engine     ] [shutdown:501] Shutting down Analysis Engine...
2025-05-15 19:12:58 [INFO   ] [src.core.engine     ] [shutdown:513] Analysis Engine shut down successfully.
2025-05-15 19:12:58 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:13:02 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:13:02 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:13:02 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:13:02 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:13:02 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:13:02 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:13:02 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:13:02 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:13:02 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:13:02 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:13:02 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:13:26 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:13:26 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [run_live_capture:194] Starting live capture run: interface=Wi-Fi, count=200, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap'
2025-05-15 19:13:26 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi (count=200, timeout=None, filter='None')
2025-05-15 19:13:26 [ERROR  ] [src.capture.frame_capture] [start_capture:53] Error during synchronous packet capture: Interface 'Wi-Fi' not found !
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\capture\frame_capture.py", line 50, in start_capture
    sniff(**kwargs)
  File "C:\Users\juanc\Documents\Redes Unal\venv\lib\site-packages\scapy\sendrecv.py", line 1424, in sniff
    sniffer._run(*args, **kwargs)
  File "C:\Users\juanc\Documents\Redes Unal\venv\lib\site-packages\scapy\sendrecv.py", line 1273, in _run
    sniff_sockets[_RL2(iface)(type=ETH_P_ALL, iface=iface,
  File "C:\Users\juanc\Documents\Redes Unal\venv\lib\site-packages\scapy\sendrecv.py", line 1258, in <lambda>
    _RL2 = lambda i: L2socket or resolve_iface(i).l2listen()  # type: Callable[[_GlobInterfaceType], Callable[..., SuperSocket]]  # noqa: E501
  File "C:\Users\juanc\Documents\Redes Unal\venv\lib\site-packages\scapy\interfaces.py", line 434, in resolve_iface
    return resolve_iface(dev, retry=False)
  File "C:\Users\juanc\Documents\Redes Unal\venv\lib\site-packages\scapy\interfaces.py", line 431, in resolve_iface
    raise ValueError("Interface '%s' not found !" % dev)
ValueError: Interface 'Wi-Fi' not found !
2025-05-15 19:13:26 [WARNING] [src.core.engine     ] [run_live_capture:214] No packets were captured. PCAP file 'C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap' will not be written.
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [run_live_capture:216] Live capture run finished.
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:13:26 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_191326.json
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 0
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: None
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: None
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 0
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 0
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:13:26 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 0
2025-05-15 19:13:46 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:13:46 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:13:46 [INFO   ] [src.core.engine     ] [run_live_capture:194] Starting live capture run: interface=Wi-Fi 2, count=200, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap'
2025-05-15 19:13:46 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=200, timeout=None, filter='None')
2025-05-15 19:13:51 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [run_live_capture:211] Writing 200 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:13:51 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 200 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:13:51 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:13:51 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap size: 33817 bytes.
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [run_live_capture:216] Live capture run finished.
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:13:51 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_191351.json
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 200
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:13:46.161781
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:13:51.455821
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 5.29404
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 37.78
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 155
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 39
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 5
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     IP Protocol 2: 1
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 200
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 82
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 31
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.115: 22
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.116: 8
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.169.174.231: 6
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 79
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 21
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.115: 20
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.169.174.231: 10
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.116: 9
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 77
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60572: 19
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60558: 11
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60559: 9
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60560: 9
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 78
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60572: 29
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60558: 13
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60559: 9
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60560: 8
2025-05-15 19:13:51 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 39
2025-05-15 19:15:06 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:15:06 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:458] Starting AI anomaly model training process...
2025-05-15 19:15:06 [INFO   ] [src.core.engine     ] [_read_packets_for_training:449] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap for training.
2025-05-15 19:15:06 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:488] Extracting features from 200 packets for training.
2025-05-15 19:15:06 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 200 packets. DataFrame shape: (200, 51)
2025-05-15 19:15:06 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 19:15:06 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 19:15:06 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:15:06 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:15:06 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:503] AI Anomaly Detector trained successfully.
2025-05-15 19:15:14 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:15:14 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [run_from_pcap:220] Starting PCAP file run: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:15:14 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:15:14 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 200 packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [run_from_pcap:232] PCAP file run finished for C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap.
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:15:14 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_191514.json
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 200
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:15:14.105840
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:15:14.255596
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 0.149756
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 1335.51
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 121
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 77
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 2
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 200
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 31
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.115: 22
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.116: 8
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.169.174.231: 6
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.189.173.12: 2
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 79
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 77
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     53: 2
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60572: 29
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60558: 13
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60559: 9
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60560: 8
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60342: 5
2025-05-15 19:15:14 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 121
2025-05-15 19:15:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:279] Starting AI analysis on 200 processed packets' original data.
2025-05-15 19:15:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:287] Extracting features from 200 packets for AI...
2025-05-15 19:15:31 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:203] Extracted features for 200 packets. DataFrame shape: (200, 51)
2025-05-15 19:15:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:295] AI Feature extraction complete. Shape: (200, 51)
2025-05-15 19:15:31 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 200 samples.
2025-05-15 19:15:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:432] AI analysis on session data completed and results structured.
2025-05-15 19:18:59 [INFO   ] [src.core.engine     ] [shutdown:515] Shutting down Analysis Engine...
2025-05-15 19:18:59 [INFO   ] [src.core.engine     ] [shutdown:527] Analysis Engine shut down successfully.
2025-05-15 19:18:59 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:22:35 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:22:35 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:22:35 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:22:35 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:22:35 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:22:35 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:22:35 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:22:35 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:22:36 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:22:36 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:22:36 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:23:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:23:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [run_from_pcap:220] Starting PCAP file run: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:23:06 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:120] Critical error in _determine_packet_type_and_analyze for packet: 'EDecimal' object cannot be interpreted as an integer
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 117, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\core\engine.py", line 179, in _determine_packet_type_and_analyze
    wifi_analysis = self.analyzers["wifi"].analyze_packet(packet, analysis_results)
  File "C:\Users\juanc\Documents\Redes Unal\Networking_tester\src\analysis\ieee802_11_analyzer.py", line 131, in analyze_packet
    'timestamp': datetime.fromtimestamp(packet.time).strftime('%Y-%m-%d %H:%M:%S.%f') if hasattr(packet, 'time') else datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f'),
TypeError: 'EDecimal' object cannot be interpreted as an integer
2025-05-15 19:23:06 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 200 packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [run_from_pcap:232] PCAP file run finished for C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train3.pcap.
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:23:06 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_192306.json
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 200
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:23:06.292800
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:23:06.474559
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 0.181759
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 1100.36
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 121
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 77
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 2
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 200
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 31
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.115: 22
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     66.110.49.116: 8
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.169.174.231: 6
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.189.173.12: 2
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 79
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 77
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     53: 2
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60572: 29
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60558: 13
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60559: 9
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60560: 8
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60342: 5
2025-05-15 19:23:06 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 121
2025-05-15 19:24:43 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:24:43 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:24:43 [INFO   ] [src.core.engine     ] [run_live_capture:194] Starting live capture run: interface=Wi-Fi 2, count=200, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap'
2025-05-15 19:24:43 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=200, timeout=None, filter='None')
2025-05-15 19:25:04 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:25:04 [INFO   ] [src.core.engine     ] [run_live_capture:211] Writing 200 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:25:04 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 200 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:25:05 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:25:05 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap size: 30740 bytes.
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [run_live_capture:216] Live capture run finished.
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:25:05 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_192505.json
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 200
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:24:43.625426
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:25:04.924032
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 21.298606
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 9.39
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 141
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 8
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 51
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 200
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 31
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     13.107.5.93: 14
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.189.172.32: 8
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 2
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.106: 1
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 28
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     13.107.5.93: 11
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     20.189.172.32: 10
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     239.255.255.250: 4
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 2
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 26
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61056: 11
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61059: 10
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     49676: 4
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     53: 2
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 25
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61056: 14
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61059: 8
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     1900: 4
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:255]     53: 2
2025-05-15 19:25:05 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 141
2025-05-15 19:29:38 [INFO   ] [src.core.engine     ] [shutdown:515] Shutting down Analysis Engine...
2025-05-15 19:29:38 [INFO   ] [src.core.engine     ] [shutdown:527] Analysis Engine shut down successfully.
2025-05-15 19:29:38 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:29:41 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:29:41 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:29:41 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:29:41 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:29:41 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:29:41 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:29:41 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:29:41 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:29:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:29:41 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:29:41 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:29:54 [INFO   ] [src.ui.menu_handler ] [run_main_loop:427] \nNetworking Tester interrupted by user (Ctrl+C). Exiting now.
2025-05-15 19:29:54 [INFO   ] [src.core.engine     ] [shutdown:515] Shutting down Analysis Engine...
2025-05-15 19:29:54 [INFO   ] [src.core.engine     ] [shutdown:527] Analysis Engine shut down successfully.
2025-05-15 19:29:54 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:29:57 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:29:57 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:29:57 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:29:57 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:29:57 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:29:57 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:29:57 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:29:57 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:29:57 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:29:57 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:29:57 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:30:39 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:30:39 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:30:39 [INFO   ] [src.core.engine     ] [run_live_capture:194] Starting live capture run: interface=Wi-Fi 2, count=400, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap'
2025-05-15 19:30:39 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=400, timeout=None, filter='None')
2025-05-15 19:31:03 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [run_live_capture:211] Writing 400 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:31:03 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 400 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:31:03 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:31:03 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap size: 69544 bytes.
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [run_live_capture:216] Live capture run finished.
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:31:03 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_193103.json
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 400
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:30:39.368749
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:31:03.532927
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 24.164178
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 16.55
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 249
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 103
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 48
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 400
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 108
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.138: 15
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.78.10: 14
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.106: 8
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 2
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 43
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     224.0.0.251: 40
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.138: 15
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.106: 14
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.78.10: 12
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 41
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     5353: 40
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60425: 9
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60770: 9
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61373: 8
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 62
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     5353: 40
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60652: 8
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61373: 8
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61374: 7
2025-05-15 19:31:03 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 249
2025-05-15 19:32:24 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:240] Attempting to read PCAP from default location: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:32:24 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:254] Analyzing PCAP file: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:32:24 [INFO   ] [src.core.engine     ] [run_from_pcap:220] Starting PCAP file run: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:32:24 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:32:25 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 400 packets from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [run_from_pcap:232] PCAP file run finished for C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap.
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:32:25 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_193225.json
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 400
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:32:24.936723
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:32:25.014716
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 0.077993
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 5128.67
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 249
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 103
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 48
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 400
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 108
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.138: 15
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.78.10: 14
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.106: 8
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.8.8: 2
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 43
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     224.0.0.251: 40
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.138: 15
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.218.106: 14
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.78.10: 12
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 41
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     5353: 40
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60425: 9
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60770: 9
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61373: 8
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 62
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     5353: 40
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     60652: 8
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61373: 8
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61374: 7
2025-05-15 19:32:25 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 249
2025-05-15 19:33:08 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:368] Attempting to use PCAP from default location for training: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap
2025-05-15 19:33:08 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:458] Starting AI anomaly model training process...
2025-05-15 19:33:08 [INFO   ] [src.core.engine     ] [_read_packets_for_training:449] Reading packets directly using rdpcap from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train4.pcap for training.
2025-05-15 19:33:09 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:488] Extracting features from 400 packets for training.
2025-05-15 19:33:09 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 400 packets. DataFrame shape: (400, 51)
2025-05-15 19:33:09 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-15 19:33:09 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-15 19:33:09 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:33:09 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:33:09 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:503] AI Anomaly Detector trained successfully.
2025-05-15 19:33:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:279] Starting AI analysis on 400 processed packets' original data.
2025-05-15 19:33:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:287] Extracting features from 400 packets for AI...
2025-05-15 19:33:30 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 400 packets. DataFrame shape: (400, 51)
2025-05-15 19:33:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:295] AI Feature extraction complete. Shape: (400, 51)
2025-05-15 19:33:30 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 400 samples.
2025-05-15 19:33:30 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:432] AI analysis on session data completed and results structured.
2025-05-15 19:41:26 [INFO   ] [src.core.engine     ] [shutdown:515] Shutting down Analysis Engine...
2025-05-15 19:41:26 [INFO   ] [src.core.engine     ] [shutdown:527] Analysis Engine shut down successfully.
2025-05-15 19:41:26 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:45:59 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:45:59 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:45:59 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:45:59 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:45:59 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:45:59 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:45:59 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:45:59 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:45:59 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:45:59 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:45:59 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:46:08 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train5.pcap
2025-05-15 19:46:08 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:46:08 [INFO   ] [src.core.engine     ] [run_live_capture:194] Starting live capture run: interface=Wi-Fi 2, count=200, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train5.pcap'
2025-05-15 19:46:08 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=200, timeout=None, filter='None')
2025-05-15 19:46:24 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [run_live_capture:211] Writing 200 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train5.pcap
2025-05-15 19:46:24 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 200 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train5.pcap
2025-05-15 19:46:24 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train5.pcap
2025-05-15 19:46:24 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_train5.pcap size: 24779 bytes.
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [run_live_capture:216] Live capture run finished.
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:46:24 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_194624.json
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 200
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:46:08.547960
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:46:24.787378
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 16.239418
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 12.32
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 153
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     TCP: 25
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     UDP: 22
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 200
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 36
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.4.4: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     140.82.114.25: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     13.89.179.14: 1
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     142.250.78.42: 1
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     224.0.0.251: 20
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     10.203.146.75: 11
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     2.22.20.68: 3
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     8.8.4.4: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     239.255.255.250: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     5353: 20
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 11
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61945: 3
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     49676: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     57250: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     5353: 20
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     443: 14
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61864: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     1900: 2
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:255]     61884: 1
2025-05-15 19:46:24 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 153
2025-05-15 19:52:57 [INFO   ] [src.core.engine     ] [shutdown:515] Shutting down Analysis Engine...
2025-05-15 19:52:57 [INFO   ] [src.core.engine     ] [shutdown:527] Analysis Engine shut down successfully.
2025-05-15 19:52:57 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 19:56:05 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 19:56:05 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 19:56:05 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 19:56:05 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 19:56:05 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 19:56:05 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 19:56:05 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 19:56:05 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 19:56:05 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 19:56:05 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:56:05 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 19:56:32 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:194] Capture will be saved to: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_final.pcap
2025-05-15 19:56:32 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:196] Starting live capture on interface: Wi-Fi 2
2025-05-15 19:56:32 [INFO   ] [src.core.engine     ] [run_live_capture:194] Starting live capture run: interface=Wi-Fi 2, count=10, timeout=None, filter='None', write_to='C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_final.pcap'
2025-05-15 19:56:32 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Wi-Fi 2 (count=10, timeout=None, filter='None')
2025-05-15 19:56:33 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Wi-Fi 2.
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [run_live_capture:211] Writing 10 captured packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_final.pcap
2025-05-15 19:56:33 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_final.pcap
2025-05-15 19:56:33 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_final.pcap
2025-05-15 19:56:33 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\captures\data_final.pcap size: 604 bytes.
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [run_live_capture:216] Live capture run finished.
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:237] Finalizing run...
2025-05-15 19:56:33 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Redes Unal\Networking_tester\reports\capture_report_20250515_195633.json
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:250] Final Statistics (also included in reports):
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   total_packets: 10
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   start_time: 2025-05-15T19:56:32.371453
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   end_time: 2025-05-15T19:56:33.716424
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   duration_seconds: 1.344971
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packets_per_second: 7.44
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   protocol_distribution:
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:255]     OTHER: 10
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   packet_type_distribution:
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:255]     Ethernet: 10
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ips:
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ips:
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_source_ports:
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   top_destination_ports:
2025-05-15 19:56:33 [INFO   ] [src.core.engine     ] [_finalize_run:252]   error_count: 10
2025-05-15 19:58:41 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:279] Starting AI analysis on 10 processed packets' original data.
2025-05-15 19:58:41 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:287] Extracting features from 10 packets for AI...
2025-05-15 19:58:41 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 10 packets. DataFrame shape: (10, 51)
2025-05-15 19:58:41 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:295] AI Feature extraction complete. Shape: (10, 51)
2025-05-15 19:58:41 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 10 samples.
2025-05-15 19:58:41 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:432] AI analysis on session data completed and results structured.
2025-05-15 20:00:55 [INFO   ] [src.core.engine     ] [shutdown:515] Shutting down Analysis Engine...
2025-05-15 20:00:55 [INFO   ] [src.core.engine     ] [shutdown:527] Analysis Engine shut down successfully.
2025-05-15 20:00:55 [INFO   ] [src.ui.menu_handler ] [run_main_loop:431] Networking Tester finished.
2025-05-15 20:01:02 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Redes Unal\Networking_tester\logs\networking_tester.log
2025-05-15 20:01:02 [INFO   ] [src.core.engine     ] [__init__:31] Initializing AnalysisEngine...
2025-05-15 20:01:02 [INFO   ] [src.core.engine     ] [_load_analyzers:77] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-15 20:01:02 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-15 20:01:02 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-15 20:01:02 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-15 20:01:02 [INFO   ] [src.ai_monitoring.performance_analyzer_ml_simple] [__init__:20] PerformanceMLAnalyzer initialized.
2025-05-15 20:01:02 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-15 20:01:02 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-15 20:01:02 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-15 20:01:02 [INFO   ] [src.core.engine     ] [_load_ai_model:92] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Redes Unal\Networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:42:57 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 17:42:57 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 17:42:57 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 17:42:57 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 17:42:57 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 17:42:57 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 17:42:57 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 17:42:57 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 17:42:57 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 17:42:57 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:42:57 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:44:05 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:188] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\captura_para_el_profe.pcap
2025-05-17 17:44:05 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:190] Starting live capture on interface: Ethernet 2
2025-05-17 17:44:05 [INFO   ] [src.core.engine     ] [run_live_capture:199] Starting live capture run: interface=Ethernet 2, count=10, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\captura_para_el_profe.pcap'
2025-05-17 17:44:05 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=10, timeout=None, filter='None')
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:05 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:07 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:07 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:07 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 145, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:44:07 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [run_live_capture:217] Writing 10 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\captura_para_el_profe.pcap
2025-05-17 17:44:07 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 10 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\captura_para_el_profe.pcap
2025-05-17 17:44:07 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\captura_para_el_profe.pcap
2025-05-17 17:44:07 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\captura_para_el_profe.pcap size: 978 bytes.
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [run_live_capture:222] Live capture run finished.
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 17:44:07 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_174407.json
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 10
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T17:44:05.919170
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T17:44:07.158073
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 1.238903
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 8.07
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:263]     OTHER: 10
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 10
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 17:44:07 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 10
2025-05-17 17:46:16 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 17:46:16 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 17:46:16 [INFO   ] [src.ui.menu_handler ] [run_main_loop:420] Networking Tester finished.
2025-05-17 17:46:26 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 17:46:26 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 17:46:26 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 17:46:26 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 17:46:26 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 17:46:26 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 17:46:26 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 17:46:26 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 17:46:26 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 17:46:26 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:46:26 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:46:54 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:188] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test1.pcap
2025-05-17 17:46:54 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:190] Starting live capture on interface: Ethernet 2
2025-05-17 17:46:54 [INFO   ] [src.core.engine     ] [run_live_capture:199] Starting live capture run: interface=Ethernet 2, count=20, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test1.pcap'
2025-05-17 17:46:54 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=20, timeout=None, filter='None')
2025-05-17 17:46:58 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:58 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:58 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:59 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:59 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:59 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:59 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:46:59 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:02 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:02 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:03 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:03 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:03 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:03 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:03 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:04 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:04 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:04 [ERROR  ] [src.core.engine     ] [_process_packet_core_logic:125] Critical error in _determine_packet_type_and_analyze for packet: 'NoneType' object has no attribute 'get'
Traceback (most recent call last):
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 122, in _process_packet_core_logic
    detailed_analysis_results = self._determine_packet_type_and_analyze(packet)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\core\engine.py", line 182, in _determine_packet_type_and_analyze
    analysis_results['ethernet_details'] = self.analyzers["ethernet"].analyze_packet(packet, analysis_results)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\analysis\ieee802_3_analyzer.py", line 146, in analyze_packet
    "protocol_name": self.ethertype_map.get(ethertype_val, f"Unknown ({hex(ethertype_val)})"),
                     ^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'get'
2025-05-17 17:47:04 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [run_live_capture:217] Writing 20 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test1.pcap
2025-05-17 17:47:04 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 20 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test1.pcap
2025-05-17 17:47:04 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test1.pcap
2025-05-17 17:47:04 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test1.pcap size: 2087 bytes.
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [run_live_capture:222] Live capture run finished.
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 17:47:04 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_174704.json
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T17:46:55.293875
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T17:47:04.162094
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 8.868219
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 2.26
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:263]     OTHER: 20
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Other: 2
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 18
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 17:47:04 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 20
2025-05-17 17:50:21 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 17:50:21 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 17:50:21 [INFO   ] [src.ui.menu_handler ] [run_main_loop:420] Networking Tester finished.
2025-05-17 17:50:25 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 17:50:25 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 17:50:25 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 17:50:25 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 17:50:25 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 17:50:25 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 17:50:25 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 17:50:25 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 17:50:25 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 17:50:25 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 17:50:25 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:50:25 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:50:55 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:188] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:50:55 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:190] Starting live capture on interface: Ethernet 2
2025-05-17 17:50:55 [INFO   ] [src.core.engine     ] [run_live_capture:199] Starting live capture run: interface=Ethernet 2, count=20, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap'
2025-05-17 17:50:55 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=20, timeout=None, filter='None')
2025-05-17 17:50:57 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [run_live_capture:217] Writing 20 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:50:57 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 20 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:50:57 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:50:57 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap size: 10298 bytes.
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [run_live_capture:222] Live capture run finished.
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 17:50:57 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_175057.json
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T17:50:57.139406
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T17:50:57.564302
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 0.424896
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 47.07
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 2
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 18
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 11
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 8
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 10
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 10
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 10
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 8
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 17:50:57 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 17:53:50 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:288] Starting AI analysis on 20 processed packets' original data.
2025-05-17 17:53:50 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:296] Extracting features from 20 packets for AI...
2025-05-17 17:53:50 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 17:53:50 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:304] AI Feature extraction complete. Shape: (20, 51)
2025-05-17 17:53:50 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 20 samples.
2025-05-17 17:53:50 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:88] Performed basic performance feature analysis on 20 samples.
2025-05-17 17:53:50 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:408] AI analysis on session data completed and results structured.
2025-05-17 17:54:15 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:357] Attempting to use PCAP from default location for training: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:54:15 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:433] Starting AI anomaly model training process...
2025-05-17 17:54:15 [INFO   ] [src.core.engine     ] [_read_packets_for_training:424] Reading packets directly using rdpcap from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap for training.
2025-05-17 17:54:15 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:463] Extracting features from 20 packets for training.
2025-05-17 17:54:15 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 17:54:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-17 17:54:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-17 17:54:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 17:54:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 17:54:15 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:477] AI Anomaly Detector trained successfully.
2025-05-17 17:55:17 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:235] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:55:17 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:243] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [run_from_pcap:226] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:55:17 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:55:17 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 20 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [run_from_pcap:239] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap.
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 17:55:17 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_175517.json
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T17:55:17.270063
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T17:55:17.274554
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 0.004491
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 4453.35
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 2
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 18
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 11
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 8
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 10
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 10
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 10
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 8
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 17:55:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 17:55:56 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:288] Starting AI analysis on 20 processed packets' original data.
2025-05-17 17:55:56 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:296] Extracting features from 20 packets for AI...
2025-05-17 17:55:56 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 17:55:56 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:304] AI Feature extraction complete. Shape: (20, 51)
2025-05-17 17:55:56 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 20 samples.
2025-05-17 17:55:56 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:88] Performed basic performance feature analysis on 20 samples.
2025-05-17 17:55:56 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:408] AI analysis on session data completed and results structured.
2025-05-17 18:02:42 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 18:02:42 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 18:02:42 [INFO   ] [src.ui.menu_handler ] [run_main_loop:420] Networking Tester finished.
2025-05-17 18:02:53 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:02:53 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:02:53 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:02:53 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:02:53 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:02:53 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:02:53 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 18:02:53 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 18:02:53 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:02:53 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:02:53 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:02:53 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:03:05 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '2'
2025-05-17 18:03:17 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:235] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:03:17 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:243] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [run_from_pcap:226] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:03:17 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:03:17 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 20 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [run_from_pcap:239] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap.
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 18:03:17 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_180317.json
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T18:03:17.669897
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T18:03:17.674777
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 0.00488
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 4098.36
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 2
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 18
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 11
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 8
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 10
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 10
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 10
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 8
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:03:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 18:03:22 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 18:03:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:288] Starting AI analysis on 20 processed packets' original data.
2025-05-17 18:03:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:296] Extracting features from 20 packets for AI...
2025-05-17 18:03:22 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 18:03:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:304] AI Feature extraction complete. Shape: (20, 51)
2025-05-17 18:03:22 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 20 samples.
2025-05-17 18:03:22 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:88] Performed basic performance feature analysis on 20 samples.
2025-05-17 18:03:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:408] AI analysis on session data completed and results structured.
2025-05-17 18:03:53 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 18:03:53 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 18:03:53 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 18:03:53 [INFO   ] [src.ui.menu_handler ] [run_main_loop:441] Networking Tester finished.
2025-05-17 18:05:12 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:05:12 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:05:12 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:05:12 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:05:12 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:05:12 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:05:12 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 18:05:12 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 18:05:12 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:05:12 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:05:12 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:05:12 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:05:15 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '2'
2025-05-17 18:05:17 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:235] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:05:17 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:243] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [run_from_pcap:226] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:05:17 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:05:17 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 20 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [run_from_pcap:239] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap.
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 18:05:17 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_180517.json
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T18:05:17.939206
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T18:05:17.943912
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 0.004706
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 4249.89
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 2
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 18
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 11
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 8
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 10
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 10
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 10
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 8
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:05:17 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 18:05:22 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 18:05:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:288] Starting AI analysis on 20 processed packets' original data.
2025-05-17 18:05:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:296] Extracting features from 20 packets for AI...
2025-05-17 18:05:22 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 18:05:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:304] AI Feature extraction complete. Shape: (20, 51)
2025-05-17 18:05:22 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 20 samples.
2025-05-17 18:05:22 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:88] Performed basic performance feature analysis on 20 samples.
2025-05-17 18:05:22 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:408] AI analysis on session data completed and results structured.
2025-05-17 18:12:07 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 18:12:07 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 18:12:07 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 18:12:07 [INFO   ] [src.ui.menu_handler ] [run_main_loop:442] Networking Tester finished.
2025-05-17 18:12:10 [INFO   ] [networking_tester   ] [setup_logging:59] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:12:10 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:12:10 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:12:10 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:12:10 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:12:10 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:12:10 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 18:12:10 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 18:12:10 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:12:10 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:12:10 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:12:10 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:12:16 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '2'
2025-05-17 18:12:35 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:235] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:12:35 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:243] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [run_from_pcap:226] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:12:35 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:12:35 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 20 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [run_from_pcap:239] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap.
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 18:12:35 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_181235.json
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T18:12:35.106370
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T18:12:35.112636
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 0.006266
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 3191.83
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 2
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 18
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 11
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 8
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 10
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 10
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 10
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 8
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:12:35 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 18:12:52 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 18:12:52 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:288] Starting AI analysis on 20 processed packets' original data.
2025-05-17 18:12:52 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:296] Extracting features from 20 packets for AI...
2025-05-17 18:12:52 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 18:12:52 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:304] AI Feature extraction complete. Shape: (20, 51)
2025-05-17 18:12:52 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:112] Performed QoS analysis on 20 samples.
2025-05-17 18:12:52 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:88] Performed basic performance feature analysis on 20 samples.
2025-05-17 18:12:52 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:408] AI analysis on session data completed and results structured.
2025-05-17 18:14:44 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 18:14:44 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 18:14:44 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 18:14:44 [INFO   ] [src.ui.menu_handler ] [run_main_loop:472] Networking Tester finished.
2025-05-17 18:20:31 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:20:31 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:20:31 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:20:31 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:20:31 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:20:31 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:20:31 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:60] QoSMLAnalyzer initialized.
2025-05-17 18:20:31 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:22] PerformanceMLAnalyzer initialized.
2025-05-17 18:20:31 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:20:31 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:20:31 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:20:31 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:20:58 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '2'
2025-05-17 18:21:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:235] Attempting to read PCAP from default location: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:21:06 [INFO   ] [src.ui.menu_handler ] [handle_pcap_analysis:243] Analyzing PCAP file: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [run_from_pcap:226] Starting PCAP file run: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:21:06 [INFO   ] [src.capture.frame_capture] [read_pcap:58] Reading packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:21:06 [INFO   ] [src.capture.frame_capture] [read_pcap:70] Read and processed 20 packets from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [run_from_pcap:239] PCAP file run finished for c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test2.pcap.
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 18:21:06 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_182106.json
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T18:21:06.252999
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T18:21:06.257784
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 0.004785
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 4179.73
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 2
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 18
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 11
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 8
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52.182.143.208: 10
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 1
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 10
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 10
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     52983: 8
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53: 1
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:263]     65142: 1
2025-05-17 18:21:06 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 18:43:46 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 18:43:46 [INFO   ] [src.core.engine     ] [shutdown:489] Shutting down Analysis Engine...
2025-05-17 18:43:46 [INFO   ] [src.core.engine     ] [shutdown:501] Analysis Engine shut down successfully.
2025-05-17 18:43:46 [INFO   ] [src.ui.menu_handler ] [run_main_loop:472] Networking Tester finished.
2025-05-17 18:46:30 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:46:30 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:46:30 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:46:30 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:46:30 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:46:30 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:46:30 [ERROR  ] [src.ai_monitoring.qos_analyzer_ml] [__init__:70] Error loading QoS rules from config: type object 'ConfigManager' has no attribute 'get_setting'
2025-05-17 18:46:30 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:83] Using default 'ef_small_packet_concern' rules.
2025-05-17 18:46:30 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:96] QoSMLAnalyzer initialized.
2025-05-17 18:46:30 [ERROR  ] [src.ai_monitoring.performance_analyzer_ml] [__init__:28] Error loading performance rules from config: type object 'ConfigManager' has no attribute 'get_setting'
2025-05-17 18:46:30 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:48] PerformanceMLAnalyzer initialized.
2025-05-17 18:46:30 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:46:30 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:46:30 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:46:30 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:49:28 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '1'
2025-05-17 18:53:34 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:188] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap
2025-05-17 18:53:34 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:190] Starting live capture on interface: Ethernet 2
2025-05-17 18:53:34 [INFO   ] [src.core.engine     ] [run_live_capture:199] Starting live capture run: interface=Ethernet 2, count=20, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap'
2025-05-17 18:53:34 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=20, timeout=None, filter='None')
2025-05-17 18:53:39 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [run_live_capture:217] Writing 20 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap
2025-05-17 18:53:39 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 20 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap
2025-05-17 18:53:39 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap
2025-05-17 18:53:39 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap size: 2002 bytes.
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [run_live_capture:222] Live capture run finished.
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 18:53:39 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_185339.json
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 20
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T18:53:34.810968
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T18:53:39.358166
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 4.547198
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 4.4
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 19
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 1
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 20
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 9
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     92.122.157.40: 3
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.61: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.1: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     199.232.177.91: 1
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 10
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     92.122.157.40: 3
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.1: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.61: 1
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     199.232.177.91: 1
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54076: 3
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     5222: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53458: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53602: 1
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 8
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54076: 3
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53602: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     53458: 2
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:263]     5222: 1
2025-05-17 18:53:39 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 18:54:31 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 18:54:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:287] Starting AI analysis on 20 processed packets' original data.
2025-05-17 18:54:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:294] Extracting features from 20 packets for AI...
2025-05-17 18:54:31 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 18:54:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:301] AI Feature extraction complete. Shape: (20, 51)
2025-05-17 18:54:31 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:160] Performed QoS analysis on 20 samples.
2025-05-17 18:54:31 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:132] Performed performance feature analysis on 20 samples.
2025-05-17 18:54:31 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:439] AI analysis on session data completed and results structured.
2025-05-17 18:56:26 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '7'
2025-05-17 18:56:32 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:410] Attempting to use PCAP from default location for training: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap
2025-05-17 18:56:32 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:463] Starting AI anomaly model training process...
2025-05-17 18:56:32 [INFO   ] [src.core.engine     ] [_read_packets_for_training:454] Reading packets directly using rdpcap from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test3.pcap for training.
2025-05-17 18:56:32 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:493] Extracting features from 20 packets for training.
2025-05-17 18:56:32 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 20 packets. DataFrame shape: (20, 51)
2025-05-17 18:56:32 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-17 18:56:32 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-17 18:56:32 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:56:32 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:56:32 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:507] AI Anomaly Detector trained successfully.
2025-05-17 18:59:12 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 18:59:12 [INFO   ] [src.core.engine     ] [shutdown:519] Shutting down Analysis Engine...
2025-05-17 18:59:12 [INFO   ] [src.core.engine     ] [shutdown:531] Analysis Engine shut down successfully.
2025-05-17 18:59:12 [INFO   ] [src.ui.menu_handler ] [run_main_loop:483] Networking Tester finished.
2025-05-17 18:59:15 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:59:15 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:59:15 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:59:15 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:59:15 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:59:15 [WARNING] [src.utils.config_manager] [get:49] Config key part 'qos_rules' not found or parent is not a dict for key 'ai_monitoring_settings.qos_rules'.
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:67] Loaded QoS rules: {}
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:83] Using default 'ef_small_packet_concern' rules.
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:96] QoSMLAnalyzer initialized.
2025-05-17 18:59:15 [WARNING] [src.utils.config_manager] [get:49] Config key part 'performance_rules' not found or parent is not a dict for key 'ai_monitoring_settings.performance_rules'.
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:29] Loaded performance rules: {}
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:52] PerformanceMLAnalyzer initialized.
2025-05-17 18:59:15 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:59:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:59:15 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:59:17 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 18:59:17 [INFO   ] [src.core.engine     ] [shutdown:519] Shutting down Analysis Engine...
2025-05-17 18:59:17 [INFO   ] [src.core.engine     ] [shutdown:531] Analysis Engine shut down successfully.
2025-05-17 18:59:17 [INFO   ] [src.ui.menu_handler ] [run_main_loop:483] Networking Tester finished.
2025-05-17 18:59:21 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 18:59:21 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 18:59:21 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 18:59:21 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 18:59:21 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 18:59:21 [WARNING] [src.utils.config_manager] [get:49] Config key part 'qos_rules' not found or parent is not a dict for key 'ai_monitoring_settings.qos_rules'.
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:67] Loaded QoS rules: {}
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:83] Using default 'ef_small_packet_concern' rules.
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:96] QoSMLAnalyzer initialized.
2025-05-17 18:59:21 [WARNING] [src.utils.config_manager] [get:49] Config key part 'performance_rules' not found or parent is not a dict for key 'ai_monitoring_settings.performance_rules'.
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:29] Loaded performance rules: {}
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:52] PerformanceMLAnalyzer initialized.
2025-05-17 18:59:21 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 18:59:21 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 18:59:21 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:00:39 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 19:00:39 [INFO   ] [src.core.engine     ] [shutdown:519] Shutting down Analysis Engine...
2025-05-17 19:00:39 [INFO   ] [src.core.engine     ] [shutdown:531] Analysis Engine shut down successfully.
2025-05-17 19:00:39 [INFO   ] [src.ui.menu_handler ] [run_main_loop:483] Networking Tester finished.
2025-05-17 19:00:42 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 19:00:42 [INFO   ] [src.core.engine     ] [__init__:32] Initializing AnalysisEngine...
2025-05-17 19:00:42 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 19:00:42 [INFO   ] [src.core.engine     ] [_load_analyzers:82] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 19:00:42 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:68] Loaded QoS rules: {'ef_small_packet_concern': {'enabled': True, 'dscp_threshold': 46, 'frame_length_threshold': 100}}
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:97] QoSMLAnalyzer initialized.
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:30] Loaded performance rules: {'packet_size_categories': {'small_threshold': 100, 'medium_threshold': 1000}, 'protocol_insights': {'enabled': True}, 'small_packet_percentage_concern': {'enabled': True, 'threshold_percentage': 60, 'minimum_sample_size': 50}}
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:53] PerformanceMLAnalyzer initialized.
2025-05-17 19:00:42 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 19:00:42 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:00:42 [INFO   ] [src.core.engine     ] [_load_ai_model:97] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:00:57 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '1'
2025-05-17 19:01:17 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:188] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap
2025-05-17 19:01:17 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:190] Starting live capture on interface: Ethernet 2
2025-05-17 19:01:17 [INFO   ] [src.core.engine     ] [run_live_capture:199] Starting live capture run: interface=Ethernet 2, count=40, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap'
2025-05-17 19:01:17 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=40, timeout=None, filter='None')
2025-05-17 19:01:21 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [run_live_capture:217] Writing 40 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap
2025-05-17 19:01:21 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 40 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap
2025-05-17 19:01:21 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap
2025-05-17 19:01:21 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap size: 14723 bytes.
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [run_live_capture:222] Live capture run finished.
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:244] Finalizing run...
2025-05-17 19:01:21 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_190121.json
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:258] Final Statistics (also included in reports):
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   total_packets: 40
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   start_time: 2025-05-17T19:01:18.680763
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   end_time: 2025-05-17T19:01:21.704764
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   duration_seconds: 3.024001
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packets_per_second: 13.23
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   protocol_distribution:
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     TCP: 35
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     UDP: 5
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   packet_type_distribution:
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     Ethernet: 40
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ips:
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 19
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.21: 7
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     20.42.73.28: 5
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.1: 4
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 2
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ips:
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.5: 20
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.21: 6
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     20.42.73.28: 5
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     163.70.152.1: 4
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     192.168.0.1: 2
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_source_ports:
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 18
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     51059: 6
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54233: 5
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54005: 2
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54004: 2
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   top_destination_ports:
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     443: 17
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     51059: 7
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54233: 5
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54004: 2
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:263]     54005: 2
2025-05-17 19:01:21 [INFO   ] [src.core.engine     ] [_finalize_run:260]   error_count: 0
2025-05-17 19:01:34 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 19:01:34 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:287] Starting AI analysis on 40 processed packets' original data.
2025-05-17 19:01:34 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:294] Extracting features from 40 packets for AI...
2025-05-17 19:01:34 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 40 packets. DataFrame shape: (40, 51)
2025-05-17 19:01:34 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:301] AI Feature extraction complete. Shape: (40, 51)
2025-05-17 19:01:34 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:161] Performed QoS analysis on 40 samples.
2025-05-17 19:01:34 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:137] Performed performance feature analysis on 40 samples.
2025-05-17 19:01:34 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:439] AI analysis on session data completed and results structured.
2025-05-17 19:03:20 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '7'
2025-05-17 19:03:28 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:410] Attempting to use PCAP from default location for training: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap
2025-05-17 19:03:28 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:463] Starting AI anomaly model training process...
2025-05-17 19:03:28 [INFO   ] [src.core.engine     ] [_read_packets_for_training:454] Reading packets directly using rdpcap from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test5.pcap for training.
2025-05-17 19:03:28 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:493] Extracting features from 40 packets for training.
2025-05-17 19:03:28 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 40 packets. DataFrame shape: (40, 51)
2025-05-17 19:03:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-17 19:03:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-17 19:03:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 19:03:28 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:03:28 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:507] AI Anomaly Detector trained successfully.
2025-05-17 19:03:36 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 19:03:36 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:287] Starting AI analysis on 40 processed packets' original data.
2025-05-17 19:03:36 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:294] Extracting features from 40 packets for AI...
2025-05-17 19:03:36 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 40 packets. DataFrame shape: (40, 51)
2025-05-17 19:03:36 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:301] AI Feature extraction complete. Shape: (40, 51)
2025-05-17 19:03:36 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:161] Performed QoS analysis on 40 samples.
2025-05-17 19:03:36 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:137] Performed performance feature analysis on 40 samples.
2025-05-17 19:03:36 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:439] AI analysis on session data completed and results structured.
2025-05-17 19:07:45 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 19:07:45 [INFO   ] [src.core.engine     ] [shutdown:519] Shutting down Analysis Engine...
2025-05-17 19:07:45 [INFO   ] [src.core.engine     ] [shutdown:531] Analysis Engine shut down successfully.
2025-05-17 19:07:45 [INFO   ] [src.ui.menu_handler ] [run_main_loop:483] Networking Tester finished.
2025-05-17 19:09:16 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-17 19:09:16 [INFO   ] [src.core.engine     ] [__init__:33] Initializing AnalysisEngine...
2025-05-17 19:09:16 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-17 19:09:16 [INFO   ] [src.core.engine     ] [_load_analyzers:83] Loaded 5 standard analyzers: ['ProtocolAnalyzer', 'IEEE802_11_Analyzer', 'IEEE802_3_Analyzer', 'FlowAnalyzer', 'RuleBasedAnomalyDetector']
2025-05-17 19:09:16 [INFO   ] [src.storage.database_handler] [__init__:26] DatabaseHandler is disabled by configuration.
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.feature_extractor] [__init__:17] PacketFeatureExtractor initialized.
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:68] Loaded QoS rules: {'ef_small_packet_concern': {'enabled': True, 'dscp_threshold': 46, 'frame_length_threshold': 100}}
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [__init__:97] QoSMLAnalyzer initialized.
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:30] Loaded performance rules: {'packet_size_categories': {'small_threshold': 100, 'medium_threshold': 1000}, 'protocol_insights': {'enabled': True}, 'small_packet_percentage_concern': {'enabled': True, 'threshold_percentage': 60, 'minimum_sample_size': 50}}
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [__init__:53] PerformanceMLAnalyzer initialized.
2025-05-17 19:09:16 [WARNING] [src.ai_monitoring.anomaly_detector] [__init__:28] AnomalyDetector: Model path 'None' not provided or not found. Anomaly detection will not be performed unless a model is loaded or trained.
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:37] AnomalyDetector model loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 19:09:16 [INFO   ] [src.ai_monitoring.anomaly_detector] [load_model:42] Scaler loaded from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:09:16 [INFO   ] [src.core.engine     ] [_load_ai_model:98] AI Anomaly Detection model and scaler loaded from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib and C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:09:30 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '1'
2025-05-17 19:09:39 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:188] Capture will be saved to: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap
2025-05-17 19:09:39 [INFO   ] [src.ui.menu_handler ] [handle_live_capture:190] Starting live capture on interface: Ethernet 2
2025-05-17 19:09:39 [INFO   ] [src.core.engine     ] [run_live_capture:200] Starting live capture run: interface=Ethernet 2, count=200, timeout=None, filter='None', write_to='c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap'
2025-05-17 19:09:39 [INFO   ] [src.capture.frame_capture] [start_capture:42] Starting synchronous capture on interface Ethernet 2 (count=200, timeout=None, filter='None')
2025-05-17 19:09:55 [INFO   ] [src.capture.frame_capture] [start_capture:51] Synchronous capture finished on Ethernet 2.
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [run_live_capture:218] Writing 200 captured packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap
2025-05-17 19:09:55 [INFO   ] [src.capture.frame_capture] [write_pcap:89] Writing 200 packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap
2025-05-17 19:09:55 [INFO   ] [src.capture.frame_capture] [write_pcap:91] Successfully wrote packets to c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap
2025-05-17 19:09:55 [INFO   ] [src.capture.frame_capture] [write_pcap:96] PCAP file c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap size: 60191 bytes.
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [run_live_capture:223] Live capture run finished.
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:245] Finalizing run...
2025-05-17 19:09:55 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250517_190955.json
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:259] Final Statistics (also included in reports):
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   total_packets: 200
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   start_time: 2025-05-17T19:09:39.377735
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   end_time: 2025-05-17T19:09:55.758905
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   duration_seconds: 16.38117
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   packets_per_second: 12.21
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   protocol_distribution:
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     TCP: 179
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     UDP: 18
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     OTHER: 2
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     ICMP: 1
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   packet_type_distribution:
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     Ethernet: 200
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   top_source_ips:
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     192.168.0.5: 95
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     20.189.172.76: 22
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     163.70.152.21: 11
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     192.168.0.1: 9
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     142.250.218.110: 8
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   top_destination_ips:
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     192.168.0.5: 100
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     20.189.172.76: 20
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     163.70.152.21: 12
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     142.251.132.106: 8
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     192.168.0.1: 7
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   top_source_ports:
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     443: 91
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     51059: 12
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     54363: 10
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     54365: 10
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     53: 9
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   top_destination_ports:
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     443: 88
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     54363: 11
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     54365: 11
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     51059: 11
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:264]     54366: 7
2025-05-17 19:09:55 [INFO   ] [src.core.engine     ] [_finalize_run:261]   error_count: 2
2025-05-17 19:10:09 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '7'
2025-05-17 19:10:15 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:324] Attempting to use PCAP from default location for training: c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap
2025-05-17 19:10:15 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:484] Starting AI anomaly model training process...
2025-05-17 19:10:15 [INFO   ] [src.core.engine     ] [_read_packets_for_training:475] Reading packets directly using rdpcap from c:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test6.pcap for training.
2025-05-17 19:10:15 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:514] Extracting features from 200 packets for training.
2025-05-17 19:10:15 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 200 packets. DataFrame shape: (200, 51)
2025-05-17 19:10:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:163] Training anomaly detector model...
2025-05-17 19:10:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:168] AnomalyDetector model training completed.
2025-05-17 19:10:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:176] Model saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector.joblib
2025-05-17 19:10:15 [INFO   ] [src.ai_monitoring.anomaly_detector] [train_model:182] Scaler saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\models\ai_anomaly_detector_scaler.joblib
2025-05-17 19:10:15 [INFO   ] [src.core.engine     ] [train_ai_anomaly_model:528] AI Anomaly Detector trained successfully.
2025-05-17 19:10:26 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '6'
2025-05-17 19:10:26 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:288] Starting AI analysis on 200 processed packets' original data.
2025-05-17 19:10:26 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:295] Extracting features from 200 packets for AI...
2025-05-17 19:10:26 [INFO   ] [src.ai_monitoring.feature_extractor] [extract_features_to_dataframe:221] Extracted features for 200 packets. DataFrame shape: (200, 51)
2025-05-17 19:10:26 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:302] AI Feature extraction complete. Shape: (200, 51)
2025-05-17 19:10:26 [INFO   ] [src.ai_monitoring.qos_analyzer_ml] [analyze_qos_features:161] Performed QoS analysis on 200 samples.
2025-05-17 19:10:26 [INFO   ] [src.ai_monitoring.performance_analyzer_ml] [analyze_performance_features:137] Performed performance feature analysis on 200 samples.
2025-05-17 19:10:26 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:440] AI analysis on session data completed and results structured.
2025-05-17 19:10:26 [INFO   ] [src.core.engine     ] [run_ai_analysis_on_session_data:454] Detailed AI analysis report saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\reports\AI_reports\ai_analysis_report_20250517_191026.json
2025-05-17 19:12:47 [INFO   ] [src.ui.menu_handler ] [handle_user_choice:255] Menu handler received choice: '5'
2025-05-17 19:12:47 [INFO   ] [src.core.engine     ] [shutdown:540] Shutting down Analysis Engine...
2025-05-17 19:12:47 [INFO   ] [src.core.engine     ] [shutdown:552] Analysis Engine shut down successfully.
2025-05-17 19:12:47 [INFO   ] [src.ui.menu_handler ] [run_main_loop:397] Networking Tester finished.
2025-05-18 14:38:56 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 14:38:56 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 14:41:15 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 14:41:15 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 14:42:22 [INFO   ] [__main__            ] [handle_live_capture:227] Output PCAP will be saved to default location: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test7.pcap
2025-05-18 14:42:22 [INFO   ] [__main__            ] [handle_live_capture:236] Preparing for live capture on interface: Ethernet 2 with filter: 'ip'
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=368, family=23, type=1, proto=6, laddr=('::1', 65419, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1910>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1910> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=368, family=23, type=1, proto=6, laddr=('::1', 65419, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=368, family=23, type=1, proto=6, laddr=('::1', 65419, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=368, family=23, type=1, proto=6, laddr=('::1', 65419, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=368, family=23, type=1, proto=6, laddr=('::1', 65419, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=636, family=2, type=1, proto=6, laddr=('127.0.0.1', 65420), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1AC0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1AC0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=636, family=2, type=1, proto=6, laddr=('127.0.0.1', 65420), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=636, family=2, type=1, proto=6, laddr=('127.0.0.1', 65420), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=636, family=2, type=1, proto=6, laddr=('127.0.0.1', 65420), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=636, family=2, type=1, proto=6, laddr=('127.0.0.1', 65420), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [INFO   ] [__main__            ] [handle_live_capture:251] Starting PacketIngestorService for live capture on interface 'Ethernet 2'.
2025-05-18 14:42:22 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 14:42:22 [INFO   ] [src.capture.frame_capture] [start_capture:100] Starting live packet capture on interface 'Ethernet 2' with filter 'ip'.
2025-05-18 14:42:22 [INFO   ] [src.capture.frame_capture] [start_capture:101] Publishing to queue 'raw_frames_queue'
2025-05-18 14:42:22 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=952, family=23, type=1, proto=6, laddr=('::1', 65423, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD2A20>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD2A20> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=952, family=23, type=1, proto=6, laddr=('::1', 65423, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=952, family=23, type=1, proto=6, laddr=('::1', 65423, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=952, family=23, type=1, proto=6, laddr=('::1', 65423, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=952, family=23, type=1, proto=6, laddr=('::1', 65423, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=956, family=2, type=1, proto=6, laddr=('127.0.0.1', 65424), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD2C90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD2C90> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=956, family=2, type=1, proto=6, laddr=('127.0.0.1', 65424), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=956, family=2, type=1, proto=6, laddr=('127.0.0.1', 65424), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=956, family=2, type=1, proto=6, laddr=('127.0.0.1', 65424), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=956, family=2, type=1, proto=6, laddr=('127.0.0.1', 65424), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:42:22 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=360, family=23, type=1, proto=6, laddr=('::1', 65427, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1880>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1880> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=360, family=23, type=1, proto=6, laddr=('::1', 65427, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=360, family=23, type=1, proto=6, laddr=('::1', 65427, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=360, family=23, type=1, proto=6, laddr=('::1', 65427, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=360, family=23, type=1, proto=6, laddr=('::1', 65427, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1040, family=2, type=1, proto=6, laddr=('127.0.0.1', 65428), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1580>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1580> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1040, family=2, type=1, proto=6, laddr=('127.0.0.1', 65428), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1040, family=2, type=1, proto=6, laddr=('127.0.0.1', 65428), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1040, family=2, type=1, proto=6, laddr=('127.0.0.1', 65428), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1040, family=2, type=1, proto=6, laddr=('127.0.0.1', 65428), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:42:22 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=980, family=23, type=1, proto=6, laddr=('::1', 65431, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3830>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3830> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=980, family=23, type=1, proto=6, laddr=('::1', 65431, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=980, family=23, type=1, proto=6, laddr=('::1', 65431, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=980, family=23, type=1, proto=6, laddr=('::1', 65431, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=980, family=23, type=1, proto=6, laddr=('::1', 65431, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=532, family=2, type=1, proto=6, laddr=('127.0.0.1', 65432), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3770>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3770> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=532, family=2, type=1, proto=6, laddr=('127.0.0.1', 65432), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=532, family=2, type=1, proto=6, laddr=('127.0.0.1', 65432), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=532, family=2, type=1, proto=6, laddr=('127.0.0.1', 65432), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=532, family=2, type=1, proto=6, laddr=('127.0.0.1', 65432), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:42:22 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=388, family=23, type=1, proto=6, laddr=('::1', 65435, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4530>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4530> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=388, family=23, type=1, proto=6, laddr=('::1', 65435, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=388, family=23, type=1, proto=6, laddr=('::1', 65435, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=388, family=23, type=1, proto=6, laddr=('::1', 65435, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=388, family=23, type=1, proto=6, laddr=('::1', 65435, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=368, family=2, type=1, proto=6, laddr=('127.0.0.1', 65436), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE50D0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE50D0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=368, family=2, type=1, proto=6, laddr=('127.0.0.1', 65436), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=368, family=2, type=1, proto=6, laddr=('127.0.0.1', 65436), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=368, family=2, type=1, proto=6, laddr=('127.0.0.1', 65436), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=368, family=2, type=1, proto=6, laddr=('127.0.0.1', 65436), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:42:22 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1044, family=23, type=1, proto=6, laddr=('::1', 65439, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4F20>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4F20> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1044, family=23, type=1, proto=6, laddr=('::1', 65439, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1044, family=23, type=1, proto=6, laddr=('::1', 65439, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1044, family=23, type=1, proto=6, laddr=('::1', 65439, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1044, family=23, type=1, proto=6, laddr=('::1', 65439, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=952, family=2, type=1, proto=6, laddr=('127.0.0.1', 65440), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3F50>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3F50> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=952, family=2, type=1, proto=6, laddr=('127.0.0.1', 65440), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=952, family=2, type=1, proto=6, laddr=('127.0.0.1', 65440), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=952, family=2, type=1, proto=6, laddr=('127.0.0.1', 65440), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:42:22 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=952, family=2, type=1, proto=6, laddr=('127.0.0.1', 65440), raddr=('127.0.0.1', 5672)>
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:42:22 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:42:22 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:42:22 [INFO   ] [src.capture.frame_capture] [start_capture:110] Finished live packet capture on interface 'Ethernet 2'.
2025-05-18 14:42:22 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 14:43:54 [INFO   ] [__main__            ] [handle_pcap_analysis:339] Preparing to analyze PCAP file: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test7.pcap using PacketIngestorService.
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1008, family=23, type=1, proto=6, laddr=('::1', 65453, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD0F80>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD0F80> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1008, family=23, type=1, proto=6, laddr=('::1', 65453, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1008, family=23, type=1, proto=6, laddr=('::1', 65453, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1008, family=23, type=1, proto=6, laddr=('::1', 65453, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1008, family=23, type=1, proto=6, laddr=('::1', 65453, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=752, family=2, type=1, proto=6, laddr=('127.0.0.1', 65454), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1D60>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD1D60> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=752, family=2, type=1, proto=6, laddr=('127.0.0.1', 65454), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=752, family=2, type=1, proto=6, laddr=('127.0.0.1', 65454), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=752, family=2, type=1, proto=6, laddr=('127.0.0.1', 65454), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=752, family=2, type=1, proto=6, laddr=('127.0.0.1', 65454), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [INFO   ] [__main__            ] [handle_pcap_analysis:354] Starting PacketIngestorService for PCAP file: 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test7.pcap'.
2025-05-18 14:43:54 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 14:43:54 [INFO   ] [src.capture.frame_capture] [process_pcap_file:131] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test7.pcap'.
2025-05-18 14:43:54 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Publishing to queue 'raw_frames_queue'
2025-05-18 14:43:54 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=968, family=23, type=1, proto=6, laddr=('::1', 65457, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4E60>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4E60> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=968, family=23, type=1, proto=6, laddr=('::1', 65457, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=968, family=23, type=1, proto=6, laddr=('::1', 65457, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=968, family=23, type=1, proto=6, laddr=('::1', 65457, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=968, family=23, type=1, proto=6, laddr=('::1', 65457, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65458), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4E90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE4E90> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65458), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65458), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65458), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65458), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:43:54 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1072, family=23, type=1, proto=6, laddr=('::1', 65461, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE5670>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE5670> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1072, family=23, type=1, proto=6, laddr=('::1', 65461, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1072, family=23, type=1, proto=6, laddr=('::1', 65461, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1072, family=23, type=1, proto=6, laddr=('::1', 65461, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1072, family=23, type=1, proto=6, laddr=('::1', 65461, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=948, family=2, type=1, proto=6, laddr=('127.0.0.1', 65462), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE54C0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE54C0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=948, family=2, type=1, proto=6, laddr=('127.0.0.1', 65462), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=948, family=2, type=1, proto=6, laddr=('127.0.0.1', 65462), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=948, family=2, type=1, proto=6, laddr=('127.0.0.1', 65462), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=948, family=2, type=1, proto=6, laddr=('127.0.0.1', 65462), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:43:54 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=532, family=23, type=1, proto=6, laddr=('::1', 65465, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE5E20>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE5E20> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=532, family=23, type=1, proto=6, laddr=('::1', 65465, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=532, family=23, type=1, proto=6, laddr=('::1', 65465, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=532, family=23, type=1, proto=6, laddr=('::1', 65465, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=532, family=23, type=1, proto=6, laddr=('::1', 65465, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=980, family=2, type=1, proto=6, laddr=('127.0.0.1', 65466), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE5DF0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AE5DF0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=980, family=2, type=1, proto=6, laddr=('127.0.0.1', 65466), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=980, family=2, type=1, proto=6, laddr=('127.0.0.1', 65466), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=980, family=2, type=1, proto=6, laddr=('127.0.0.1', 65466), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=980, family=2, type=1, proto=6, laddr=('127.0.0.1', 65466), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:43:54 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=592, family=23, type=1, proto=6, laddr=('::1', 65469, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD31D0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD31D0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=592, family=23, type=1, proto=6, laddr=('::1', 65469, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=592, family=23, type=1, proto=6, laddr=('::1', 65469, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=592, family=23, type=1, proto=6, laddr=('::1', 65469, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=592, family=23, type=1, proto=6, laddr=('::1', 65469, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65470), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3290>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3290> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65470), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65470), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65470), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1028, family=2, type=1, proto=6, laddr=('127.0.0.1', 65470), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:43:54 [WARNING] [src.messaging.message_producer] [publish_message:70] Connection to RabbitMQ is not active. Attempting to reconnect...
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1028, family=23, type=1, proto=6, laddr=('::1', 65473, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3E90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3E90> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1028, family=23, type=1, proto=6, laddr=('::1', 65473, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1028, family=23, type=1, proto=6, laddr=('::1', 65473, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1028, family=23, type=1, proto=6, laddr=('::1', 65473, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1028, family=23, type=1, proto=6, laddr=('::1', 65473, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1020, family=2, type=1, proto=6, laddr=('127.0.0.1', 65474), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3E00>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018AA7AD3E00> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1020, family=2, type=1, proto=6, laddr=('127.0.0.1', 65474), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1020, family=2, type=1, proto=6, laddr=('127.0.0.1', 65474), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1020, family=2, type=1, proto=6, laddr=('127.0.0.1', 65474), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-18 14:43:54 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1020, family=2, type=1, proto=6, laddr=('127.0.0.1', 65474), raddr=('127.0.0.1', 5672)>
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-18 14:43:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [_connect:35] Failed to connect to RabbitMQ at localhost:5672: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-18 14:43:54 [ERROR  ] [src.messaging.message_producer] [publish_message:73] Failed to publish message: No active connection to RabbitMQ after attempting reconnect.
2025-05-18 14:43:54 [INFO   ] [src.capture.frame_capture] [process_pcap_file:142] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test7.pcap'. Processed 5 packets.
2025-05-18 14:43:54 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 14:51:36 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 14:51:36 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 14:52:25 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:52:25 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=928, family=23, type=1, proto=6, laddr=('::1', 49246, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:52:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E6165E19D0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E6165E19D0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:52:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E6165E19D0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:52:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E6165E19D0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:52:25 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E6165E19D0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:52:25 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 14:52:25 [INFO   ] [src.messaging.message_producer] [_connect:45] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 14:52:25 [INFO   ] [__main__            ] [handle_live_capture:240] Starting live capture...
2025-05-18 14:52:25 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 14:52:25 [INFO   ] [src.capture.frame_capture] [start_capture:100] Starting live packet capture on interface 'Ethernet 2' with filter 'ip'.
2025-05-18 14:52:25 [INFO   ] [src.capture.frame_capture] [start_capture:101] Publishing to queue 'raw_frames_queue'
2025-05-18 14:52:25 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:52:25 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:52:25 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:52:25 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:52:25 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:52:25 [INFO   ] [src.capture.frame_capture] [start_capture:110] Finished live packet capture on interface 'Ethernet 2'.
2025-05-18 14:52:25 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 14:52:25 [INFO   ] [__main__            ] [handle_live_capture:242] Live capture finished. Packets are being processed by backend services.
2025-05-18 14:52:25 [INFO   ] [__main__            ] [handle_live_capture:244] Captured packets saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap
2025-05-18 14:54:30 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 14:54:30 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 14:54:47 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:54:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1056, family=23, type=1, proto=6, laddr=('::1', 49316, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:54:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002843B151460>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002843B151460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:54:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002843B151460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:54:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002843B151460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:54:47 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002843B151460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:54:47 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 14:54:47 [INFO   ] [src.messaging.message_producer] [_connect:45] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 14:54:47 [INFO   ] [__main__            ] [handle_pcap_analysis:304] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap...
2025-05-18 14:54:47 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 14:54:47 [INFO   ] [src.capture.frame_capture] [process_pcap_file:131] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap'.
2025-05-18 14:54:47 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Publishing to queue 'raw_frames_queue'
2025-05-18 14:54:47 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:54:47 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:54:47 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:54:47 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:54:47 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:54:47 [INFO   ] [src.capture.frame_capture] [process_pcap_file:142] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap'. Processed 5 packets.
2025-05-18 14:54:47 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 14:54:47 [INFO   ] [__main__            ] [handle_pcap_analysis:306] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 14:55:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 14:55:20 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 14:55:40 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 14:55:40 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1196, family=23, type=1, proto=6, laddr=('::1', 49338, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 14:55:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000028702C11460>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000028702C11460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 14:55:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000028702C11460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:55:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000028702C11460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:55:40 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000028702C11460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 14:55:40 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 14:55:40 [INFO   ] [src.messaging.message_producer] [_connect:45] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 14:55:40 [INFO   ] [__main__            ] [handle_pcap_analysis:304] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap...
2025-05-18 14:55:40 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 14:55:40 [INFO   ] [src.capture.frame_capture] [process_pcap_file:131] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap'.
2025-05-18 14:55:40 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Publishing to queue 'raw_frames_queue'
2025-05-18 14:55:40 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:55:40 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:55:40 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:55:40 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:55:40 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 14:55:40 [INFO   ] [src.capture.frame_capture] [process_pcap_file:142] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test8.pcap'. Processed 5 packets.
2025-05-18 14:55:40 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 14:55:40 [INFO   ] [__main__            ] [handle_pcap_analysis:306] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 20:33:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:33:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:33:25 [INFO   ] [__main__            ] [<module>:282] Initializing Feature Extractor Service Example...
2025-05-18 20:33:25 [INFO   ] [__main__            ] [<module>:473] Initializing Core Analysis Service Example...
2025-05-18 20:33:25 [ERROR  ] [__main__            ] [<module>:308] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 285, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:33:25 [ERROR  ] [__main__            ] [<module>:520] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 476, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:33:25 [INFO   ] [__main__            ] [<module>:313] Feature Extractor Service Example finished.
2025-05-18 20:33:25 [INFO   ] [__main__            ] [<module>:525] Core Analysis Service Example finished.
2025-05-18 20:33:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:33:25 [INFO   ] [__main__            ] [<module>:144] Initializing Reporting Service Example...
2025-05-18 20:33:25 [ERROR  ] [__main__            ] [<module>:168] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 148, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:33:25 [INFO   ] [__main__            ] [<module>:178] Reporting Service Example finished.
2025-05-18 20:33:36 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:33:36 [INFO   ] [__main__            ] [<module>:370] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:33:36 [INFO   ] [__main__            ] [<module>:373] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:33:36 [INFO   ] [__main__            ] [<module>:380] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:33:36 [INFO   ] [__main__            ] [<module>:382] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:33:36 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:33:36 [ERROR  ] [__main__            ] [<module>:448] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 421, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:33:36 [INFO   ] [__main__            ] [<module>:453] QoS ML Inference Service Example finished.
2025-05-18 15:34:24 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 15:34:24 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 15:35:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 15:35:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=392, family=23, type=1, proto=6, laddr=('::1', 49962, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 15:35:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F831790>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F831790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 15:35:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F831790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 15:35:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F831790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 15:35:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F831790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 15:35:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 15:35:11 [INFO   ] [src.messaging.message_producer] [_connect:45] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 15:35:11 [INFO   ] [__main__            ] [handle_live_capture:240] Starting live capture...
2025-05-18 15:35:11 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 15:35:11 [INFO   ] [src.capture.frame_capture] [start_capture:100] Starting live packet capture on interface 'Ethernet 2' with filter 'ip'.
2025-05-18 15:35:11 [INFO   ] [src.capture.frame_capture] [start_capture:101] Publishing to queue 'raw_frames_queue'
2025-05-18 15:35:11 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:11 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:11 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:11 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:12 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:12 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:13 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:13 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:14 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:14 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:35:14 [INFO   ] [src.capture.frame_capture] [start_capture:110] Finished live packet capture on interface 'Ethernet 2'.
2025-05-18 15:35:14 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 15:35:14 [INFO   ] [__main__            ] [handle_live_capture:242] Live capture finished. Packets are being processed by backend services.
2025-05-18 15:35:14 [INFO   ] [__main__            ] [handle_live_capture:244] Captured packets saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test9.pcap
2025-05-18 15:36:37 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 15:36:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1124, family=23, type=1, proto=6, laddr=('::1', 50091, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 15:36:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F8402C0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F8402C0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 15:36:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F8402C0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 15:36:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F8402C0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 15:36:37 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001777F8402C0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 15:36:37 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [_connect:45] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 15:36:37 [INFO   ] [__main__            ] [handle_pcap_analysis:304] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test9.pcap...
2025-05-18 15:36:37 [INFO   ] [src.capture.frame_capture] [run:160] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 15:36:37 [INFO   ] [src.capture.frame_capture] [process_pcap_file:131] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test9.pcap'.
2025-05-18 15:36:37 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Publishing to queue 'raw_frames_queue'
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.messaging.message_producer] [declare_queue:66] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 15:36:37 [INFO   ] [src.capture.frame_capture] [process_pcap_file:142] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test9.pcap'. Processed 10 packets.
2025-05-18 15:36:37 [INFO   ] [src.capture.frame_capture] [run:171] PacketIngestorService run method finished.
2025-05-18 15:36:37 [INFO   ] [__main__            ] [handle_pcap_analysis:306] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 20:40:01 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:40:01 [INFO   ] [__main__            ] [<module>:282] Initializing Feature Extractor Service Example...
2025-05-18 20:40:01 [ERROR  ] [__main__            ] [<module>:308] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 285, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:40:01 [INFO   ] [__main__            ] [<module>:313] Feature Extractor Service Example finished.
2025-05-18 20:40:01 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:40:01 [INFO   ] [__main__            ] [<module>:473] Initializing Core Analysis Service Example...
2025-05-18 20:40:01 [ERROR  ] [__main__            ] [<module>:520] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 476, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:40:01 [INFO   ] [__main__            ] [<module>:525] Core Analysis Service Example finished.
2025-05-18 20:40:02 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:40:02 [INFO   ] [__main__            ] [<module>:144] Initializing Reporting Service Example...
2025-05-18 20:40:02 [ERROR  ] [__main__            ] [<module>:168] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 148, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:40:02 [INFO   ] [__main__            ] [<module>:178] Reporting Service Example finished.
2025-05-18 20:40:07 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:40:07 [INFO   ] [__main__            ] [<module>:370] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:40:07 [INFO   ] [__main__            ] [<module>:373] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:40:07 [INFO   ] [__main__            ] [<module>:380] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:40:07 [INFO   ] [__main__            ] [<module>:382] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:40:07 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:40:07 [ERROR  ] [__main__            ] [<module>:448] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 421, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:40:07 [INFO   ] [__main__            ] [<module>:453] QoS ML Inference Service Example finished.
2025-05-18 20:41:07 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:07 [INFO   ] [__main__            ] [<module>:473] Initializing Core Analysis Service Example...
2025-05-18 20:41:07 [ERROR  ] [__main__            ] [<module>:520] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 476, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:07 [INFO   ] [__main__            ] [<module>:525] Core Analysis Service Example finished.
2025-05-18 20:41:07 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:07 [INFO   ] [__main__            ] [<module>:282] Initializing Feature Extractor Service Example...
2025-05-18 20:41:07 [ERROR  ] [__main__            ] [<module>:308] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 285, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:07 [INFO   ] [__main__            ] [<module>:313] Feature Extractor Service Example finished.
2025-05-18 20:41:07 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:07 [INFO   ] [__main__            ] [<module>:144] Initializing Reporting Service Example...
2025-05-18 20:41:07 [ERROR  ] [__main__            ] [<module>:168] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 148, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:07 [INFO   ] [__main__            ] [<module>:178] Reporting Service Example finished.
2025-05-18 20:41:13 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:13 [INFO   ] [__main__            ] [<module>:370] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:41:13 [INFO   ] [__main__            ] [<module>:373] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:41:13 [INFO   ] [__main__            ] [<module>:380] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:41:13 [INFO   ] [__main__            ] [<module>:382] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:41:13 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:41:13 [ERROR  ] [__main__            ] [<module>:448] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 421, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:13 [INFO   ] [__main__            ] [<module>:453] QoS ML Inference Service Example finished.
2025-05-18 20:41:33 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:33 [INFO   ] [__main__            ] [<module>:282] Initializing Feature Extractor Service Example...
2025-05-18 20:41:33 [ERROR  ] [__main__            ] [<module>:308] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 285, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:33 [INFO   ] [__main__            ] [<module>:313] Feature Extractor Service Example finished.
2025-05-18 20:41:34 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:34 [INFO   ] [__main__            ] [<module>:473] Initializing Core Analysis Service Example...
2025-05-18 20:41:34 [ERROR  ] [__main__            ] [<module>:520] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 476, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:34 [INFO   ] [__main__            ] [<module>:525] Core Analysis Service Example finished.
2025-05-18 20:41:36 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:36 [INFO   ] [__main__            ] [<module>:144] Initializing Reporting Service Example...
2025-05-18 20:41:36 [ERROR  ] [__main__            ] [<module>:168] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 148, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:36 [INFO   ] [__main__            ] [<module>:178] Reporting Service Example finished.
2025-05-18 20:41:40 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:41:40 [INFO   ] [__main__            ] [<module>:370] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:41:40 [INFO   ] [__main__            ] [<module>:373] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:41:40 [INFO   ] [__main__            ] [<module>:380] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:41:40 [INFO   ] [__main__            ] [<module>:382] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:41:40 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:41:40 [ERROR  ] [__main__            ] [<module>:448] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 421, in <module>
    mq_client_instance = RabbitMQClient(host=RABBITMQ_HOST, port=RABBITMQ_PORT)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:41:40 [INFO   ] [__main__            ] [<module>:453] QoS ML Inference Service Example finished.
2025-05-18 20:48:54 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 56402), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0c5b9a58b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0c5b9a58b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0c5b9a58b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0c5b9a58b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0c5b9a58b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 40616), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2fd19a5ac0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2fd19a5ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2fd19a5ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2fd19a5ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 20:48:54 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2fd19a5ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:48:54 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:48:54 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:48:54 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:48:54 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:48:54 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 38390), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f81047e8890>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f81047e8890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f81047e8890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f81047e8890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f81047e8890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:54 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:54 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 20:48:54 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 20:48:54 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 20:48:54 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 20:48:55 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:55 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:48:55 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:55 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 55034), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:55 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff2f7d20110>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff2f7d20110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:55 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff2f7d20110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:55 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff2f7d20110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:55 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff2f7d20110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:55 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:55 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:48:55 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:48:55 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:48:55 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:48:55 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:48:55 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:48:55 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:48:55 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:48:55 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:48:55 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:48:57 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:57 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:48:57 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:57 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 39260), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:57 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7d62b68d40>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7d62b68d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:57 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7d62b68d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:57 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7d62b68d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:57 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7d62b68d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:57 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:57 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:48:57 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:48:57 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:48:57 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:48:57 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:48:57 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:48:57 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:48:57 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:48:57 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:48:57 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:48:58 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:58 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:48:58 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 39276), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:58 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe5c8f0f7a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe5c8f0f7a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:58 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe5c8f0f7a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:58 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe5c8f0f7a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:58 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe5c8f0f7a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:58 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:58 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:48:58 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:48:58 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:48:58 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:48:58 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:48:58 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:48:58 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:48:58 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:48:58 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:48:58 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:48:59 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:48:59 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:48:59 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:48:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 39292), raddr=('172.18.0.2', 5672)>
2025-05-18 20:48:59 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe81cb889e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe81cb889e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:48:59 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe81cb889e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:59 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe81cb889e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:59 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe81cb889e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:48:59 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:48:59 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:48:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:48:59 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:48:59 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:48:59 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:48:59 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:48:59 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:48:59 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:48:59 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:48:59 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:49:01 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:49:01 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 59206), raddr=('172.18.0.2', 5672)>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6cac4b7200>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6cac4b7200> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6cac4b7200> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6cac4b7200> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6cac4b7200> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:49:01 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 20:49:01 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:126] No models found in registry data when searching for model 'qos_anomaly_vae_e2e_test'
2025-05-18 20:49:01 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 20:49:01 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 20:49:01 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 20:49:01 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 20:49:01 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 20:49:01 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 20:49:01 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 20:49:01 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 39306), raddr=('172.18.0.2', 5672)>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5c7a1e89e0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5c7a1e89e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5c7a1e89e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5c7a1e89e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5c7a1e89e0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:01 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:49:01 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:49:01 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:49:01 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:49:01 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:49:01 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:49:01 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:49:01 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:49:01 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:49:01 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:49:05 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:49:05 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:49:05 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:49:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 56168), raddr=('172.18.0.2', 5672)>
2025-05-18 20:49:05 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fafbefc0e90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fafbefc0e90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:49:05 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fafbefc0e90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:05 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fafbefc0e90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:05 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fafbefc0e90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:05 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:49:05 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:49:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:49:05 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:49:05 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:49:05 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:49:05 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:49:05 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:49:05 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:49:05 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:49:05 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:49:12 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:49:12 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:49:12 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:49:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 56180), raddr=('172.18.0.2', 5672)>
2025-05-18 20:49:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fceb44a47a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fceb44a47a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:49:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fceb44a47a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fceb44a47a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:12 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fceb44a47a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:12 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:49:12 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:49:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:49:12 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:49:12 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:49:12 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:49:12 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:49:12 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:49:12 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:49:12 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:49:12 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:49:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:49:26 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:49:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:49:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 46694), raddr=('172.18.0.2', 5672)>
2025-05-18 20:49:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd701a1bfb0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd701a1bfb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:49:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd701a1bfb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd701a1bfb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd701a1bfb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:49:26 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:49:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:49:26 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:49:26 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:49:26 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:49:26 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:49:26 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:49:26 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:49:26 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:49:26 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:49:52 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:49:52 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:49:52 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:49:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 60544), raddr=('172.18.0.2', 5672)>
2025-05-18 20:49:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fac989b4110>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fac989b4110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:49:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fac989b4110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fac989b4110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:52 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fac989b4110> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:49:52 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:49:52 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:49:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:49:52 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:49:52 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:49:52 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:49:52 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:49:52 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:49:52 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:49:52 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:49:52 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:50:44 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:50:44 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:50:44 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:50:44 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 48472), raddr=('172.18.0.2', 5672)>
2025-05-18 20:50:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe6a55147a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe6a55147a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:50:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe6a55147a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:50:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe6a55147a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:50:44 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe6a55147a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:50:44 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:50:44 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:50:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:50:44 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:50:44 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:50:44 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:50:44 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:50:44 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:50:44 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:50:44 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:50:44 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:51:44 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:51:44 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:51:44 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 20:51:44 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 47180), raddr=('172.18.0.2', 5672)>
2025-05-18 20:51:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550932a1b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550932a1b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 20:51:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550932a1b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:51:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550932a1b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:51:44 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550932a1b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 20:51:44 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 20:51:44 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 20:51:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 20:51:44 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 20:51:44 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 20:51:44 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 20:51:44 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 20:51:44 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 20:51:44 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 20:51:44 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:51:44 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 20:51:57 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 20:51:57 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 20:51:57 [ERROR  ] [src.messaging.rabbitmq_client] [consume:127] Error while consuming from queue 'reporting_service_analysis_results_queue': 'BlockingChannel' object has no attribute 'is_consuming'
2025-05-18 20:51:57 [ERROR  ] [__main__            ] [start_consuming:128] ReportingService failed during consumption: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/messaging/rabbitmq_client.py", line 122, in consume
    self.channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
    self.connection.process_data_events(time_limit=time_limit)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 842, in process_data_events
    self._flush_output(common_terminator)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 514, in _flush_output
    self._impl.ioloop.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 579, in poll
    self._poller.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 1184, in poll
    events = self._poll.poll(self._get_max_wait())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/reporting/reporting_service.py", line 69, in _handle_shutdown_signal
    self.mq_client.stop_consuming() # Assuming RabbitMQClient has such a method
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 114, in start_consuming
    self.mq_client.consume(
  File "/app/src/messaging/rabbitmq_client.py", line 128, in consume
    self.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:51:57 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 20:51:57 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/messaging/rabbitmq_client.py", line 122, in consume
    self.channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
    self.connection.process_data_events(time_limit=time_limit)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 842, in process_data_events
    self._flush_output(common_terminator)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 514, in _flush_output
    self._impl.ioloop.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 579, in poll
    self._poller.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 1184, in poll
    events = self._poll.poll(self._get_max_wait())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/reporting/reporting_service.py", line 69, in _handle_shutdown_signal
    self.mq_client.stop_consuming() # Assuming RabbitMQClient has such a method
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 114, in start_consuming
    self.mq_client.consume(
  File "/app/src/messaging/rabbitmq_client.py", line 128, in consume
    self.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 167, in <module>
    reporting_service_instance.start_consuming()
  File "/app/src/reporting/reporting_service.py", line 130, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 20:51:57 [INFO   ] [__main__            ] [<module>:183] Closing RabbitMQ connection from main block.
2025-05-18 20:52:09 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:52:09 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 20:52:09 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:52:09 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 20:52:09 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:52:09 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 20:52:09 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:52:09 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 20:52:10 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:52:10 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:52:10 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:52:10 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 20:52:16 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:52:16 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:52:16 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:52:16 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:52:16 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:52:16 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:52:16 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:52:16 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 20:55:22 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:55:22 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 20:55:22 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:55:22 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 20:55:22 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:55:22 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:55:22 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:55:22 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 20:55:22 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:55:22 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 20:55:22 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:55:22 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 20:55:29 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:55:29 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:55:29 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:55:29 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:55:29 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:55:29 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:55:29 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:55:29 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 20:57:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:57:06 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 20:57:06 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:57:06 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 20:57:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:57:06 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:57:06 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:57:06 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 20:57:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:57:06 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 20:57:06 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:57:06 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 20:57:13 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:57:13 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:57:13 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:57:13 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:57:13 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:57:13 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:57:13 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:57:13 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 20:58:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:58:25 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 20:58:25 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:58:25 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 20:58:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:58:25 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 20:58:25 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:58:25 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 20:58:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:58:25 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 20:58:25 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:58:25 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 20:58:31 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 20:58:31 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 20:58:31 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 20:58:31 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 20:58:31 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 20:58:31 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 20:58:31 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 20:58:31 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 21:01:53 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:01:53 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:01:53 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:01:53 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 21:01:53 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:01:53 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 21:01:53 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:01:53 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 21:01:53 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:01:53 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 21:01:53 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:01:53 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 21:01:59 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:01:59 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 21:01:59 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 21:01:59 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 21:01:59 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 21:01:59 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 21:01:59 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:01:59 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 21:05:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:05:20 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:05:20 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:05:20 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 21:05:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:05:20 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 21:05:20 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:05:20 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 21:05:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:05:20 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 21:05:20 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:05:20 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 21:05:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:05:26 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 21:05:26 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 21:05:26 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 21:05:26 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 21:05:26 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 21:05:26 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:05:26 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 21:07:43 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:07:43 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:07:43 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:07:43 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 21:07:43 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 478, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:07:43 [INFO   ] [__main__            ] [<module>:532] Core Analysis Service Example finished.
2025-05-18 21:07:43 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:07:43 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-18 21:07:43 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:07:43 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 21:07:43 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:07:43 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 21:07:49 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:07:49 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 21:07:49 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 21:07:49 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 21:07:49 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 21:07:49 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 21:07:49 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 26, in _connect
    params = pika.ConnectionParameters(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 617, in __init__
    self.credentials = credentials
    ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/connection.py", line 267, in credentials
    raise TypeError('credentials must be an object of type: %r, but '
TypeError: credentials must be an object of type: [<class 'pika.credentials.PlainCredentials'>, <class 'pika.credentials.ExternalCredentials'>], but got None
2025-05-18 21:07:49 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-18 21:09:15 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 47144), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a4696db0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a4696db0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a4696db0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a4696db0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a4696db0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:15 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:15 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:15 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:15 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:15 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:15 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 53492), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f182279da90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f182279da90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f182279da90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f182279da90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f182279da90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 21:09:15 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 50918), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0e66c11dc0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0e66c11dc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0e66c11dc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0e66c11dc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0e66c11dc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:15 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:15 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 21:09:15 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 21:09:15 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 21:09:15 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 21:09:16 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:16 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:16 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:16 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 55474), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:16 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9739bfcb00>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9739bfcb00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:16 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9739bfcb00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:16 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9739bfcb00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:16 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9739bfcb00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:16 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:16 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:16 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:16 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:16 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:16 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:16 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:16 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:16 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:16 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:16 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:18 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 55476), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f73ed600590>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f73ed600590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f73ed600590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f73ed600590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f73ed600590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:18 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:18 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:18 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:18 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:18 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:18 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:18 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:18 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:18 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:19 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:19 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:19 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:19 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 55480), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:19 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f26dda3fef0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f26dda3fef0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:19 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f26dda3fef0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:19 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f26dda3fef0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:19 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f26dda3fef0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:19 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:19 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:19 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:19 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:19 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:19 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:19 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:19 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:19 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:19 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:20 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:20 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 55486), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe12213cec0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe12213cec0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe12213cec0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe12213cec0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:20 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe12213cec0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:20 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:20 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:20 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:20 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:20 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:20 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:20 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:20 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:20 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:20 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:22 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:22 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 21:09:22 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 21:09:22 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 21:09:22 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 21:09:22 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 21:09:22 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:22 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 37710), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f468239be00>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f468239be00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f468239be00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:22 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f468239be00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:22 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f468239be00> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:22 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:22 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 21:09:22 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:126] No models found in registry data when searching for model 'qos_anomaly_vae_e2e_test'
2025-05-18 21:09:22 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 21:09:22 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 21:09:22 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 21:09:22 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 21:09:22 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 21:09:22 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 21:09:22 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 21:09:22 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 21:09:22 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 21:09:23 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:23 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:23 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:23 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 55496), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:23 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f37324d07d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f37324d07d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:23 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f37324d07d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:23 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f37324d07d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:23 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f37324d07d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:23 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:23 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:23 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:23 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:23 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:23 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:23 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:23 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:23 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:23 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:23 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:26 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 42730), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5aa099c920>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5aa099c920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5aa099c920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5aa099c920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f5aa099c920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:27 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:27 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:27 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:27 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:27 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:27 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:27 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:27 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:27 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:27 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:33 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:33 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:33 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:33 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 42736), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:33 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8d22f48920>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8d22f48920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:33 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8d22f48920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:33 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8d22f48920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:33 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8d22f48920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:33 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:33 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:33 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:33 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:33 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:33 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:33 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:33 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:33 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:34 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:09:47 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:09:47 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:09:47 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:09:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 33984), raddr=('172.18.0.2', 5672)>
2025-05-18 21:09:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f174dccc920>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f174dccc920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:09:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f174dccc920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f174dccc920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:47 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f174dccc920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:09:47 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:09:47 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:09:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:09:47 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:09:47 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:09:47 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:09:47 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:09:47 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:09:47 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:09:47 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:09:47 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:10:13 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:10:13 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:10:13 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:10:13 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 59266), raddr=('172.18.0.2', 5672)>
2025-05-18 21:10:13 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcfbdb4590>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcfbdb4590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:10:13 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcfbdb4590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:10:13 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcfbdb4590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:10:13 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcfbdb4590> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:10:13 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:10:13 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:10:13 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:10:13 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:10:13 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:10:13 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:10:13 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:10:13 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:10:13 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:10:13 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:10:13 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:11:05 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:11:05 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:11:05 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:11:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 50760), raddr=('172.18.0.2', 5672)>
2025-05-18 21:11:05 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcc34cd4920>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcc34cd4920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:11:05 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcc34cd4920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:11:05 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcc34cd4920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:11:05 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcc34cd4920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:11:05 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:11:05 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:11:05 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:11:05 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:11:05 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:11:05 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:11:05 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:11:05 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:11:05 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:11:05 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:11:05 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:12:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:12:06 [INFO   ] [__main__            ] [<module>:475] Initializing Core Analysis Service Example...
2025-05-18 21:12:06 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:12:06 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 44198), raddr=('172.18.0.2', 5672)>
2025-05-18 21:12:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f68d55b09b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f68d55b09b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:12:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f68d55b09b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:12:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f68d55b09b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:12:06 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f68d55b09b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:12:06 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:12:06 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:12:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:12:06 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:12:06 [INFO   ] [__main__            ] [<module>:502] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:12:06 [WARNING] [__main__            ] [<module>:511] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:12:06 [INFO   ] [__main__            ] [start_consuming:419] CoreAnalysisService starting to consume from queues: 'parsed_packets_for_analysis_queue' and 'ml_results_for_analysis_queue'
2025-05-18 21:12:06 [ERROR  ] [__main__            ] [start_consuming:459] CoreAnalysisService failed to start consuming: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'
2025-05-18 21:12:06 [INFO   ] [__main__            ] [start_consuming:463] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-18 21:12:06 [ERROR  ] [__main__            ] [<module>:527] An unexpected error occurred in the main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 423, in start_consuming
    self.mq_client.consume(
TypeError: RabbitMQClient.consume() got an unexpected keyword argument 'consumer_tag'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 520, in <module>
    core_analysis_service.start_consuming()
  File "/app/src/analysis/core_analysis_service.py", line 461, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    self.stop_consuming()
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:12:06 [INFO   ] [__main__            ] [<module>:530] Closing RabbitMQ connection.
2025-05-18 21:13:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:13:06 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 21:13:06 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:13:06 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 36282), raddr=('172.18.0.2', 5672)>
2025-05-18 21:13:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f806bdfbda0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f806bdfbda0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:13:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f806bdfbda0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:13:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f806bdfbda0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:13:06 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f806bdfbda0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:13:06 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:13:06 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:13:06 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:13:06 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:13:06 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:13:06 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 21:13:06 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 21:21:57 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 21:21:57 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 21:21:57 [ERROR  ] [src.messaging.rabbitmq_client] [consume:127] Error while consuming from queue 'reporting_service_analysis_results_queue': 'BlockingChannel' object has no attribute 'is_consuming'
2025-05-18 21:21:57 [ERROR  ] [__main__            ] [start_consuming:128] ReportingService failed during consumption: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/messaging/rabbitmq_client.py", line 122, in consume
    self.channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
    self.connection.process_data_events(time_limit=time_limit)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 842, in process_data_events
    self._flush_output(common_terminator)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 514, in _flush_output
    self._impl.ioloop.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 579, in poll
    self._poller.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 1184, in poll
    events = self._poll.poll(self._get_max_wait())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/reporting/reporting_service.py", line 69, in _handle_shutdown_signal
    self.mq_client.stop_consuming() # Assuming RabbitMQClient has such a method
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and hasattr(self.channel, 'is_consuming') and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 114, in start_consuming
    self.mq_client.consume(
  File "/app/src/messaging/rabbitmq_client.py", line 128, in consume
    self.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    # This might indicate a different pika version or an unexpected state.
    ^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and hasattr(self.channel, 'is_consuming') and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:21:58 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 21:21:58 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: 'BlockingChannel' object has no attribute 'is_consuming'
Traceback (most recent call last):
  File "/app/src/messaging/rabbitmq_client.py", line 122, in consume
    self.channel.start_consuming()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 1883, in start_consuming
    self._process_data_events(time_limit=None)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 2044, in _process_data_events
    self.connection.process_data_events(time_limit=time_limit)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 842, in process_data_events
    self._flush_output(common_terminator)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 514, in _flush_output
    self._impl.ioloop.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 579, in poll
    self._poller.poll()
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/select_connection.py", line 1184, in poll
    events = self._poll.poll(self._get_max_wait())
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/reporting/reporting_service.py", line 69, in _handle_shutdown_signal
    self.mq_client.stop_consuming() # Assuming RabbitMQClient has such a method
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and hasattr(self.channel, 'is_consuming') and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 114, in start_consuming
    self.mq_client.consume(
  File "/app/src/messaging/rabbitmq_client.py", line 128, in consume
    self.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    # This might indicate a different pika version or an unexpected state.
    ^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and hasattr(self.channel, 'is_consuming') and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 167, in <module>
    reporting_service_instance.start_consuming()
  File "/app/src/reporting/reporting_service.py", line 130, in start_consuming
    self.mq_client.close()
  File "/app/src/messaging/rabbitmq_client.py", line 137, in close
    # This might indicate a different pika version or an unexpected state.
    ^^^^^^^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 132, in stop_consuming
    if self.channel and hasattr(self.channel, 'is_consuming') and self.channel.is_consuming:
                        ^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'BlockingChannel' object has no attribute 'is_consuming'. Did you mean: 'stop_consuming'?
2025-05-18 21:21:58 [INFO   ] [__main__            ] [<module>:183] Closing RabbitMQ connection from main block.
2025-05-18 21:23:30 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 41078), raddr=('172.18.0.2', 5672)>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:23:30 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:23:30 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 56442), raddr=('172.18.0.2', 5672)>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559a393d70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559a393d70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559a393d70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559a393d70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f559a393d70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 21:23:30 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 50646), raddr=('172.18.0.2', 5672)>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5d0e77d40>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5d0e77d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5d0e77d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5d0e77d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5d0e77d40> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:30 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:23:30 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 21:23:30 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 21:23:30 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 21:23:30 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 21:23:30 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 21:23:37 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 21:23:37 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 21:23:37 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 21:23:37 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 21:23:37 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 21:23:37 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 21:23:37 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 21:23:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 37702), raddr=('172.18.0.2', 5672)>
2025-05-18 21:23:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1e456a3560>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1e456a3560> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:23:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1e456a3560> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1e456a3560> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:37 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1e456a3560> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:23:37 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 21:23:37 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 21:23:37 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:126] No models found in registry data when searching for model 'qos_anomaly_vae_e2e_test'
2025-05-18 21:23:37 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 21:23:37 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 21:23:37 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 21:23:37 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 21:23:37 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 21:23:37 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 21:23:37 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 21:23:37 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 21:23:37 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 21:56:03 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': '51cce5a3-87e1-49d0-aae5-ffeea71a00d8', 'original_raw_frame_id': '713370fb-403d-4854-84cd-426a0792edae', 'raw_frame_timestamp': '2025-05-18T21:56:03.289541+00:00', 'parsing_timestamp': '2025-05-18T21:56:03.289541+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.10', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 21:56:03 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 21:56:03 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': '1f67aef0-bc03-424b-b0b8-32cfa71b849b', 'original_raw_frame_id': '713370fb-403d-4854-84cd-426a0792edae', 'raw_frame_timestamp': '2025-05-18T21:56:03.393932+00:00', 'parsing_timestamp': '2025-05-18T21:56:03.289541+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.11', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 21:56:03 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 21:57:18 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': '824bf729-0ea2-4a44-ac34-17473a7f06c5', 'original_raw_frame_id': '4804600a-8012-4b4b-a714-64c0f044f06a', 'raw_frame_timestamp': '2025-05-18T21:57:18.578328+00:00', 'parsing_timestamp': '2025-05-18T21:57:18.578328+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.10', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 21:57:18 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 21:57:18 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': 'db643304-51c8-4a0a-966f-ad2313df2925', 'original_raw_frame_id': '4804600a-8012-4b4b-a714-64c0f044f06a', 'raw_frame_timestamp': '2025-05-18T21:57:18.683186+00:00', 'parsing_timestamp': '2025-05-18T21:57:18.578328+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.11', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 21:57:18 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 22:04:05 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': 'f333f074-1f60-42e9-9c9a-67f1730df942', 'original_raw_frame_id': '76fbe49f-a8bd-46fa-833b-458fb92087b8', 'raw_frame_timestamp': '2025-05-18T22:04:04.977776+00:00', 'parsing_timestamp': '2025-05-18T22:04:04.977776+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.10', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 22:04:05 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 22:04:05 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': '6228e1f3-999b-4b24-8eab-2475a96de299', 'original_raw_frame_id': '76fbe49f-a8bd-46fa-833b-458fb92087b8', 'raw_frame_timestamp': '2025-05-18T22:04:05.082880+00:00', 'parsing_timestamp': '2025-05-18T22:04:04.977776+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.11', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 22:04:05 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 22:08:25 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': 'af431e51-b90a-4fe8-b532-0dfd15b912b5', 'original_raw_frame_id': 'ae622fea-fe28-4c43-869a-9baf93729d38', 'raw_frame_timestamp': '2025-05-18T22:08:25.026490+00:00', 'parsing_timestamp': '2025-05-18T22:08:25.026490+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.10', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 22:08:25 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 22:08:25 [ERROR  ] [__main__            ] [_extract_features:70] ParsedPacket missing packet_id or timestamp: {'schema_version': '1.0', 'parsed_packet_id': 'a541296b-8ded-4178-bd23-6aa56fbf6d06', 'original_raw_frame_id': 'ae622fea-fe28-4c43-869a-9baf93729d38', 'raw_frame_timestamp': '2025-05-18T22:08:25.131294+00:00', 'parsing_timestamp': '2025-05-18T22:08:25.026490+00:00', 'source_info': {'type': 'pcap_file', 'identifier': 'test.pcap'}, 'layers': {'ethernet': {'destination_mac': '00:AA:BB:CC:DD:EE', 'source_mac': '00:11:22:33:44:55', 'ethertype': '0x0800'}, 'ip': {'version': 4, 'source_ip': '192.168.1.11', 'destination_ip': '10.0.0.5', 'protocol': 6, 'ttl': 64, 'length': 52}, 'tcp': {'source_port': 54321, 'destination_port': 80, 'sequence_number': 1000, 'acknowledgment_number': 0, 'flags': {'syn': True, 'ack': False, 'fin': False, 'rst': False, 'psh': False, 'urg': False, 'ece': False, 'cwr': False}, 'window_size': 65535}}, 'parsing_errors': []}
2025-05-18 22:08:25 [WARNING] [__main__            ] [_message_handler:241] Failed to extract features for packet_id: None. Message will not be published.
2025-05-18 22:18:36 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:18:36 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:18:36 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:18:36 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:18:36 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:18:36 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:18:36 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:18:36 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe2838fc7d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:18:36 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:18:36 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:18:36 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:18:36 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 41078), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 41078), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 41078), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:36 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:18:36 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:18:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 41078), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:36 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:18:36 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:18:36 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:18:36 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:18:36 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:18:49 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:18:49 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 56196), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ffbb32842c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ffbb32842c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ffbb32842c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ffbb32842c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 60028), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ffbb32842c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3fd9ac99a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3fd9ac99a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3fd9ac99a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3fd9ac99a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3fd9ac99a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:18:49 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:18:49 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 58956), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:18:49 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:18:49 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:18:49 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:18:49 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:18:49 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:18:49 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:18:59 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:18:59 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:18:59 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:18:59 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:18:59 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:18:59 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:18:59 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:18:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 58026), raddr=('172.18.0.2', 5672)>
2025-05-18 22:18:59 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f16b47fc530>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f16b47fc530> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:18:59 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f16b47fc530> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:59 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f16b47fc530> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:59 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f16b47fc530> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:18:59 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:18:59 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:18:59 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:126] No models found in registry data when searching for model 'qos_anomaly_vae_e2e_test'
2025-05-18 22:18:59 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:18:59 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:18:59 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:18:59 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:18:59 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:18:59 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:18:59 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:18:59 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:18:59 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:22:11 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:22:11 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:22:11 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:22:11 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:22:11 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:22:11 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:22:11 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:22:11 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff89c5de6f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:22:11 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:22:11 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:22:11 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:22:11 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 58956), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 58956), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 58956), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:11 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:22:11 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:22:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 58956), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:11 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:22:11 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:22:11 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:22:11 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:22:11 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:22:24 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 36024), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:22:24 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:22:24 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 40146), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f51b9c3fb90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f51b9c3fb90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f51b9c3fb90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f51b9c3fb90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f51b9c3fb90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:22:24 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:22:24 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:22:24 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 41218), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9ef53e5820>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9ef53e5820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9ef53e5820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9ef53e5820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9ef53e5820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:24 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:22:24 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:22:24 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:22:24 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:22:30 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:22:30 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:22:30 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:22:30 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:22:30 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:22:30 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:22:30 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:22:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 37216), raddr=('172.18.0.2', 5672)>
2025-05-18 22:22:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9660ae86b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9660ae86b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:22:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9660ae86b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:30 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9660ae86b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:30 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9660ae86b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:22:30 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:22:30 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:22:30 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:126] No models found in registry data when searching for model 'qos_anomaly_vae_e2e_test'
2025-05-18 22:22:30 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:22:30 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:22:30 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:22:30 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:22:30 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:22:30 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:22:30 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:22:30 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:22:30 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:24:30 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:24:30 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:24:30 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:24:30 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:24:30 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:24:30 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:24:30 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:24:30 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3f9e451e80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:24:30 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:24:30 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:24:30 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:24:30 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 36024), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 36024), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 36024), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:30 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:24:30 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:24:30 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 36024), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:30 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:24:30 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:24:30 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:24:30 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:24:30 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:24:43 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:24:43 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:24:43 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:24:43 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 42152), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad89da1910>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad89da1910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 40868), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdcf1e1eb70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdcf1e1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad89da1910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdcf1e1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad89da1910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdcf1e1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdcf1e1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad89da1910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:43 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:24:43 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:24:43 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:24:43 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:24:43 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:24:43 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:24:43 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:24:44 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:24:44 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:24:44 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:24:44 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 36926), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:24:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:44 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:44 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:24:44 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:24:44 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:24:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:24:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:24:44 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:24:44 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:24:44 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:24:44 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:24:50 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:24:50 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:24:50 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:24:50 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:24:50 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:24:50 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:24:50 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:24:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 55780), raddr=('172.18.0.2', 5672)>
2025-05-18 22:24:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06867cc8c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06867cc8c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:24:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06867cc8c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06867cc8c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:50 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f06867cc8c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:24:50 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:24:50 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:24:50 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:126] No models found in registry data when searching for model 'qos_anomaly_vae_e2e_test'
2025-05-18 22:24:50 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:24:50 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:24:50 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:24:50 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:24:50 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:24:50 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:24:50 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:24:50 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:24:50 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:26:59 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:26:59 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:26:59 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:26:59 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:26:59 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:26:59 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:26:59 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:26:59 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58761063f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:26:59 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:26:59 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:26:59 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:26:59 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 36926), raddr=('172.18.0.2', 5672)>
2025-05-18 22:26:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 36926), raddr=('172.18.0.2', 5672)>
2025-05-18 22:26:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 36926), raddr=('172.18.0.2', 5672)>
2025-05-18 22:26:59 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:26:59 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:26:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 36926), raddr=('172.18.0.2', 5672)>
2025-05-18 22:26:59 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:26:59 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:26:59 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:26:59 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:26:59 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:27:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:27:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 33270), raddr=('172.18.0.2', 5672)>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 33432), raddr=('172.18.0.2', 5672)>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb8e4c1eb70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb8e4c1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb8e4c1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb8e4c1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb8e4c1eb70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:27:11 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:27:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:27:11 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:27:11 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:27:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 48172), raddr=('172.18.0.2', 5672)>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f45cc1919a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f45cc1919a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f45cc1919a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f45cc1919a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f45cc1919a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:27:11 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:27:11 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:27:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:27:17 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:27:17 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:27:17 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:27:17 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:27:17 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:27:17 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:27:17 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:27:17 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 35966), raddr=('172.18.0.2', 5672)>
2025-05-18 22:27:17 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fae2cce01d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fae2cce01d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:27:17 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fae2cce01d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:17 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fae2cce01d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:17 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fae2cce01d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:27:17 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:27:17 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:27:17 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:133] No versions found for model 'qos_anomaly_vae_e2e_test'
2025-05-18 22:27:17 [ERROR  ] [__main__            ] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:27:17 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:27:17 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:27:17 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:27:17 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:27:17 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:27:17 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:27:17 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:27:17 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:29:13 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:29:13 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:29:13 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:29:13 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:29:13 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:29:13 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:29:13 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:29:13 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fabccdee3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:29:13 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:29:13 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:29:13 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:29:13 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 33432), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:13 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 33432), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:13 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 33432), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:13 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:29:13 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:29:13 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 33432), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:13 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:29:13 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:29:13 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:29:13 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:29:13 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:29:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:29:25 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:29:25 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:29:25 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 60594), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:29:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:25 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:25 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:29:25 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:29:25 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:29:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:29:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:29:25 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:29:25 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:29:25 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:29:25 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:29:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:29:26 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 33348), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd24802d100>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd24802d100> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd24802d100> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd24802d100> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd24802d100> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:29:26 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:29:26 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:29:26 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:29:26 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:29:26 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:29:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:29:26 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 38560), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f21d5588170>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f21d5588170> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f21d5588170> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f21d5588170> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f21d5588170> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:29:26 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:29:26 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:29:26 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:29:26 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:29:26 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:29:26 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:29:31 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:29:31 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:29:31 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:29:31 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:29:31 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:29:31 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:29:31 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:29:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 39468), raddr=('172.18.0.2', 5672)>
2025-05-18 22:29:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4d011aafc0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4d011aafc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:29:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4d011aafc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4d011aafc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:31 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4d011aafc0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:29:31 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:29:32 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:29:32 [ERROR  ] [__main__            ] [_load_model_and_scaler:92] Model type not found in registry metadata for qos_anomaly_vae_e2e_test-1.0.0. Cannot load model.
2025-05-18 22:29:32 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:29:32 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:29:32 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:29:32 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:29:32 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:29:32 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:29:32 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:29:32 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:31:31 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:31:31 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:31:31 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:31:31 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:31:31 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:31:31 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:31:31 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:31:31 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f58f74428d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:31:31 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:31:31 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:31:31 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:31:31 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 60594), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 60594), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 60594), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:31 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:31:31 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:31:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 60594), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:31 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:31:31 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:31:31 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:31:31 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:31:31 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:31:43 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:31:43 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:31:43 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:31:43 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 34862), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe290d04380>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe290d04380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:31:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe290d04380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:43 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe290d04380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:43 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe290d04380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:43 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:31:43 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:31:43 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:31:43 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:31:43 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:31:43 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:31:43 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:31:44 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:31:44 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 50358), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8249782870>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8249782870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8249782870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8249782870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8249782870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:31:44 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:31:44 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:31:44 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:31:44 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:31:44 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:31:44 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:31:44 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 57062), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:44 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:31:44 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:31:44 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:31:44 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:31:44 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:31:44 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:31:50 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:31:50 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:31:50 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:31:50 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:31:50 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:31:50 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:31:50 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:31:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 55098), raddr=('172.18.0.2', 5672)>
2025-05-18 22:31:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad43164890>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad43164890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:31:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad43164890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad43164890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:50 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fad43164890> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:31:50 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:31:50 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:31:50 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 22:31:50 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/qos_anomaly_vae_e2e_test/1.0.0/' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 22:31:50 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:31:50 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:31:50 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:31:50 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:31:50 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:31:50 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:31:50 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:31:50 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:38:50 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:38:50 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:38:50 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:38:50 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:38:50 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:38:50 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:38:50 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:38:50 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f263965e3f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:38:50 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:38:50 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:38:50 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:38:50 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 57062), raddr=('172.18.0.2', 5672)>
2025-05-18 22:38:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 57062), raddr=('172.18.0.2', 5672)>
2025-05-18 22:38:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 57062), raddr=('172.18.0.2', 5672)>
2025-05-18 22:38:50 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:38:50 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:38:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 57062), raddr=('172.18.0.2', 5672)>
2025-05-18 22:38:50 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:38:50 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:38:50 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:38:50 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:38:50 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:39:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 43952), raddr=('172.18.0.2', 5672)>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f74b03afcb0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f74b03afcb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f74b03afcb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f74b03afcb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f74b03afcb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:39:03 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:39:03 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:39:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 47862), raddr=('172.18.0.2', 5672)>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc832fc1970>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc832fc1970> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc832fc1970> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc832fc1970> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc832fc1970> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:39:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 59272), raddr=('172.18.0.2', 5672)>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:39:03 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:39:03 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:39:03 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:39:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:39:09 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:39:09 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:39:09 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:39:09 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:39:09 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:39:09 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:39:09 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:39:09 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 47932), raddr=('172.18.0.2', 5672)>
2025-05-18 22:39:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcab8e850a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcab8e850a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:39:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcab8e850a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcab8e850a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:09 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fcab8e850a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:39:09 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:39:09 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:39:09 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 22:39:09 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 22:39:09 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:39:09 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:39:09 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:39:09 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:39:09 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:39:09 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:39:09 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:39:09 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:43:27 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:43:27 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:43:27 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:43:27 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:43:27 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:43:27 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:43:27 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:43:27 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7feefba26180> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:43:27 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:43:27 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:43:27 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:43:27 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 59272), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:27 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 59272), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:27 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 59272), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:27 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:43:27 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:43:27 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 59272), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:27 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:43:27 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:43:27 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:43:27 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:43:27 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:43:39 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 60740), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7e183b1ac0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7e183b1ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7e183b1ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7e183b1ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7e183b1ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:43:40 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 40036), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2c12805c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2c12805c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2c12805c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2c12805c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2c12805c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:43:40 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:43:40 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:43:40 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 43546), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:40 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:43:40 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:43:40 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:43:40 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:43:40 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:43:46 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:43:46 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_gmm_e2e_test
2025-05-18 22:43:46 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.8
2025-05-18 22:43:46 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_gmm_e2e_test' version: '1.0.8'
2025-05-18 22:43:46 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:43:46 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:43:46 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:43:46 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 45714), raddr=('172.18.0.2', 5672)>
2025-05-18 22:43:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd11854e4b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd11854e4b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:43:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd11854e4b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd11854e4b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:46 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd11854e4b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:43:46 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:43:46 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_gmm_e2e_test' version '1.0.8' from registry.
2025-05-18 22:43:46 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_gmm_e2e_test-1.0.8 of type 'gmm' from directory: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/qos_anomaly_gmm_e2e_test_1.0.8.joblib
2025-05-18 22:43:46 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/qos_anomaly_gmm_e2e_test_1.0.8.joblib' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 22:43:46 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:43:46 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:43:46 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_gmm_e2e_test' version '1.0.8' could not be loaded via registry.
2025-05-18 22:43:46 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:43:46 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:43:46 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:43:46 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:43:46 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:44:50 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:44:50 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:44:50 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:44:50 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:44:50 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:44:50 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:44:50 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:44:50 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb764916690> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:44:50 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:44:50 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:44:50 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:44:50 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 43546), raddr=('172.18.0.2', 5672)>
2025-05-18 22:44:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 43546), raddr=('172.18.0.2', 5672)>
2025-05-18 22:44:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 43546), raddr=('172.18.0.2', 5672)>
2025-05-18 22:44:50 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:44:50 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:44:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 43546), raddr=('172.18.0.2', 5672)>
2025-05-18 22:44:50 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:44:50 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:44:50 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:44:50 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:44:50 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:45:02 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:45:02 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 39988), raddr=('172.18.0.2', 5672)>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7faa1df3c860>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7faa1df3c860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7faa1df3c860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7faa1df3c860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7faa1df3c860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:45:02 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:45:02 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:45:02 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:45:02 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:45:02 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:45:02 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:45:02 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 51284), raddr=('172.18.0.2', 5672)>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8ba1f35730>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8ba1f35730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8ba1f35730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8ba1f35730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8ba1f35730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:02 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:45:02 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:45:02 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:45:02 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:45:02 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:45:02 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:45:02 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:45:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:45:03 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:45:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:45:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 52534), raddr=('172.18.0.2', 5672)>
2025-05-18 22:45:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:45:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:45:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:45:03 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:45:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:45:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:45:03 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:45:03 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:45:03 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:45:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:45:09 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:45:09 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_gmm_e2e_test
2025-05-18 22:45:09 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.8
2025-05-18 22:45:09 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_gmm_e2e_test' version: '1.0.8'
2025-05-18 22:45:09 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:45:09 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:45:09 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:45:09 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 50168), raddr=('172.18.0.2', 5672)>
2025-05-18 22:45:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f561b747e30>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f561b747e30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:45:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f561b747e30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f561b747e30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:09 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f561b747e30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:45:09 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:45:09 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_gmm_e2e_test' version '1.0.8' from registry.
2025-05-18 22:45:09 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_gmm_e2e_test-1.0.8 of type 'gmm' from directory: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:45:09 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [load:309] Attempting to load GMMAnomalyDetector from base model path: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:45:09 [ERROR  ] [src.ai_monitoring.gmm_anomaly_detector] [load:320] Scaler file not found: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_scaler.joblib
2025-05-18 22:45:09 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/ for model type gmm: 'NoneType' object has no attribute 'trained_features_'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 102, in _load_model_and_scaler
    self.expected_features = self.model.trained_features_
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'trained_features_'
2025-05-18 22:45:09 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:45:09 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:45:09 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_gmm_e2e_test' version '1.0.8' could not be loaded via registry.
2025-05-18 22:45:09 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:45:09 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:45:09 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:45:09 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:45:09 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:47:34 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:47:34 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:47:34 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:47:34 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:47:34 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:47:34 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:47:34 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:47:34 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7afc72de80> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:47:34 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:47:34 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:47:34 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:47:34 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 52534), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:34 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 52534), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:34 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 52534), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:34 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:47:34 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:47:34 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 52534), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:34 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:47:34 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:47:34 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:47:34 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:47:34 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:47:46 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:47:46 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:47:46 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:47:46 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 49236), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2af4977d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2af4977d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:47:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2af4977d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2af4977d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:46 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fd2af4977d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:46 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:47:46 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:47:46 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:47:46 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:47:46 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:47:46 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:47:46 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:47:47 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:47:47 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 36892), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f85019205c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f85019205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f85019205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f85019205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f85019205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:47:47 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:47:47 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:47:47 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:47:47 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:47:47 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:47:47 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:47:47 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 50488), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:47 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:47:47 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:47:47 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:47:47 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:47:47 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:47:47 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:47:53 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:47:53 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_gmm_e2e_test
2025-05-18 22:47:53 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.8
2025-05-18 22:47:53 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_gmm_e2e_test' version: '1.0.8'
2025-05-18 22:47:53 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:47:53 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:47:53 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:47:53 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 33196), raddr=('172.18.0.2', 5672)>
2025-05-18 22:47:53 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbe190cbb30>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbe190cbb30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:47:53 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbe190cbb30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:53 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbe190cbb30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:53 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbe190cbb30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:47:53 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:47:53 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_gmm_e2e_test' version '1.0.8' from registry.
2025-05-18 22:47:53 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_gmm_e2e_test-1.0.8 of type 'gmm' from directory: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:47:53 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [load:309] Attempting to load GMMAnomalyDetector from base model path: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:47:53 [ERROR  ] [src.ai_monitoring.gmm_anomaly_detector] [load:323] Metadata file not found: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_metadata.joblib
2025-05-18 22:47:53 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/ for model type gmm: 'NoneType' object has no attribute 'trained_features_'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 102, in _load_model_and_scaler
    self.expected_features = self.model.trained_features_
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'trained_features_'
2025-05-18 22:47:53 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:47:53 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:47:53 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_gmm_e2e_test' version '1.0.8' could not be loaded via registry.
2025-05-18 22:47:53 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:47:53 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:47:53 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:47:53 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:47:53 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:48:51 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:48:51 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:48:51 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:48:51 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:48:51 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:48:51 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:48:51 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:48:51 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc79ee187d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:48:51 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:48:51 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:48:51 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:48:51 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 50488), raddr=('172.18.0.2', 5672)>
2025-05-18 22:48:51 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 50488), raddr=('172.18.0.2', 5672)>
2025-05-18 22:48:51 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 50488), raddr=('172.18.0.2', 5672)>
2025-05-18 22:48:51 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:48:51 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:48:51 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 50488), raddr=('172.18.0.2', 5672)>
2025-05-18 22:48:51 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:48:51 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:48:51 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:48:51 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:48:51 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:49:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 54596), raddr=('172.18.0.2', 5672)>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f84e24f1730>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f84e24f1730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f84e24f1730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f84e24f1730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f84e24f1730> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:49:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:49:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 53300), raddr=('172.18.0.2', 5672)>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdb3b2b6b70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdb3b2b6b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44444), raddr=('172.18.0.2', 5672)>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdb3b2b6b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdb3b2b6b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdb3b2b6b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:49:03 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:49:03 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:49:03 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:49:03 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:49:03 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:49:03 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:49:10 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:49:10 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_gmm_e2e_test
2025-05-18 22:49:10 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.8
2025-05-18 22:49:10 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_gmm_e2e_test' version: '1.0.8'
2025-05-18 22:49:10 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:49:10 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:49:10 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:49:10 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 60686), raddr=('172.18.0.2', 5672)>
2025-05-18 22:49:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f560a6f4b30>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f560a6f4b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:49:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f560a6f4b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f560a6f4b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:10 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f560a6f4b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:49:10 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:49:10 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_gmm_e2e_test' version '1.0.8' from registry.
2025-05-18 22:49:10 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_gmm_e2e_test-1.0.8 of type 'gmm' from directory: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:49:10 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [load:309] Attempting to load GMMAnomalyDetector from base model path: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:49:10 [ERROR  ] [src.ai_monitoring.gmm_anomaly_detector] [_load_joblib:294] Error loading GMM model from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/: [Errno 21] Is a directory: '/app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/gmm_anomaly_detector.py", line 287, in _load_joblib
    obj = joblib.load(path)
          ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/joblib/numpy_pickle.py", line 735, in load
    with open(filename, "rb") as f:
         ^^^^^^^^^^^^^^^^^^^^
IsADirectoryError: [Errno 21] Is a directory: '/app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/'
2025-05-18 22:49:10 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [_load_joblib:288] Scaler loaded from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_scaler.joblib
2025-05-18 22:49:10 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [_load_joblib:288] GMM metadata loaded from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_metadata.joblib
2025-05-18 22:49:10 [ERROR  ] [src.ai_monitoring.gmm_anomaly_detector] [load:357] Failed to load one or more GMM components (model, scaler, or metadata).
2025-05-18 22:49:10 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/ for model type gmm: 'NoneType' object has no attribute 'trained_features_'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 102, in _load_model_and_scaler
    self.expected_features = self.model.trained_features_
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'trained_features_'
2025-05-18 22:49:10 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:49:10 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:49:10 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_gmm_e2e_test' version '1.0.8' could not be loaded via registry.
2025-05-18 22:49:10 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:49:10 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:49:10 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:49:10 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:49:10 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:50:26 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:50:26 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:50:26 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:50:26 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:50:26 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:50:26 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:50:26 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:50:26 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbc39688680> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:50:26 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:50:26 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:50:26 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:50:26 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44444), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44444), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44444), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:26 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:50:26 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:50:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44444), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:26 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:50:26 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:50:26 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:50:26 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:50:26 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:50:39 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 46026), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4bb2579ac0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4bb2579ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4bb2579ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4bb2579ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4bb2579ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:50:39 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 51108), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:50:39 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:50:39 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 45272), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55972da480>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55972da480> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55972da480> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55972da480> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f55972da480> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:39 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:50:39 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:50:39 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:50:39 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:50:39 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:50:39 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:50:46 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:50:46 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_gmm_e2e_test
2025-05-18 22:50:46 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.8
2025-05-18 22:50:46 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_gmm_e2e_test' version: '1.0.8'
2025-05-18 22:50:46 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:50:46 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:50:46 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:50:46 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 40174), raddr=('172.18.0.2', 5672)>
2025-05-18 22:50:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4638b9f3b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4638b9f3b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:50:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4638b9f3b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:46 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4638b9f3b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:46 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4638b9f3b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:50:46 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:50:46 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_gmm_e2e_test' version '1.0.8' from registry.
2025-05-18 22:50:46 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_gmm_e2e_test-1.0.8 of type 'gmm' from directory: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:50:46 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [load:309] Attempting to load GMMAnomalyDetector from base model path: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/
2025-05-18 22:50:46 [ERROR  ] [src.ai_monitoring.gmm_anomaly_detector] [_load_joblib:294] Error loading GMM model from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/: [Errno 21] Is a directory: '/app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/gmm_anomaly_detector.py", line 287, in _load_joblib
    obj = joblib.load(path)
          ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/joblib/numpy_pickle.py", line 735, in load
    with open(filename, "rb") as f:
         ^^^^^^^^^^^^^^^^^^^^
IsADirectoryError: [Errno 21] Is a directory: '/app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/'
2025-05-18 22:50:46 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [_load_joblib:288] Scaler loaded from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_scaler.joblib
2025-05-18 22:50:46 [INFO   ] [src.ai_monitoring.gmm_anomaly_detector] [_load_joblib:288] GMM metadata loaded from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_metadata.joblib
2025-05-18 22:50:46 [ERROR  ] [src.ai_monitoring.gmm_anomaly_detector] [load:357] Failed to load one or more GMM components (model, scaler, or metadata).
2025-05-18 22:50:46 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/ for model type gmm: 'NoneType' object has no attribute 'trained_features_'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 102, in _load_model_and_scaler
    self.expected_features = self.model.trained_features_
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'trained_features_'
2025-05-18 22:50:46 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:50:46 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:50:46 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_gmm_e2e_test' version '1.0.8' could not be loaded via registry.
2025-05-18 22:50:46 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:50:46 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:50:46 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:50:46 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:50:46 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:52:14 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:52:14 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:52:14 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:52:14 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:52:14 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:52:14 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:52:14 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:52:14 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0a4b281340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:52:14 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:52:14 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:52:14 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:52:14 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 51108), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:14 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 51108), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:14 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 51108), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:14 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:52:14 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:52:14 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 51108), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:14 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:52:14 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:52:14 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:52:14 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:52:14 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:52:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 37824), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f704e5de870>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f704e5de870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f704e5de870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f704e5de870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f704e5de870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:52:26 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:52:26 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:52:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 33934), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:52:26 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:52:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 51680), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9c26870380>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9c26870380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9c26870380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9c26870380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9c26870380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:52:26 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:52:26 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:52:26 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:52:33 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:52:33 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_gmm_e2e_test
2025-05-18 22:52:33 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.8
2025-05-18 22:52:33 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_gmm_e2e_test' version: '1.0.8'
2025-05-18 22:52:33 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:52:33 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:52:33 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:52:33 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 60666), raddr=('172.18.0.2', 5672)>
2025-05-18 22:52:33 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1c74e317f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1c74e317f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:52:33 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1c74e317f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:33 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1c74e317f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:33 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1c74e317f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:52:33 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:52:33 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_gmm_e2e_test' version '1.0.8' from registry.
2025-05-18 22:52:33 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_gmm_e2e_test-1.0.8 of type 'gmm' from directory: /app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_model.joblib
2025-05-18 22:52:33 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_gmm_e2e_test/1_0_8_20250518012814/_model.joblib' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 22:52:33 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:52:33 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:52:33 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_gmm_e2e_test' version '1.0.8' could not be loaded via registry.
2025-05-18 22:52:33 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:52:33 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:52:33 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:52:33 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:52:33 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 22:58:07 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 22:58:07 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 22:58:07 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:58:07 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:58:07 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 22:58:07 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 22:58:07 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:58:07 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fa9b3d5d340> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 22:58:07 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 22:58:07 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 22:58:07 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 22:58:07 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 33934), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:07 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 33934), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:07 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 33934), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:07 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:58:07 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 22:58:07 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 33934), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:07 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 22:58:07 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 22:58:07 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 22:58:07 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 22:58:07 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 22:58:19 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:58:19 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 22:58:19 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:58:19 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 58254), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:19 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550b180860>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550b180860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:58:19 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550b180860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:19 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550b180860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:19 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f550b180860> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:19 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:58:19 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:58:19 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 22:58:19 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 22:58:19 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 22:58:19 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 22:58:19 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 22:58:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:58:20 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 44366), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc59e5cd7f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc59e5cd7f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc59e5cd7f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc59e5cd7f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc59e5cd7f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:58:20 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 22:58:20 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:58:20 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 22:58:20 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 22:58:20 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 22:58:20 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:58:20 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 38270), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:20 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:58:20 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 22:58:20 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 22:58:20 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 22:58:20 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 22:58:20 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 22:58:26 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 22:58:26 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 22:58:26 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 22:58:26 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 22:58:26 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 22:58:26 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 22:58:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 22:58:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 60414), raddr=('172.18.0.2', 5672)>
2025-05-18 22:58:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7551ba9ac0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7551ba9ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 22:58:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7551ba9ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7551ba9ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7551ba9ac0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 22:58:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 22:58:26 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 22:58:26 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/qos_anomaly_vae_e2e_test.weights.h5
2025-05-18 22:58:26 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/qos_anomaly_vae_e2e_test.weights.h5' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 22:58:26 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 22:58:26 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 22:58:26 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 22:58:26 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 22:58:26 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 22:58:26 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 22:58:26 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 22:58:26 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:01:59 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:01:59 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:01:59 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:01:59 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:01:59 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:01:59 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:01:59 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:01:59 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fe0193127b0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:01:59 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:01:59 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:01:59 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:01:59 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 38270), raddr=('172.18.0.2', 5672)>
2025-05-18 23:01:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 38270), raddr=('172.18.0.2', 5672)>
2025-05-18 23:01:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 38270), raddr=('172.18.0.2', 5672)>
2025-05-18 23:01:59 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:01:59 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:01:59 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 38270), raddr=('172.18.0.2', 5672)>
2025-05-18 23:01:59 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:01:59 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:01:59 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:01:59 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:01:59 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:02:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:02:11 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:02:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:02:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 51030), raddr=('172.18.0.2', 5672)>
2025-05-18 23:02:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb02baf2b70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb02baf2b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:02:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb02baf2b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb02baf2b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fb02baf2b70> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:02:11 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:02:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:02:11 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:02:11 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:02:11 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:02:11 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:02:12 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:02:12 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 34952), raddr=('172.18.0.2', 5672)>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f41cfc40380>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f41cfc40380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f41cfc40380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f41cfc40380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f41cfc40380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:02:12 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:02:12 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:02:12 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:02:12 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:02:12 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:02:12 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:02:12 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 55972), raddr=('172.18.0.2', 5672)>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:12 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:02:12 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:02:12 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:02:12 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:02:12 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:02:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:02:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:02:18 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:02:18 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:02:18 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:02:18 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:02:18 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:02:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:02:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 47428), raddr=('172.18.0.2', 5672)>
2025-05-18 23:02:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1a8de94b90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1a8de94b90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:02:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1a8de94b90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1a8de94b90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1a8de94b90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:02:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:02:18 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:02:18 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/qos_anomaly_vae_e2e_test.weights.h5
2025-05-18 23:02:18 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/qos_anomaly_vae_e2e_test.weights.h5' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 23:02:18 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:02:18 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:02:18 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 23:02:18 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 23:02:18 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 23:02:18 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:02:18 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:02:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:04:49 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:04:49 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:04:49 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:04:49 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:04:49 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:04:49 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:04:49 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:04:49 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f888e02e630> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:04:49 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:04:49 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:04:49 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:04:49 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 55972), raddr=('172.18.0.2', 5672)>
2025-05-18 23:04:49 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 55972), raddr=('172.18.0.2', 5672)>
2025-05-18 23:04:49 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 55972), raddr=('172.18.0.2', 5672)>
2025-05-18 23:04:49 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:04:49 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:04:49 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 55972), raddr=('172.18.0.2', 5672)>
2025-05-18 23:04:49 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:04:49 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:04:49 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:04:49 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:04:49 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:05:02 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 52986), raddr=('172.18.0.2', 5672)>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7fbf02bc20>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7fbf02bc20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7fbf02bc20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7fbf02bc20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7fbf02bc20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:05:02 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:05:02 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:05:02 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 55476), raddr=('172.18.0.2', 5672)>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7b16f75910>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7b16f75910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7b16f75910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7b16f75910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f7b16f75910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:05:02 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 49526), raddr=('172.18.0.2', 5672)>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:02 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:05:02 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:05:02 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:05:02 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:05:02 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:05:08 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:05:08 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:05:08 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:05:08 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:05:08 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:05:08 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:05:08 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:05:08 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 51910), raddr=('172.18.0.2', 5672)>
2025-05-18 23:05:08 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a9693cb0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a9693cb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:05:08 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a9693cb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:08 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a9693cb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:08 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f79a9693cb0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:05:08 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:05:08 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:05:08 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/qos_anomaly_vae_e2e_test
2025-05-18 23:05:08 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/qos_anomaly_vae_e2e_test' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 23:05:08 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:05:08 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:05:08 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 23:05:08 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 23:05:08 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 23:05:08 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:05:08 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:05:08 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:07:58 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:07:58 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:07:58 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:07:58 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:07:58 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:07:58 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:07:58 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:07:58 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f44a06368d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:07:58 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:07:58 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:07:58 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:07:58 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 49526), raddr=('172.18.0.2', 5672)>
2025-05-18 23:07:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 49526), raddr=('172.18.0.2', 5672)>
2025-05-18 23:07:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 49526), raddr=('172.18.0.2', 5672)>
2025-05-18 23:07:58 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:07:58 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:07:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 49526), raddr=('172.18.0.2', 5672)>
2025-05-18 23:07:58 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:07:58 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:07:58 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:07:58 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:07:58 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:08:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 56640), raddr=('172.18.0.2', 5672)>
2025-05-18 23:08:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5974205c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5974205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5974205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5974205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff5974205c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 51694), raddr=('172.18.0.2', 5672)>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f207edd7920>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f207edd7920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f207edd7920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f207edd7920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f207edd7920> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:08:11 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:08:11 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:08:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 36790), raddr=('172.18.0.2', 5672)>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:08:11 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:08:11 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:08:11 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:08:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:08:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:08:18 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:08:18 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:08:18 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:08:18 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:08:18 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:08:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:08:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 46590), raddr=('172.18.0.2', 5672)>
2025-05-18 23:08:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f48b576ce90>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f48b576ce90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:08:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f48b576ce90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f48b576ce90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f48b576ce90> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:08:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:08:18 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:08:18 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:08:18 [ERROR  ] [__main__            ] [_load_model_and_scaler:145] Model path '/app/data/mlops_artifacts/qos_anomaly_vae_e2e_test/1.0.0/' (from registry) is not a valid directory or does not exist. QoS ML Inference will not work.
2025-05-18 23:08:18 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:08:18 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:08:18 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 23:08:18 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 23:08:18 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 23:08:18 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:08:18 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:08:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:13:58 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:13:58 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:13:58 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:13:58 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:13:58 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:13:58 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:13:58 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:13:58 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f40b03263c0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:13:58 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:13:58 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:13:58 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:13:58 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 36790), raddr=('172.18.0.2', 5672)>
2025-05-18 23:13:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 36790), raddr=('172.18.0.2', 5672)>
2025-05-18 23:13:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 36790), raddr=('172.18.0.2', 5672)>
2025-05-18 23:13:58 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:13:58 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:13:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 36790), raddr=('172.18.0.2', 5672)>
2025-05-18 23:13:58 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:13:58 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:13:58 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:13:58 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:13:58 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:14:10 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:14:10 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 38200), raddr=('172.18.0.2', 5672)>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:14:10 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:14:10 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:14:10 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:14:10 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:14:10 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:14:10 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 53798), raddr=('172.18.0.2', 5672)>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1303605820>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1303605820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1303605820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1303605820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f1303605820> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:10 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:14:10 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:14:10 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:14:10 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:14:10 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:14:10 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:14:10 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:14:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:14:11 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:14:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:14:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 34178), raddr=('172.18.0.2', 5672)>
2025-05-18 23:14:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0228f6e870>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0228f6e870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:14:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0228f6e870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0228f6e870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0228f6e870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:14:11 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:14:11 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:14:11 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:14:11 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:14:11 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:14:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:14:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:14:18 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:14:18 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:14:18 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:14:18 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:14:18 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:14:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:14:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 54112), raddr=('172.18.0.2', 5672)>
2025-05-18 23:14:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff081253c20>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff081253c20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:14:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff081253c20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff081253c20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7ff081253c20> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:14:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:14:18 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:14:18 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:14:18 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/ for model type vae: VAEAnomalyDetector.load() got an unexpected keyword argument 'model_prefix'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 123, in _load_model_and_scaler
    self.model = VAEAnomalyDetector.load(model_prefix=self.model_path)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: VAEAnomalyDetector.load() got an unexpected keyword argument 'model_prefix'
2025-05-18 23:14:18 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:14:18 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:14:18 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 23:14:18 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 23:14:18 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 23:14:18 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:14:18 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:14:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:16:05 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:16:05 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:16:05 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:16:05 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:16:05 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:16:05 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:16:05 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:16:05 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f9f41bde5a0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:16:05 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:16:05 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:16:05 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:16:05 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 38200), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 38200), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 38200), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:05 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:16:05 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:16:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 38200), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:05 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:16:05 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:16:05 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:16:05 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:16:05 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:16:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 40348), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8e9c52a870>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8e9c52a870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8e9c52a870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8e9c52a870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f8e9c52a870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:16:18 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:16:18 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:16:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 45582), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc0ebf60380>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc0ebf60380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc0ebf60380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc0ebf60380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fc0ebf60380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:16:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 46078), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:16:18 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:16:18 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:16:18 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:16:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:16:24 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:16:24 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:16:24 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:16:24 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:16:24 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:16:24 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:16:24 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:16:24 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.5', 35588), raddr=('172.18.0.2', 5672)>
2025-05-18 23:16:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f765efb7b30>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f765efb7b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:16:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f765efb7b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f765efb7b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:24 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f765efb7b30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:16:24 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:16:24 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:16:24 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:16:24 [ERROR  ] [src.ai_monitoring.vae_anomaly_detector] [load:244] One or more VAE artifact files not found for prefix /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/. Searched for weights (/app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/.weights.h5), scaler (/app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/_scaler.joblib), and metadata (/app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/_metadata.joblib).
2025-05-18 23:16:24 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/ for model type vae: Failed to load VAEAnomalyDetector with prefix: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 125, in _load_model_and_scaler
    raise RuntimeError(f"Failed to load VAEAnomalyDetector with prefix: {self.model_path}")
RuntimeError: Failed to load VAEAnomalyDetector with prefix: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:16:24 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:16:24 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:16:24 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 23:16:24 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 23:16:24 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 23:16:24 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:16:24 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:16:24 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:20:05 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:20:05 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:20:05 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:20:05 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:20:05 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:20:05 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:20:05 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:20:05 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f66b17447d0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:20:05 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:20:05 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:20:05 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:20:05 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 46078), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 46078), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 46078), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:05 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:20:05 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:20:05 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.8', 46078), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:05 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:20:05 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:20:05 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:20:05 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:20:05 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:20:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44382), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:20:18 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:20:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 59406), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f14c3aefe30>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f14c3aefe30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f14c3aefe30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f14c3aefe30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f14c3aefe30> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:20:18 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:20:18 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:20:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 47358), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4547e64380>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4547e64380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4547e64380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4547e64380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f4547e64380> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:20:18 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:20:18 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:20:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:20:25 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:20:25 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:20:25 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:20:25 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:20:25 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:20:25 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:20:25 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:20:25 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 42898), raddr=('172.18.0.2', 5672)>
2025-05-18 23:20:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6001818440>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6001818440> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:20:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6001818440> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:25 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6001818440> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:25 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f6001818440> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:20:25 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:20:25 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:20:25 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:20:25 [INFO   ] [src.ai_monitoring.vae_anomaly_detector] [_build_model:153] VAE model (subclassed) built: input_dim=5, latent_dim=2, intermediate_dim=32
2025-05-18 23:20:25 [INFO   ] [src.ai_monitoring.vae_anomaly_detector] [load:295] VAE model explicitly built with input_shape=(None, 5) before loading weights.
2025-05-18 23:20:25 [INFO   ] [src.ai_monitoring.vae_anomaly_detector] [load:309] VAE model loaded successfully from prefix: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:20:25 [ERROR  ] [__main__            ] [_load_model_and_scaler:142] Error loading model artifacts from /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/ for model type vae: 'VAEAnomalyDetector' object has no attribute 'trained_features_'
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 126, in _load_model_and_scaler
    self.expected_features = self.model.trained_features_ # Assuming VAEAnomalyDetector stores this
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'VAEAnomalyDetector' object has no attribute 'trained_features_'. Did you mean: 'trained_features'?
2025-05-18 23:20:25 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:20:25 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:20:25 [WARNING] [__main__            ] [<module>:444] ML Model 'qos_anomaly_vae_e2e_test' version '1.0.0' could not be loaded via registry.
2025-05-18 23:20:25 [WARNING] [__main__            ] [<module>:445] Please ensure the model and version exist in the registry: /app/data/models/model_registry.json
2025-05-18 23:20:25 [WARNING] [__main__            ] [<module>:446] And that the corresponding model/scaler files exist at paths specified in the registry.
2025-05-18 23:20:25 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:20:25 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:20:25 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 23:21:58 [INFO   ] [__main__            ] [_handle_shutdown_signal:63] Shutdown signal 15 received. Initiating graceful shutdown.
2025-05-18 23:21:58 [INFO   ] [__main__            ] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-18 23:21:58 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:21:58 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:21:58 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-18 23:21:58 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-18 23:21:58 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:21:58 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f2edb63e750> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>>
2025-05-18 23:21:58 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-18 23:21:58 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 23:21:58 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 23:21:58 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44382), raddr=('172.18.0.2', 5672)>
2025-05-18 23:21:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44382), raddr=('172.18.0.2', 5672)>
2025-05-18 23:21:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44382), raddr=('172.18.0.2', 5672)>
2025-05-18 23:21:58 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:21:58 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 23:21:58 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.4', 44382), raddr=('172.18.0.2', 5672)>
2025-05-18 23:21:58 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 23:21:58 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-18 23:21:58 [INFO   ] [__main__            ] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-18 23:21:58 [INFO   ] [__main__            ] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-18 23:21:58 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-18 23:22:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:22:11 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.3', 40348), raddr=('172.18.0.2', 5672)>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0bfa029910>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0bfa029910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0bfa029910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0bfa029910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f0bfa029910> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:22:11 [INFO   ] [__main__            ] [<module>:299] Declared exchange 'features_exchange' and queue 'features_queue' for output.
2025-05-18 23:22:11 [INFO   ] [__main__            ] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:22:11 [INFO   ] [__main__            ] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-18 23:22:11 [INFO   ] [__main__            ] [<module>:309] Starting feature extraction. Consuming from 'parsed_packets_queue'. Press Ctrl+C to stop.
2025-05-18 23:22:11 [INFO   ] [__main__            ] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-18 23:22:11 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:22:11 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.7', 34090), raddr=('172.18.0.2', 5672)>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdf6ad02870>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdf6ad02870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdf6ad02870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdf6ad02870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fdf6ad02870> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:11 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:22:11 [INFO   ] [__main__            ] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_for_analysis_queue' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_for_analysis_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_for_analysis_queue'.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:11 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_for_analysis_queue' declared successfully.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_for_analysis_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_for_analysis_queue'.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:22:12 [INFO   ] [__main__            ] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_for_analysis_queue and ml_results_for_analysis_queue, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-18 23:22:12 [INFO   ] [__main__            ] [<module>:483] Starting Core Analysis Service. Press Ctrl+C to stop.
2025-05-18 23:22:12 [WARNING] [__main__            ] [<module>:492] Note: The current RabbitMQClient's consume method is likely blocking. To consume from both parsed_packets and ml_results queues concurrently in a single service instance, the client needs to support non-blocking operations or manage threads/async tasks. This example may only process from the first queue registered if the consume call blocks.
2025-05-18 23:22:12 [INFO   ] [__main__            ] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_for_analysis_queue
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_for_analysis_queue'. Waiting for messages...
2025-05-18 23:22:12 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:22:12 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-18 23:22:12 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:22:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.9', 42024), raddr=('172.18.0.2', 5672)>
2025-05-18 23:22:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3637cf23f0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3637cf23f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:22:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3637cf23f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3637cf23f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:12 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7f3637cf23f0> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:12 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:22:12 [INFO   ] [__main__            ] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'reporting_service_analysis_results_queue' declared successfully.
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-18 23:22:12 [INFO   ] [__main__            ] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'reporting_service_analysis_results_queue' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-18 23:22:12 [INFO   ] [__main__            ] [<module>:166] Starting Reporting Service. Press Ctrl+C to generate a final report and stop.
2025-05-18 23:22:12 [INFO   ] [__main__            ] [start_consuming:112] ReportingService starting to consume from queue: 'reporting_service_analysis_results_queue'
2025-05-18 23:22:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'reporting_service_analysis_results_queue'. Waiting for messages...
2025-05-18 23:22:21 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-18 23:22:21 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-18 23:22:21 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-18 23:22:21 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-18 23:22:21 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-18 23:22:21 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-18 23:22:21 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('172.18.0.2', 5672)
2025-05-18 23:22:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=7, family=2, type=1, proto=6, laddr=('172.18.0.6', 42748), raddr=('172.18.0.2', 5672)>
2025-05-18 23:22:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcaca26570>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcaca26570> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>).
2025-05-18 23:22:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcaca26570> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcaca26570> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:21 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x7fbcaca26570> params=<ConnectionParameters host=rabbitmq port=5672 virtual_host=/ ssl=False>>
2025-05-18 23:22:21 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 23:22:21 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at rabbitmq:5672
2025-05-18 23:22:21 [INFO   ] [__main__            ] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_vae_e2e_test' version '1.0.0' from registry.
2025-05-18 23:22:21 [INFO   ] [__main__            ] [_load_model_and_scaler:96] Loading model qos_anomaly_vae_e2e_test-1.0.0 of type 'vae' from directory: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:22:22 [INFO   ] [src.ai_monitoring.vae_anomaly_detector] [_build_model:153] VAE model (subclassed) built: input_dim=5, latent_dim=2, intermediate_dim=32
2025-05-18 23:22:22 [INFO   ] [src.ai_monitoring.vae_anomaly_detector] [load:295] VAE model explicitly built with input_shape=(None, 5) before loading weights.
2025-05-18 23:22:22 [INFO   ] [src.ai_monitoring.vae_anomaly_detector] [load:309] VAE model loaded successfully from prefix: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:22:22 [INFO   ] [__main__            ] [_load_model_and_scaler:126] Model and scaler for 'qos_anomaly_vae_e2e_test' version '1.0.0' loaded successfully.
2025-05-18 23:22:22 [INFO   ] [__main__            ] [_load_model_and_scaler:127] Successfully loaded VAE model and artifacts using prefix: /app/data/mlops_artifacts/models/qos_anomaly_vae_e2e_test/1.0.0/
2025-05-18 23:22:22 [INFO   ] [__main__            ] [_load_model_and_scaler:128] VAE model expects features: ['feature1', 'feature2', 'feature3', 'feature4', 'feature5']
2025-05-18 23:22:22 [INFO   ] [__main__            ] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-18 23:22:22 [INFO   ] [__main__            ] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-18 23:22:22 [INFO   ] [__main__            ] [<module>:449] Starting QoS ML Inference. Consuming from 'features_queue'. Press Ctrl+C to stop.
2025-05-18 23:22:22 [INFO   ] [__main__            ] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-18 23:22:22 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-18 18:25:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 18:25:18 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 18:25:42 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 18:25:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1152, family=23, type=1, proto=6, laddr=('::1', 55751, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 18:25:42 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001800609BEC0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001800609BEC0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 18:25:42 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001800609BEC0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:25:42 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001800609BEC0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:25:42 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001800609BEC0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:25:42 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 18:25:42 [INFO   ] [__main__            ] [handle_live_capture:240] Starting live capture...
2025-05-18 18:25:42 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 18:25:42 [INFO   ] [src.capture.frame_capture] [start_capture:101] Starting live packet capture on interface 'Ethernet 2' with filter 'ip'.
2025-05-18 18:25:42 [INFO   ] [src.capture.frame_capture] [start_capture:102] Publishing to queue 'raw_frames_queue'
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:42 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:43 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:43 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:43 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:43 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:43 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:43 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:44 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:45 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:45 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:45 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:45 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:45 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:46 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:25:46 [INFO   ] [src.capture.frame_capture] [start_capture:111] Finished live packet capture on interface 'Ethernet 2'.
2025-05-18 18:25:46 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 18:25:46 [INFO   ] [__main__            ] [handle_live_capture:242] Live capture finished. Packets are being processed by backend services.
2025-05-18 18:25:46 [INFO   ] [__main__            ] [handle_live_capture:244] Captured packets saved to: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap
2025-05-18 18:26:17 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 18:26:17 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 18:26:26 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 18:26:26 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=348, family=23, type=1, proto=6, laddr=('::1', 55776, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 18:26:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC741460>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC741460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 18:26:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC741460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:26:26 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC741460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:26:26 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC741460> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:26:26 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 18:26:26 [INFO   ] [__main__            ] [handle_pcap_analysis:304] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap...
2025-05-18 18:26:26 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 18:26:26 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'.
2025-05-18 18:26:26 [INFO   ] [src.capture.frame_capture] [process_pcap_file:133] Current working directory before PcapReader: C:\Users\juanc\Documents\Proyectos Personales\networking_tester
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:26 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:26:27 [INFO   ] [src.capture.frame_capture] [process_pcap_file:150] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'. Processed 20 packets.
2025-05-18 18:26:27 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 18:26:27 [INFO   ] [__main__            ] [handle_pcap_analysis:306] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 18:27:36 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 18:27:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1092, family=23, type=1, proto=6, laddr=('::1', 55811, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 18:27:36 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC743170>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC743170> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 18:27:36 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC743170> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:27:36 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC743170> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:27:36 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B3AC743170> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:27:36 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 18:27:36 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 18:27:36 [INFO   ] [__main__            ] [handle_pcap_analysis:304] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap...
2025-05-18 18:27:36 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 18:27:36 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'.
2025-05-18 18:27:36 [INFO   ] [src.capture.frame_capture] [process_pcap_file:133] Current working directory before PcapReader: C:\Users\juanc\Documents\Proyectos Personales\networking_tester
2025-05-18 18:27:36 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:36 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:27:37 [INFO   ] [src.capture.frame_capture] [process_pcap_file:150] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'. Processed 20 packets.
2025-05-18 18:27:37 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 18:27:37 [INFO   ] [__main__            ] [handle_pcap_analysis:306] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 18:46:48 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 18:46:48 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 18:47:06 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 18:47:06 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1032, family=23, type=1, proto=6, laddr=('::1', 56718, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 18:47:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E372F3D550>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E372F3D550> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 18:47:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E372F3D550> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:47:07 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E372F3D550> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:47:07 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001E372F3D550> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 18:47:07 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 18:47:07 [INFO   ] [__main__            ] [handle_pcap_analysis:305] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap...
2025-05-18 18:47:07 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 18:47:07 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'.
2025-05-18 18:47:07 [INFO   ] [src.capture.frame_capture] [process_pcap_file:133] Current working directory before PcapReader: C:\Users\juanc\Documents\Proyectos Personales\networking_tester
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 18:47:07 [INFO   ] [src.capture.frame_capture] [process_pcap_file:150] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'. Processed 20 packets.
2025-05-18 18:47:07 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 18:47:07 [INFO   ] [__main__            ] [handle_pcap_analysis:307] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 18:47:12 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250518_184712.json
2025-05-18 18:55:34 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 18:55:34 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 19:02:24 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 19:02:24 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=712, family=23, type=1, proto=6, laddr=('::1', 57002, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:02:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCD760>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCD760> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 19:02:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCD760> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:02:24 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCD760> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:02:24 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCD760> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:02:24 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 19:02:24 [INFO   ] [__main__            ] [handle_pcap_analysis:305] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap...
2025-05-18 19:02:24 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 19:02:24 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'.
2025-05-18 19:02:24 [INFO   ] [src.capture.frame_capture] [process_pcap_file:133] Current working directory before PcapReader: C:\Users\juanc\Documents\Proyectos Personales\networking_tester
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:24 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:25 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:25 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:02:25 [INFO   ] [src.capture.frame_capture] [process_pcap_file:150] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'. Processed 20 packets.
2025-05-18 19:02:25 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 19:02:25 [INFO   ] [__main__            ] [handle_pcap_analysis:307] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1144, family=23, type=1, proto=6, laddr=('::1', 57012, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 19:03:20 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 19:03:20 [INFO   ] [pika.channel        ] [close:536] Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 19:03:20 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F90FBCE9F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 19:03:20 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1144, family=23, type=1, proto=6, laddr=('::1', 57012, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1144, family=23, type=1, proto=6, laddr=('::1', 57012, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1144, family=23, type=1, proto=6, laddr=('::1', 57012, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:03:20 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 19:03:20 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 19:03:20 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1144, family=23, type=1, proto=6, laddr=('::1', 57012, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:03:20 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 19:13:42 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 19:13:42 [INFO   ] [__main__            ] [load_app_config:33] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 19:14:06 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 19:14:06 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=932, family=23, type=1, proto=6, laddr=('::1', 57330, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:14:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F9790>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F9790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 19:14:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F9790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:14:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F9790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:14:06 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F9790> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:14:06 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 19:14:06 [INFO   ] [__main__            ] [handle_pcap_analysis:305] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap...
2025-05-18 19:14:06 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 19:14:06 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'.
2025-05-18 19:14:06 [INFO   ] [src.capture.frame_capture] [process_pcap_file:133] Current working directory before PcapReader: C:\Users\juanc\Documents\Proyectos Personales\networking_tester
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:06 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:07 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 19:14:07 [INFO   ] [src.capture.frame_capture] [process_pcap_file:150] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'. Processed 20 packets.
2025-05-18 19:14:07 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 19:14:07 [INFO   ] [__main__            ] [handle_pcap_analysis:307] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1112, family=23, type=1, proto=6, laddr=('::1', 57338, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 19:14:16 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 19:14:16 [INFO   ] [pika.channel        ] [close:536] Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 19:14:16 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022FD75F8E30> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 19:14:16 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=1112, family=23, type=1, proto=6, laddr=('::1', 57338, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=1112, family=23, type=1, proto=6, laddr=('::1', 57338, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=1112, family=23, type=1, proto=6, laddr=('::1', 57338, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:14:16 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 19:14:16 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 19:14:16 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=1112, family=23, type=1, proto=6, laddr=('::1', 57338, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 19:14:16 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 21:01:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-18 21:01:06 [INFO   ] [__main__            ] [load_app_config:37] Application configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-18 21:01:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 21:01:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=964, family=23, type=1, proto=6, laddr=('::1', 59631, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:01:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D4D6A0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D4D6A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:01:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D4D6A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:01:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D4D6A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:01:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D4D6A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:01:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [_connect:42] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 21:01:18 [INFO   ] [__main__            ] [handle_pcap_analysis:310] Starting PCAP file analysis for: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap...
2025-05-18 21:01:18 [INFO   ] [src.capture.frame_capture] [run:168] Packet Ingestor configured to publish to queue: 'raw_frames_queue'
2025-05-18 21:01:18 [INFO   ] [src.capture.frame_capture] [process_pcap_file:132] Starting PCAP file processing for 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'.
2025-05-18 21:01:18 [INFO   ] [src.capture.frame_capture] [process_pcap_file:133] Current working directory before PcapReader: C:\Users\juanc\Documents\Proyectos Personales\networking_tester
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:18 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:19 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:19 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:19 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:19 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:19 [INFO   ] [src.messaging.message_producer] [declare_queue:63] Queue 'raw_frames_queue' declared successfully (durable=True).
2025-05-18 21:01:19 [INFO   ] [src.capture.frame_capture] [process_pcap_file:150] Finished processing PCAP file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data\captures\test10.pcap'. Processed 20 packets.
2025-05-18 21:01:19 [INFO   ] [src.capture.frame_capture] [run:179] PacketIngestorService run method finished.
2025-05-18 21:01:19 [INFO   ] [__main__            ] [handle_pcap_analysis:312] PCAP file analysis finished. Packets are being processed by backend services.
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=780, family=23, type=1, proto=6, laddr=('::1', 59681, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D623F0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D623F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D623F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D623F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D623F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:04:50 [INFO   ] [src.ui.report_service_client] [connect:53] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 21:04:50 [WARNING] [pika.channel        ] [_on_close_from_broker:1080] Received remote Channel.Close (404): "NOT_FOUND - no queue 'feature_vectors_queue' in vhost '/'" on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D623F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 21:04:50 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=780, family=23, type=1, proto=6, laddr=('::1', 59681, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=780, family=23, type=1, proto=6, laddr=('::1', 59681, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=780, family=23, type=1, proto=6, laddr=('::1', 59681, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:04:50 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 21:04:50 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 21:04:50 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=780, family=23, type=1, proto=6, laddr=('::1', 59681, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:04:50 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 21:04:50 [INFO   ] [src.ui.report_service_client] [close:63] RabbitMQ connection closed
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=736, family=23, type=1, proto=6, laddr=('::1', 59712, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:06:21 [INFO   ] [src.ui.report_service_client] [connect:53] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 21:06:21 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 21:06:21 [INFO   ] [pika.channel        ] [close:536] Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 21:06:21 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62090> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 21:06:21 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=736, family=23, type=1, proto=6, laddr=('::1', 59712, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=736, family=23, type=1, proto=6, laddr=('::1', 59712, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=736, family=23, type=1, proto=6, laddr=('::1', 59712, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:21 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 21:06:21 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=736, family=23, type=1, proto=6, laddr=('::1', 59712, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 21:06:21 [INFO   ] [src.ui.report_service_client] [close:63] RabbitMQ connection closed
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=708, family=23, type=1, proto=6, laddr=('::1', 59715, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-18 21:06:21 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-18 21:06:21 [INFO   ] [src.ui.report_service_client] [connect:53] Successfully connected to RabbitMQ at localhost:5672
2025-05-18 21:06:21 [INFO   ] [src.ui.report_service_client] [setup_channels:87] Exchange 'analysis_results_exchange' and queue 'analysis_results_queue' set up successfully
2025-05-18 21:06:21 [INFO   ] [src.ui.report_service_client] [request_report:198] Sent report request: {'request_id': 'cli_request_1747620381', 'timestamp': '2025-05-19T02:06:21Z', 'action': 'generate_report', 'format': 'json', 'client_id': 'cli_client_1747620381'}
2025-05-18 21:06:37 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-18 21:06:37 [INFO   ] [pika.channel        ] [close:536] Closing channel (200): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 21:06:37 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001C6B4D62B70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-18 21:06:37 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-18 21:06:37 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=708, family=23, type=1, proto=6, laddr=('::1', 59715, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=708, family=23, type=1, proto=6, laddr=('::1', 59715, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=708, family=23, type=1, proto=6, laddr=('::1', 59715, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:37 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 21:06:37 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-18 21:06:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=708, family=23, type=1, proto=6, laddr=('::1', 59715, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-18 21:06:37 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-18 21:06:37 [INFO   ] [src.ui.report_service_client] [close:63] RabbitMQ connection closed
2025-05-18 21:06:37 [INFO   ] [src.reporting.report_generator] [generate_report:63] Report generated and saved to C:\Users\juanc\Documents\Proyectos Personales\networking_tester\reports\capture_report_20250518_210637.json
2025-05-25 00:02:49 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-25 00:02:49 [INFO   ] [__main__            ] [<module>:286] Initializing Feature Extractor Service Example...
2025-05-25 00:02:49 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-25 00:02:49 [INFO   ] [__main__            ] [<module>:146] Initializing Reporting Service Example...
2025-05-25 00:02:50 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-25 00:02:50 [INFO   ] [__main__            ] [<module>:456] Initializing Core Analysis Service Example...
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.selector_ioloop_adapter] [_resolve:569] Address resolution failed: gaierror(-2, 'Name or service not known')
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.connection_workflow] [_on_getaddrinfo_async_done:799] getaddrinfo failed: gaierror(-2, 'Name or service not known').
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None.
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:02:53 [ERROR  ] [__main__            ] [<module>:317] An unexpected error occurred in the main execution block of Feature Extractor: [Errno -2] Name or service not known
Traceback (most recent call last):
  File "/app/src/ai_monitoring/feature_extractor_service.py", line 289, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 37, in _connect
    self.connection = pika.BlockingConnection(params)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 360, in __init__
    self._impl = self._create_connection(parameters, _impl_class)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:02:53 [INFO   ] [__main__            ] [<module>:322] Feature Extractor Service Example finished.
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.selector_ioloop_adapter] [_resolve:569] Address resolution failed: gaierror(-2, 'Name or service not known')
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.connection_workflow] [_on_getaddrinfo_async_done:799] getaddrinfo failed: gaierror(-2, 'Name or service not known').
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None.
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:02:53 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:02:53 [ERROR  ] [__main__            ] [<module>:175] An unexpected error occurred in the Reporting Service main execution block: [Errno -2] Name or service not known
Traceback (most recent call last):
  File "/app/src/reporting/reporting_service.py", line 150, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 37, in _connect
    self.connection = pika.BlockingConnection(params)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 360, in __init__
    self._impl = self._create_connection(parameters, _impl_class)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:02:53 [INFO   ] [__main__            ] [<module>:185] Reporting Service Example finished.
2025-05-25 00:02:54 [ERROR  ] [pika.adapters.utils.selector_ioloop_adapter] [_resolve:569] Address resolution failed: gaierror(-2, 'Name or service not known')
2025-05-25 00:02:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_on_getaddrinfo_async_done:799] getaddrinfo failed: gaierror(-2, 'Name or service not known').
2025-05-25 00:02:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None.
2025-05-25 00:02:54 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:02:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:02:54 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:02:54 [ERROR  ] [__main__            ] [<module>:508] An unexpected error occurred in the main execution block: [Errno -2] Name or service not known
Traceback (most recent call last):
  File "/app/src/analysis/core_analysis_service.py", line 459, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 37, in _connect
    self.connection = pika.BlockingConnection(params)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 360, in __init__
    self._impl = self._create_connection(parameters, _impl_class)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:02:54 [INFO   ] [__main__            ] [<module>:513] Core Analysis Service Example finished.
2025-05-25 00:03:17 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: /app/logs/networking_tester.log
2025-05-25 00:03:17 [INFO   ] [__main__            ] [<module>:374] Loaded TARGET_MODEL_NAME from settings.yaml: qos_anomaly_vae_e2e_test
2025-05-25 00:03:17 [INFO   ] [__main__            ] [<module>:377] Loaded TARGET_MODEL_VERSION from settings.yaml: 1.0.0
2025-05-25 00:03:17 [INFO   ] [__main__            ] [<module>:384] QoS ML Inference Service will use model: 'qos_anomaly_vae_e2e_test' version: '1.0.0'
2025-05-25 00:03:17 [INFO   ] [__main__            ] [<module>:386] Initializing QoS ML Inference Service Example with Model Registry...
2025-05-25 00:03:17 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: /app/data/models/model_registry.json
2025-05-25 00:03:21 [ERROR  ] [pika.adapters.utils.selector_ioloop_adapter] [_resolve:569] Address resolution failed: gaierror(-2, 'Name or service not known')
2025-05-25 00:03:21 [ERROR  ] [pika.adapters.utils.connection_workflow] [_on_getaddrinfo_async_done:799] getaddrinfo failed: gaierror(-2, 'Name or service not known').
2025-05-25 00:03:21 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None.
2025-05-25 00:03:21 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:03:21 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 1 exceptions in all; last exception - gaierror(-2, 'Name or service not known'); first exception - None
2025-05-25 00:03:21 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:03:21 [ERROR  ] [__main__            ] [<module>:457] An unexpected error occurred in the main execution block: [Errno -2] Name or service not known
Traceback (most recent call last):
  File "/app/src/ai_monitoring/qos_ml_inference_service.py", line 425, in <module>
    mq_client_instance = RabbitMQClient(
                         ^^^^^^^^^^^^^^^
  File "/app/src/messaging/rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "/app/src/messaging/rabbitmq_client.py", line 37, in _connect
    self.connection = pika.BlockingConnection(params)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 360, in __init__
    self._impl = self._create_connection(parameters, _impl_class)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
  File "/usr/local/lib/python3.12/site-packages/pika/adapters/utils/selector_ioloop_adapter.py", line 565, in _resolve
    result = socket.getaddrinfo(self._host, self._port, self._family,
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/socket.py", line 978, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno -2] Name or service not known
2025-05-25 00:03:21 [INFO   ] [__main__            ] [<module>:462] QoS ML Inference Service Example finished.
2025-05-24 19:04:16 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:04:28 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:04:34 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:04:40 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:28:03 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:28:46 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:29:04 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:29:04 [INFO   ] [root                ] [start_stats_collector_command:207] Attempting to start Statistics Collector Service.
2025-05-24 19:29:04 [INFO   ] [src.statistics.statistics_collector_service] [reset_stats:74] Statistics reset.
2025-05-24 19:29:04 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:29:04 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5680, family=23, type=1, proto=6, laddr=('::1', 61991, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:29:04 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018019CDF680>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018019CDF680> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:29:04 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018019CDF680> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:29:04 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018019CDF680> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:29:04 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000018019CDF680> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:29:04 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 19:29:04 [INFO   ] [src.messaging.message_broker] [connect:52] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 19:29:04 [INFO   ] [src.statistics.statistics_collector_service] [start:100] Statistics Collector Service started successfully
2025-05-24 19:29:04 [INFO   ] [src.messaging.message_broker] [consume_messages:138] Started consuming from queue 'parsed_packets'
2025-05-24 19:30:04 [INFO   ] [src.statistics.statistics_collector_service] [_publish_current_statistics:320] Published statistics: 0 packets processed
2025-05-24 19:33:14 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:33:31 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:33:31 [INFO   ] [root                ] [start_feature_extractor_command:241] Attempting to start Feature Extractor Service.
2025-05-24 19:33:31 [INFO   ] [root                ] [start_feature_extractor_command:242]   RabbitMQ Host: localhost:5672
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5460, family=23, type=1, proto=6, laddr=('::1', 62098, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D3556900>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D3556900> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5460, family=23, type=1, proto=6, laddr=('::1', 62098, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5460, family=23, type=1, proto=6, laddr=('::1', 62098, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5460, family=23, type=1, proto=6, laddr=('::1', 62098, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:31 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:31 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:31 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:31 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5460, family=23, type=1, proto=6, laddr=('::1', 62098, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5916, family=2, type=1, proto=6, laddr=('127.0.0.1', 62099), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D3673BF0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D3673BF0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5916, family=2, type=1, proto=6, laddr=('127.0.0.1', 62099), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5916, family=2, type=1, proto=6, laddr=('127.0.0.1', 62099), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5916, family=2, type=1, proto=6, laddr=('127.0.0.1', 62099), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:31 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:31 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:31 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:31 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:31 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-24 19:33:31 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5916, family=2, type=1, proto=6, laddr=('127.0.0.1', 62099), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:31 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:31 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:31 [ERROR  ] [src.messaging.rabbitmq_client] [_connect:43] Failed to connect to RabbitMQ (attempt 1/5): ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:31 [INFO   ] [src.messaging.rabbitmq_client] [_connect:45] Retrying in 5 seconds...
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5688, family=23, type=1, proto=6, laddr=('::1', 62105, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C93A0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C93A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5688, family=23, type=1, proto=6, laddr=('::1', 62105, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5688, family=23, type=1, proto=6, laddr=('::1', 62105, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5688, family=23, type=1, proto=6, laddr=('::1', 62105, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:36 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:36 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:36 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:36 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5688, family=23, type=1, proto=6, laddr=('::1', 62105, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5448, family=2, type=1, proto=6, laddr=('127.0.0.1', 62106), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:36 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C9520>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C9520> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:37 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5448, family=2, type=1, proto=6, laddr=('127.0.0.1', 62106), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5448, family=2, type=1, proto=6, laddr=('127.0.0.1', 62106), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5448, family=2, type=1, proto=6, laddr=('127.0.0.1', 62106), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:37 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:37 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:37 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:37 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:37 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-24 19:33:37 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5448, family=2, type=1, proto=6, laddr=('127.0.0.1', 62106), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:37 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:37 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:37 [ERROR  ] [src.messaging.rabbitmq_client] [_connect:43] Failed to connect to RabbitMQ (attempt 2/5): ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:37 [INFO   ] [src.messaging.rabbitmq_client] [_connect:45] Retrying in 5 seconds...
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5552, family=23, type=1, proto=6, laddr=('::1', 62110, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C95E0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C95E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5552, family=23, type=1, proto=6, laddr=('::1', 62110, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5552, family=23, type=1, proto=6, laddr=('::1', 62110, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5552, family=23, type=1, proto=6, laddr=('::1', 62110, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:42 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:42 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:42 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:42 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5552, family=23, type=1, proto=6, laddr=('::1', 62110, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5924, family=2, type=1, proto=6, laddr=('127.0.0.1', 62111), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C96A0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C96A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5924, family=2, type=1, proto=6, laddr=('127.0.0.1', 62111), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5924, family=2, type=1, proto=6, laddr=('127.0.0.1', 62111), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5924, family=2, type=1, proto=6, laddr=('127.0.0.1', 62111), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:42 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:42 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:42 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:42 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:42 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-24 19:33:42 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:42 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5924, family=2, type=1, proto=6, laddr=('127.0.0.1', 62111), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:42 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:42 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:42 [ERROR  ] [src.messaging.rabbitmq_client] [_connect:43] Failed to connect to RabbitMQ (attempt 3/5): ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:42 [INFO   ] [src.messaging.rabbitmq_client] [_connect:45] Retrying in 5 seconds...
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5620, family=23, type=1, proto=6, laddr=('::1', 62116, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C9430>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C9430> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5620, family=23, type=1, proto=6, laddr=('::1', 62116, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5620, family=23, type=1, proto=6, laddr=('::1', 62116, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5620, family=23, type=1, proto=6, laddr=('::1', 62116, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:47 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:47 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:47 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:47 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5620, family=23, type=1, proto=6, laddr=('::1', 62116, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5908, family=2, type=1, proto=6, laddr=('127.0.0.1', 62117), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C8D70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C8D70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5908, family=2, type=1, proto=6, laddr=('127.0.0.1', 62117), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5908, family=2, type=1, proto=6, laddr=('127.0.0.1', 62117), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5908, family=2, type=1, proto=6, laddr=('127.0.0.1', 62117), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:47 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:47 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:47 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:47 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:47 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-24 19:33:47 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:47 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5908, family=2, type=1, proto=6, laddr=('127.0.0.1', 62117), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:47 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:47 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:47 [ERROR  ] [src.messaging.rabbitmq_client] [_connect:43] Failed to connect to RabbitMQ (attempt 4/5): ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:47 [INFO   ] [src.messaging.rabbitmq_client] [_connect:45] Retrying in 5 seconds...
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=6068, family=23, type=1, proto=6, laddr=('::1', 62123, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C8BF0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C8BF0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=6068, family=23, type=1, proto=6, laddr=('::1', 62123, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=6068, family=23, type=1, proto=6, laddr=('::1', 62123, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=6068, family=23, type=1, proto=6, laddr=('::1', 62123, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:52 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:52 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:52 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:52 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('127.0.0.1', 5672)
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=6068, family=23, type=1, proto=6, laddr=('::1', 62123, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=6072, family=2, type=1, proto=6, laddr=('127.0.0.1', 62124), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C9010>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000222D37C9010> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=6072, family=2, type=1, proto=6, laddr=('127.0.0.1', 62124), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=6072, family=2, type=1, proto=6, laddr=('127.0.0.1', 62124), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=6072, family=2, type=1, proto=6, laddr=('127.0.0.1', 62124), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:52 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=False, error-arg=None; pending-error=ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:52 [ERROR  ] [pika.connection     ] [_on_stream_terminated:2052] Connection closed while authenticating indicating a probable authentication error
2025-05-24 19:33:52 [INFO   ] [pika.connection     ] [_on_stream_terminated:2082] Connection setup terminated due to ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:52 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:291] AMQPConnector - reporting failure: AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:52 [ERROR  ] [pika.adapters.utils.connection_workflow] [_start_new_cycle_async:746] AMQP connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",).
2025-05-24 19:33:52 [ERROR  ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:723] AMQPConnectionWorkflow - reporting failure: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=6072, family=2, type=1, proto=6, laddr=('127.0.0.1', 62124), raddr=('127.0.0.1', 5672)>
2025-05-24 19:33:52 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:450] Connection workflow failed: AMQPConnectionWorkflowFailed: 2 exceptions in all; last exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",); first exception - AMQPConnectorAMQPHandshakeError: ProbableAuthenticationError: Client was disconnected at a connection stage indicating a probable authentication error: ("ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'",)
2025-05-24 19:33:52 [ERROR  ] [pika.adapters.blocking_connection] [_create_connection:457] Error in _create_connection().
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:52 [ERROR  ] [src.messaging.rabbitmq_client] [_connect:43] Failed to connect to RabbitMQ (attempt 5/5): ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:52 [ERROR  ] [src.messaging.rabbitmq_client] [_connect:48] Max retries reached. Could not connect to RabbitMQ.
2025-05-24 19:33:52 [ERROR  ] [root                ] [start_feature_extractor_command:269] Feature Extractor Service failed: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\main.py", line 248, in start_feature_extractor_command
    mq_client = RabbitMQClient(
                ^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\messaging\rabbitmq_client.py", line 19, in __init__
    self._connect()
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\src\messaging\rabbitmq_client.py", line 37, in _connect
    self.connection = pika.BlockingConnection(params)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 360, in __init__
    self._impl = self._create_connection(parameters, _impl_class)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\blocking_connection.py", line 451, in _create_connection
    raise self._reap_last_connection_workflow_error(error)
pika.exceptions.ProbableAuthenticationError: ConnectionClosedByBroker: (403) 'ACCESS_REFUSED - Login was refused using authentication mechanism PLAIN. For details see the broker logfile.'
2025-05-24 19:33:52 [INFO   ] [root                ] [start_feature_extractor_command:275] Feature Extractor Service has shut down.
2025-05-24 19:34:52 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:34:52 [INFO   ] [root                ] [start_feature_extractor_command:241] Attempting to start Feature Extractor Service.
2025-05-24 19:34:52 [INFO   ] [root                ] [start_feature_extractor_command:242]   RabbitMQ Host: localhost:5672
2025-05-24 19:34:52 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:34:52 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5436, family=23, type=1, proto=6, laddr=('::1', 62153, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:34:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:34:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:34:52 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:34:52 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:34:52 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 19:34:52 [INFO   ] [src.ai_monitoring.feature_extractor_service] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-24 19:34:52 [INFO   ] [src.ai_monitoring.feature_extractor_service] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-24 19:34:52 [INFO   ] [src.ai_monitoring.feature_extractor_service] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-24 19:34:52 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-24 19:36:13 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:37:56 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:37:56 [INFO   ] [root                ] [start_qos_inference_command:296] Attempting to start QoS ML Inference Service.
2025-05-24 19:37:56 [INFO   ] [root                ] [start_qos_inference_command:297]   Model Name: qos_anomaly_detector, Version: latest
2025-05-24 19:37:56 [INFO   ] [root                ] [start_qos_inference_command:298]   RabbitMQ Host: localhost:5672
2025-05-24 19:37:56 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:37:56 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=4752, family=23, type=1, proto=6, laddr=('::1', 62228, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:37:56 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:37:56 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:37:56 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:37:56 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:37:56 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 19:37:56 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data/models/model_registry.json
2025-05-24 19:37:56 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_detector' version 'latest' from registry.
2025-05-24 19:37:56 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:166] Model 'qos_anomaly_detector' not found in the registry.
2025-05-24 19:37:56 [ERROR  ] [src.ai_monitoring.qos_ml_inference_service] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_detector' version 'latest' from registry.
2025-05-24 19:37:56 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-24 19:37:56 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-24 19:37:56 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-24 19:37:56 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-24 19:38:35 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:39:44 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:39:44 [INFO   ] [root                ] [start_core_analysis_command:355] Attempting to start Core Analysis Service.
2025-05-24 19:39:44 [INFO   ] [root                ] [start_core_analysis_command:356]   RabbitMQ Host: localhost:5672
2025-05-24 19:39:44 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:39:44 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5852, family=23, type=1, proto=6, laddr=('::1', 62264, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:39:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002395041F830>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002395041F830> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:39:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002395041F830> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:39:44 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002395041F830> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:39:44 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002395041F830> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:39:44 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 19:39:44 [INFO   ] [src.analysis.core_analysis_service] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue_for_analysis' declared successfully.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue_for_analysis' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue_for_analysis'.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue_for_analysis' declared successfully.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue_for_analysis' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue_for_analysis'.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-24 19:39:44 [INFO   ] [src.analysis.core_analysis_service] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_queue_for_analysis and ml_results_queue_for_analysis, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-24 19:39:44 [INFO   ] [src.analysis.core_analysis_service] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_queue_for_analysis
2025-05-24 19:39:44 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue_for_analysis'. Waiting for messages...
2025-05-24 19:41:36 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:42:10 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 19:42:10 [INFO   ] [root                ] [start_reporting_command:407] Attempting to start Reporting Service.
2025-05-24 19:42:10 [INFO   ] [root                ] [start_reporting_command:408]   Report Format: console
2025-05-24 19:42:10 [INFO   ] [root                ] [start_reporting_command:409]   RabbitMQ Host: localhost:5672
2025-05-24 19:42:10 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 19:42:10 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=6052, family=23, type=1, proto=6, laddr=('::1', 62293, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 19:42:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 19:42:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:42:10 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:42:10 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 19:42:10 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 19:42:10 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 19:42:10 [INFO   ] [src.reporting.reporting_service] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-24 19:42:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-24 19:42:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue_for_reporting' declared successfully.
2025-05-24 19:42:10 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue_for_reporting' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-24 19:42:10 [INFO   ] [src.reporting.reporting_service] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'analysis_results_queue_for_reporting' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-24 19:42:10 [INFO   ] [src.reporting.reporting_service] [start_consuming:112] ReportingService starting to consume from queue: 'analysis_results_queue_for_reporting'
2025-05-24 19:42:10 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'analysis_results_queue_for_reporting'. Waiting for messages...
2025-05-24 20:04:36 [INFO   ] [src.reporting.reporting_service] [_handle_shutdown_signal:63] Shutdown signal 2 received. Initiating graceful shutdown.
2025-05-24 20:04:36 [INFO   ] [src.reporting.reporting_service] [generate_final_report:85] No analysis results collected. Skipping final report generation.
2025-05-24 20:04:36 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:04:36 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:04:36 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:04:36 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:04:36 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:04:36 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001ADE0F979E0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:04:36 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-24 20:04:36 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-24 20:04:36 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-24 20:04:36 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=6052, family=23, type=1, proto=6, laddr=('::1', 62293, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:04:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=6052, family=23, type=1, proto=6, laddr=('::1', 62293, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:04:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=6052, family=23, type=1, proto=6, laddr=('::1', 62293, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:04:36 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-24 20:04:36 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-24 20:04:36 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=6052, family=23, type=1, proto=6, laddr=('::1', 62293, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:04:36 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-24 20:04:36 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-24 20:04:36 [INFO   ] [src.reporting.reporting_service] [_handle_shutdown_signal:71] ReportingService shut down.
2025-05-24 20:04:36 [INFO   ] [src.reporting.reporting_service] [start_consuming:132] ReportingService consumption loop finished or was interrupted.
2025-05-24 20:04:36 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:146] Channel is not consuming or not available.
2025-05-24 20:04:36 [INFO   ] [root                ] [start_reporting_command:444] Reporting Service has shut down.
2025-05-24 20:04:56 [INFO   ] [src.messaging.rabbitmq_client] [consume:124] Consumer interrupted. Stopping...
2025-05-24 20:04:56 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:04:56 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:04:56 [INFO   ] [src.analysis.core_analysis_service] [start_consuming:432] Starting consumer for MLResult messages on queue: ml_results_queue_for_analysis
2025-05-24 20:04:56 [ERROR  ] [pika.adapters.utils.io_services_utils] [log_exception_func_wrap:55] Wrapped func exited with exception. Caller's stack:
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\diagnostic_utils.py", line 53, in log_exception_func_wrap
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 1047, in _on_socket_readable
    self._consume()
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 791, in _consume
    data = self._sigint_safe_recv(self._sock, self._MAX_RECV_BYTES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 79, in retry_sigint_wrap
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 846, in _sigint_safe_recv
    return sock.recv(max_bytes)
           ^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\diagnostic_utils.py", line 53, in log_exception_func_wrap
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 1047, in _on_socket_readable
    self._consume()
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 791, in _consume
    data = self._sigint_safe_recv(self._sock, self._MAX_RECV_BYTES)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 79, in retry_sigint_wrap
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\pika\adapters\utils\io_services_utils.py", line 846, in _sigint_safe_recv
    return sock.recv(max_bytes)
           ^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
2025-05-24 20:04:56 [INFO   ] [src.messaging.rabbitmq_client] [consume:124] Consumer interrupted. Stopping...
2025-05-24 20:04:56 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:04:56 [ERROR  ] [src.messaging.rabbitmq_client] [stop_consuming:144] Error during fallback stop_consuming: 1
2025-05-24 20:04:56 [INFO   ] [src.analysis.core_analysis_service] [start_consuming:444] CoreAnalysisService consumption loop finished or was interrupted.
2025-05-24 20:04:56 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:04:56 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:04:56 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002395041F830> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:05:08 [INFO   ] [src.messaging.rabbitmq_client] [consume:124] Consumer interrupted. Stopping...
2025-05-24 20:05:08 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:05:08 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:05:08 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [start_consuming:326] QoSMLInferenceService consumption loop finished or was interrupted.
2025-05-24 20:05:08 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:05:08 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:05:08 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:05:08 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016AAB213860> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:05:08 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-24 20:05:08 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-24 20:05:08 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-24 20:05:08 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=4752, family=23, type=1, proto=6, laddr=('::1', 62228, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:08 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=4752, family=23, type=1, proto=6, laddr=('::1', 62228, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:08 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=4752, family=23, type=1, proto=6, laddr=('::1', 62228, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:08 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-24 20:05:08 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-24 20:05:08 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=4752, family=23, type=1, proto=6, laddr=('::1', 62228, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:08 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-24 20:05:08 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-24 20:05:08 [INFO   ] [root                ] [start_qos_inference_command:341] QoS ML Inference Service has shut down.
2025-05-24 20:05:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:124] Consumer interrupted. Stopping...
2025-05-24 20:05:12 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:05:12 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:05:12 [INFO   ] [src.ai_monitoring.feature_extractor_service] [start_consuming:265] FeatureExtractorService consumption loop finished or was interrupted.
2025-05-24 20:05:12 [WARNING] [src.messaging.rabbitmq_client] [stop_consuming:139] 'is_consuming' attribute not found on channel. Attempting to stop_consuming anyway.
2025-05-24 20:05:12 [INFO   ] [src.messaging.rabbitmq_client] [stop_consuming:142] Stopped consuming messages (fallback attempt).
2025-05-24 20:05:12 [INFO   ] [pika.channel        ] [close:536] Closing channel (0): 'Normal shutdown' on <Channel number=1 OPEN conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:05:12 [INFO   ] [pika.channel        ] [_on_closeok:1133] Received <Channel.CloseOk> on <Channel number=1 CLOSING conn=<SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001D64BDB8A70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>>
2025-05-24 20:05:12 [INFO   ] [src.messaging.rabbitmq_client] [close:153] RabbitMQ channel closed.
2025-05-24 20:05:12 [INFO   ] [pika.adapters.blocking_connection] [close:802] Closing connection (200): Normal shutdown
2025-05-24 20:05:12 [INFO   ] [pika.connection     ] [close:1316] Closing connection (200): 'Normal shutdown'
2025-05-24 20:05:12 [INFO   ] [pika.adapters.utils.io_services_utils] [abort:731] Aborting transport connection: state=1; <socket.socket fd=5436, family=23, type=1, proto=6, laddr=('::1', 62153, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_initiate_abort:904] _AsyncTransportBase._initate_abort(): Initiating abrupt asynchronous transport shutdown: state=1; error=None; <socket.socket fd=5436, family=23, type=1, proto=6, laddr=('::1', 62153, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_deactivate:869] Deactivating transport: state=1; <socket.socket fd=5436, family=23, type=1, proto=6, laddr=('::1', 62153, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:12 [INFO   ] [pika.connection     ] [_on_stream_terminated:2017] AMQP stack terminated, failed to connect, or aborted: opened=True, error-arg=None; pending-error=ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-24 20:05:12 [INFO   ] [pika.connection     ] [_on_stream_terminated:2086] Stack terminated due to ConnectionClosedByClient: (200) 'Normal shutdown'
2025-05-24 20:05:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_close_and_finalize:882] Closing transport socket and unlinking: state=3; <socket.socket fd=5436, family=23, type=1, proto=6, laddr=('::1', 62153, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:05:12 [INFO   ] [pika.adapters.blocking_connection] [_flush_output:525] User-initiated close: result=BlockingConnection__OnClosedArgs(connection=<SelectConnection CLOSED transport=None params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>, error=ConnectionClosedByClient: (200) 'Normal shutdown')
2025-05-24 20:05:12 [INFO   ] [src.messaging.rabbitmq_client] [close:159] RabbitMQ connection closed.
2025-05-24 20:05:12 [INFO   ] [root                ] [start_feature_extractor_command:275] Feature Extractor Service has shut down.
2025-05-24 20:07:31 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:07:31 [INFO   ] [root                ] [start_feature_extractor_command:241] Attempting to start Feature Extractor Service.
2025-05-24 20:07:31 [INFO   ] [root                ] [start_feature_extractor_command:242]   RabbitMQ Host: localhost:5672
2025-05-24 20:07:31 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:07:31 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=6000, family=23, type=1, proto=6, laddr=('::1', 62669, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:07:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AF70BE5C70>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AF70BE5C70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:07:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AF70BE5C70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:31 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AF70BE5C70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:31 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AF70BE5C70> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:31 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:07:31 [INFO   ] [src.ai_monitoring.feature_extractor_service] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-24 20:07:31 [INFO   ] [src.ai_monitoring.feature_extractor_service] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-24 20:07:31 [INFO   ] [src.ai_monitoring.feature_extractor_service] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-24 20:07:31 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-24 20:07:34 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:07:34 [INFO   ] [root                ] [start_qos_inference_command:296] Attempting to start QoS ML Inference Service.
2025-05-24 20:07:34 [INFO   ] [root                ] [start_qos_inference_command:297]   Model Name: qos_anomaly_detector, Version: latest
2025-05-24 20:07:34 [INFO   ] [root                ] [start_qos_inference_command:298]   RabbitMQ Host: localhost:5672
2025-05-24 20:07:34 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:07:34 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5392, family=23, type=1, proto=6, laddr=('::1', 62673, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:07:34 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016346F3FB00>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016346F3FB00> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:07:34 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016346F3FB00> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:34 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016346F3FB00> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:34 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000016346F3FB00> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:34 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:07:34 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data/models/model_registry.json
2025-05-24 20:07:34 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_detector' version 'latest' from registry.
2025-05-24 20:07:34 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:166] Model 'qos_anomaly_detector' not found in the registry.
2025-05-24 20:07:34 [ERROR  ] [src.ai_monitoring.qos_ml_inference_service] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_detector' version 'latest' from registry.
2025-05-24 20:07:34 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-24 20:07:34 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-24 20:07:34 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-24 20:07:34 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-24 20:07:37 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:07:37 [INFO   ] [root                ] [start_core_analysis_command:355] Attempting to start Core Analysis Service.
2025-05-24 20:07:37 [INFO   ] [root                ] [start_core_analysis_command:356]   RabbitMQ Host: localhost:5672
2025-05-24 20:07:37 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:07:37 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5268, family=23, type=1, proto=6, laddr=('::1', 62680, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:07:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000142B1E47500>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000142B1E47500> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:07:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000142B1E47500> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:37 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000142B1E47500> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:37 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x00000142B1E47500> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:37 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:07:37 [INFO   ] [src.analysis.core_analysis_service] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue_for_analysis' declared successfully.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue_for_analysis' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue_for_analysis'.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue_for_analysis' declared successfully.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue_for_analysis' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue_for_analysis'.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-24 20:07:37 [INFO   ] [src.analysis.core_analysis_service] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_queue_for_analysis and ml_results_queue_for_analysis, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-24 20:07:37 [INFO   ] [src.analysis.core_analysis_service] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_queue_for_analysis
2025-05-24 20:07:37 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue_for_analysis'. Waiting for messages...
2025-05-24 20:07:40 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:07:40 [INFO   ] [root                ] [start_reporting_command:407] Attempting to start Reporting Service.
2025-05-24 20:07:40 [INFO   ] [root                ] [start_reporting_command:408]   Report Format: console
2025-05-24 20:07:40 [INFO   ] [root                ] [start_reporting_command:409]   RabbitMQ Host: localhost:5672
2025-05-24 20:07:40 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:07:40 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=4756, family=23, type=1, proto=6, laddr=('::1', 62684, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:07:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AD7729D370>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AD7729D370> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:07:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AD7729D370> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:40 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AD7729D370> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:40 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002AD7729D370> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:07:40 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:07:40 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:07:40 [INFO   ] [src.reporting.reporting_service] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-24 20:07:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:07:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue_for_reporting' declared successfully.
2025-05-24 20:07:40 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue_for_reporting' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-24 20:07:40 [INFO   ] [src.reporting.reporting_service] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'analysis_results_queue_for_reporting' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-24 20:07:40 [INFO   ] [src.reporting.reporting_service] [start_consuming:112] ReportingService starting to consume from queue: 'analysis_results_queue_for_reporting'
2025-05-24 20:07:40 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'analysis_results_queue_for_reporting'. Waiting for messages...
2025-05-24 20:11:06 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:11:06 [INFO   ] [root                ] [start_parser_command:181] Attempting to start Packet Parser Service.
2025-05-24 20:11:06 [INFO   ] [src.utils.config_manager] [load_config:24] Configuration loaded successfully from C:\Users\juanc\Documents\Proyectos Personales\networking_tester\config\settings.yaml
2025-05-24 20:11:06 [WARNING] [src.analysis.ieee802_3_analyzer] [__init__:35] 'analysis.ethertype_map' is null in config, using default ethertype map.
2025-05-24 20:11:06 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:11:06 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5984, family=23, type=1, proto=6, laddr=('::1', 62780, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:11:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002142574E000>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002142574E000> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:11:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002142574E000> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:06 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002142574E000> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:06 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002142574E000> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:06 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:11:06 [INFO   ] [src.messaging.message_broker] [connect:52] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:11:06 [INFO   ] [src.parsing.packet_parser_service] [start:78] Packet Parser Service started successfully
2025-05-24 20:11:06 [INFO   ] [src.messaging.message_broker] [consume_messages:138] Started consuming from queue 'raw_packets'
2025-05-24 20:11:09 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:11:09 [INFO   ] [root                ] [start_stats_collector_command:207] Attempting to start Statistics Collector Service.
2025-05-24 20:11:09 [INFO   ] [src.statistics.statistics_collector_service] [reset_stats:74] Statistics reset.
2025-05-24 20:11:09 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:11:09 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=4728, family=23, type=1, proto=6, laddr=('::1', 62785, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:11:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000019D24C27350>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000019D24C27350> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:11:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000019D24C27350> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:09 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000019D24C27350> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:09 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000019D24C27350> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:09 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:11:09 [INFO   ] [src.messaging.message_broker] [connect:52] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:11:09 [INFO   ] [src.statistics.statistics_collector_service] [start:100] Statistics Collector Service started successfully
2025-05-24 20:11:09 [INFO   ] [src.messaging.message_broker] [consume_messages:138] Started consuming from queue 'parsed_packets'
2025-05-24 20:11:12 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:11:12 [INFO   ] [root                ] [start_feature_extractor_command:241] Attempting to start Feature Extractor Service.
2025-05-24 20:11:12 [INFO   ] [root                ] [start_feature_extractor_command:242]   RabbitMQ Host: localhost:5672
2025-05-24 20:11:12 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:11:12 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5888, family=23, type=1, proto=6, laddr=('::1', 62791, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:11:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002317904E5A0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002317904E5A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:11:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002317904E5A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:12 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002317904E5A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:12 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002317904E5A0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:12 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:11:12 [INFO   ] [src.ai_monitoring.feature_extractor_service] [_setup_messaging:45] Setting up messaging for FeatureExtractorService.
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue' declared successfully.
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue'.
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-24 20:11:12 [INFO   ] [src.ai_monitoring.feature_extractor_service] [_setup_messaging:58] Messaging setup complete. Consuming from parsed_packets_queue (bound to parsed_packets_exchange), publishing to features_exchange with key features_queue
2025-05-24 20:11:12 [INFO   ] [src.ai_monitoring.feature_extractor_service] [start_consuming:252] FeatureExtractorService starting to consume from queue: 'parsed_packets_queue' bound to exchange 'parsed_packets_exchange'
2025-05-24 20:11:12 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue'. Waiting for messages...
2025-05-24 20:11:15 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:11:15 [INFO   ] [root                ] [start_qos_inference_command:296] Attempting to start QoS ML Inference Service.
2025-05-24 20:11:15 [INFO   ] [root                ] [start_qos_inference_command:297]   Model Name: qos_anomaly_detector, Version: latest
2025-05-24 20:11:15 [INFO   ] [root                ] [start_qos_inference_command:298]   RabbitMQ Host: localhost:5672
2025-05-24 20:11:15 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:11:15 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=5580, family=23, type=1, proto=6, laddr=('::1', 62796, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:11:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022EB4E19100>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022EB4E19100> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:11:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022EB4E19100> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:15 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022EB4E19100> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:15 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x0000022EB4E19100> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:15 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:11:15 [INFO   ] [src.ai_monitoring.model_registry_client] [_load_manifest:62] Successfully loaded model registry manifest from: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\data/models/model_registry.json
2025-05-24 20:11:15 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_load_model_and_scaler:77] Attempting to load model 'qos_anomaly_detector' version 'latest' from registry.
2025-05-24 20:11:15 [WARNING] [src.ai_monitoring.model_registry_client] [get_model_details:166] Model 'qos_anomaly_detector' not found in the registry.
2025-05-24 20:11:15 [ERROR  ] [src.ai_monitoring.qos_ml_inference_service] [_load_model_and_scaler:81] Could not retrieve details for model 'qos_anomaly_detector' version 'latest' from registry.
2025-05-24 20:11:15 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_setup_messaging:153] Setting up messaging for QoSMLInferenceService.
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'features_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'features_queue' declared successfully.
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'features_queue' bound to exchange 'features_exchange' with routing key 'features_queue'.
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue' declared successfully.
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue'.
2025-05-24 20:11:15 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [_setup_messaging:161] Messaging setup complete. Consuming from features_queue, publishing to ml_results_exchange with key ml_results_queue
2025-05-24 20:11:15 [INFO   ] [src.ai_monitoring.qos_ml_inference_service] [start_consuming:314] QoSMLInferenceService starting to consume from queue: 'features_queue' bound to exchange 'features_exchange'
2025-05-24 20:11:15 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'features_queue'. Waiting for messages...
2025-05-24 20:11:18 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:11:18 [INFO   ] [root                ] [start_core_analysis_command:355] Attempting to start Core Analysis Service.
2025-05-24 20:11:18 [INFO   ] [root                ] [start_core_analysis_command:356]   RabbitMQ Host: localhost:5672
2025-05-24 20:11:18 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:11:18 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=6048, family=23, type=1, proto=6, laddr=('::1', 62800, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:11:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F97425C950>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F97425C950> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:11:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F97425C950> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:18 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F97425C950> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:18 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000001F97425C950> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:18 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:11:18 [INFO   ] [src.analysis.core_analysis_service] [_setup_messaging:96] Setting up messaging for CoreAnalysisService.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'parsed_packets_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'parsed_packets_queue_for_analysis' declared successfully.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'parsed_packets_queue_for_analysis' bound to exchange 'parsed_packets_exchange' with routing key 'parsed_packets_queue_for_analysis'.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'ml_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'ml_results_queue_for_analysis' declared successfully.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'ml_results_queue_for_analysis' bound to exchange 'ml_results_exchange' with routing key 'ml_results_queue_for_analysis'.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue' declared successfully.
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-24 20:11:18 [INFO   ] [src.analysis.core_analysis_service] [_setup_messaging:110] Messaging setup complete. Consuming from parsed_packets_queue_for_analysis and ml_results_queue_for_analysis, publishing to analysis_results_exchange with key analysis_results_queue
2025-05-24 20:11:18 [INFO   ] [src.analysis.core_analysis_service] [start_consuming:421] Starting consumer for ParsedPacket messages on queue: parsed_packets_queue_for_analysis
2025-05-24 20:11:18 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'parsed_packets_queue_for_analysis'. Waiting for messages...
2025-05-24 20:11:21 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 20:11:21 [INFO   ] [root                ] [start_reporting_command:407] Attempting to start Reporting Service.
2025-05-24 20:11:21 [INFO   ] [root                ] [start_reporting_command:408]   Report Format: console
2025-05-24 20:11:21 [INFO   ] [root                ] [start_reporting_command:409]   RabbitMQ Host: localhost:5672
2025-05-24 20:11:21 [INFO   ] [pika.adapters.utils.connection_workflow] [start:179] Pika version 1.3.2 connecting to ('::1', 5672, 0, 0)
2025-05-24 20:11:21 [INFO   ] [pika.adapters.utils.io_services_utils] [_on_writable:345] Socket connected: <socket.socket fd=1764, family=23, type=1, proto=6, laddr=('::1', 62803, 0, 0), raddr=('::1', 5672, 0, 0)>
2025-05-24 20:11:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_on_transport_establishment_done:428] Streaming transport linked up: (<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B4652CB8F0>, _StreamingProtocolShim: <SelectConnection PROTOCOL transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B4652CB8F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>).
2025-05-24 20:11:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:293] AMQPConnector - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B4652CB8F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:21 [INFO   ] [pika.adapters.utils.connection_workflow] [_report_completion_and_cleanup:725] AMQPConnectionWorkflow - reporting success: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B4652CB8F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:21 [INFO   ] [pika.adapters.blocking_connection] [_create_connection:453] Connection workflow succeeded: <SelectConnection OPEN transport=<pika.adapters.utils.io_services_utils._AsyncPlaintextTransport object at 0x000002B4652CB8F0> params=<ConnectionParameters host=localhost port=5672 virtual_host=/ ssl=False>>
2025-05-24 20:11:21 [INFO   ] [pika.adapters.blocking_connection] [__init__:1264] Created channel=1
2025-05-24 20:11:21 [INFO   ] [src.messaging.rabbitmq_client] [_connect:39] Successfully connected to RabbitMQ at localhost:5672
2025-05-24 20:11:21 [INFO   ] [src.reporting.reporting_service] [_setup_messaging:51] Setting up messaging for ReportingService.
2025-05-24 20:11:21 [INFO   ] [src.messaging.rabbitmq_client] [declare_exchange:60] Exchange 'analysis_results_exchange' of type 'direct' declared successfully.
2025-05-24 20:11:21 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:71] Queue 'analysis_results_queue_for_reporting' declared successfully.
2025-05-24 20:11:21 [INFO   ] [src.messaging.rabbitmq_client] [declare_queue:74] Queue 'analysis_results_queue_for_reporting' bound to exchange 'analysis_results_exchange' with routing key 'analysis_results_queue'.
2025-05-24 20:11:21 [INFO   ] [src.reporting.reporting_service] [_setup_messaging:56] Messaging setup complete. Consuming from queue 'analysis_results_queue_for_reporting' bound to exchange 'analysis_results_exchange' with key 'analysis_results_queue'
2025-05-24 20:11:21 [INFO   ] [src.reporting.reporting_service] [start_consuming:112] ReportingService starting to consume from queue: 'analysis_results_queue_for_reporting'
2025-05-24 20:11:21 [INFO   ] [src.messaging.rabbitmq_client] [consume:121] Starting to consume messages from queue 'analysis_results_queue_for_reporting'. Waiting for messages...
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.messaging.message_broker] [wrapper:129] Error processing message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 20:11:29 [ERROR  ] [src.parsing.packet_parser_service] [_process_raw_packet_message:141] Error processing raw packet message: keys must be str, int, float, bool or None, not member_descriptor
2025-05-24 23:20:08 [INFO   ] [networking_tester   ] [setup_logging:64] Logging configurado. Nivel: INFO. Archivo: C:\Users\juanc\Documents\Proyectos Personales\networking_tester\logs\networking_tester.log
2025-05-24 23:20:08 [INFO   ] [__main__            ] [initialize:40] 🚀 Starting Phase 2 Task 2.3: ML Model Registry Enhancement
2025-05-24 23:20:08 [WARNING] [src.ai_monitoring.model_registry_client] [_load_manifest:87] Model registry manifest file not found at: C:\Users\juanc\Documents\Proyectos Personales\data/models/model_registry.json. A new one will be created upon registration.
2025-05-24 23:20:08 [INFO   ] [src.ai_monitoring.model_registry_client] [__init__:60] MLflow Model Registry integration enabled
2025-05-24 23:20:08 [WARNING] [root                ] [search_experiments:333] Malformed experiment '0'. Detailed error Yaml file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\mlruns\0\meta.yaml' does not exist.
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 329, in search_experiments
    exp = self._get_experiment(exp_id, view_type)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 427, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 1373, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 1366, in _read_helper
    result = read_yaml(root, file_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\utils\file_utils.py", line 310, in read_yaml
    raise MissingConfigException(f"Yaml file '{file_path}' does not exist.")
mlflow.exceptions.MissingConfigException: Yaml file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\mlruns\0\meta.yaml' does not exist.
2025-05-24 23:20:08 [WARNING] [root                ] [search_experiments:333] Malformed experiment '0'. Detailed error Yaml file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\mlruns\0\meta.yaml' does not exist.
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 329, in search_experiments
    exp = self._get_experiment(exp_id, view_type)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 427, in _get_experiment
    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 1373, in _read_yaml
    return _read_helper(root, file_name, attempts_remaining=retries)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\store\tracking\file_store.py", line 1366, in _read_helper
    result = read_yaml(root, file_name)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\venv\Lib\site-packages\mlflow\utils\file_utils.py", line 310, in read_yaml
    raise MissingConfigException(f"Yaml file '{file_path}' does not exist.")
mlflow.exceptions.MissingConfigException: Yaml file 'C:\Users\juanc\Documents\Proyectos Personales\networking_tester\mlruns\0\meta.yaml' does not exist.
2025-05-24 23:20:08 [INFO   ] [src.ai_monitoring.enhanced_model_registry_client] [__init__:66] MLflow Model Registry integration enabled
2025-05-24 23:20:08 [INFO   ] [src.ai_monitoring.enhanced_model_registry_client] [__init__:67] MLflow Tracking URI: file:///C:/Users/juanc/Documents/Proyectos%20Personales/networking_tester/mlruns
2025-05-24 23:20:08 [INFO   ] [src.ai_monitoring.enhanced_model_registry_client] [__init__:69] MLflow Experiment: networking_tester_phase2
2025-05-24 23:20:08 [INFO   ] [__main__            ] [initialize:51] ✅ Enhanced Model Registry initialized
2025-05-24 23:20:08 [INFO   ] [__main__            ] [initialize:52] 📁 Registry path: data/models/model_registry.json
2025-05-24 23:20:08 [INFO   ] [__main__            ] [initialize:53] 🔄 MLflow integration: ENABLED
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:322] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:323] 🔍 PHASE 2 MODEL REGISTRY VALIDATION
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:324] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [validate_registry:63] 🔍 Validating model registry...
2025-05-24 23:20:08 [INFO   ] [__main__            ] [validate_registry:80] 📊 Found 0 models in registry: []
2025-05-24 23:20:08 [INFO   ] [__main__            ] [validate_registry:153] 🏥 Registry health: EXCELLENT
2025-05-24 23:20:08 [INFO   ] [__main__            ] [validate_registry:154] ✅ Valid models: 0
2025-05-24 23:20:08 [INFO   ] [__main__            ] [validate_registry:155] ❌ Invalid models: 0
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:329] ✅ Validation Status: HEALTHY
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:330] 🏥 Registry Health: EXCELLENT
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:333] 💡 Recommendations:
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:335]    1. Add at least one valid model for testing
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:339] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:340] 🛠️ CREATING PHASE 2 SAMPLE MODELS
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:341] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [create_sample_models:167] 🛠️ Creating sample models for Phase 2...
2025-05-24 23:20:08 [ERROR  ] [__main__            ] [create_sample_models:271] ❌ Error creating sample models: ModelRegistryClient.register_model() got an unexpected keyword argument 'model_id'
Traceback (most recent call last):
  File "C:\Users\juanc\Documents\Proyectos Personales\networking_tester\enhance_model_registry.py", line 254, in create_sample_models
    success = self.registry_client.register_model(
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ModelRegistryClient.register_model() got an unexpected keyword argument 'model_id'
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:345] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:346] 📊 FINAL REGISTRY STATUS
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:347] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [display_registry_status:275] 📊 Displaying Model Registry Status...
2025-05-24 23:20:08 [INFO   ] [__main__            ] [display_registry_status:280] 📦 Total models: 0
2025-05-24 23:20:08 [INFO   ] [__main__            ] [display_registry_status:305] 🔄 MLflow models: 0
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:350] ============================================================
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:351] ✅ PHASE 2 TASK 2.3 COMPLETED: ML Model Registry Enhanced
2025-05-24 23:20:08 [INFO   ] [__main__            ] [main:352] ============================================================
